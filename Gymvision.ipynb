{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36ca0c56-a032-4bc2-8738-c5b705ef9ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\donny\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from ultralytics import YOLO\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import cv2\n",
    "from ultralytics.utils.plotting import Annotator  # for drawing bounding boxes\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "775af968",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a84ca88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'person',\n",
       " 1: 'bicycle',\n",
       " 2: 'car',\n",
       " 3: 'motorcycle',\n",
       " 4: 'airplane',\n",
       " 5: 'bus',\n",
       " 6: 'train',\n",
       " 7: 'truck',\n",
       " 8: 'boat',\n",
       " 9: 'traffic light',\n",
       " 10: 'fire hydrant',\n",
       " 11: 'stop sign',\n",
       " 12: 'parking meter',\n",
       " 13: 'bench',\n",
       " 14: 'bird',\n",
       " 15: 'cat',\n",
       " 16: 'dog',\n",
       " 17: 'horse',\n",
       " 18: 'sheep',\n",
       " 19: 'cow',\n",
       " 20: 'elephant',\n",
       " 21: 'bear',\n",
       " 22: 'zebra',\n",
       " 23: 'giraffe',\n",
       " 24: 'backpack',\n",
       " 25: 'umbrella',\n",
       " 26: 'handbag',\n",
       " 27: 'tie',\n",
       " 28: 'suitcase',\n",
       " 29: 'frisbee',\n",
       " 30: 'skis',\n",
       " 31: 'snowboard',\n",
       " 32: 'sports ball',\n",
       " 33: 'kite',\n",
       " 34: 'baseball bat',\n",
       " 35: 'baseball glove',\n",
       " 36: 'skateboard',\n",
       " 37: 'surfboard',\n",
       " 38: 'tennis racket',\n",
       " 39: 'bottle',\n",
       " 40: 'wine glass',\n",
       " 41: 'cup',\n",
       " 42: 'fork',\n",
       " 43: 'knife',\n",
       " 44: 'spoon',\n",
       " 45: 'bowl',\n",
       " 46: 'banana',\n",
       " 47: 'apple',\n",
       " 48: 'sandwich',\n",
       " 49: 'orange',\n",
       " 50: 'broccoli',\n",
       " 51: 'carrot',\n",
       " 52: 'hot dog',\n",
       " 53: 'pizza',\n",
       " 54: 'donut',\n",
       " 55: 'cake',\n",
       " 56: 'chair',\n",
       " 57: 'couch',\n",
       " 58: 'potted plant',\n",
       " 59: 'bed',\n",
       " 60: 'dining table',\n",
       " 61: 'toilet',\n",
       " 62: 'tv',\n",
       " 63: 'laptop',\n",
       " 64: 'mouse',\n",
       " 65: 'remote',\n",
       " 66: 'keyboard',\n",
       " 67: 'cell phone',\n",
       " 68: 'microwave',\n",
       " 69: 'oven',\n",
       " 70: 'toaster',\n",
       " 71: 'sink',\n",
       " 72: 'refrigerator',\n",
       " 73: 'book',\n",
       " 74: 'clock',\n",
       " 75: 'vase',\n",
       " 76: 'scissors',\n",
       " 77: 'teddy bear',\n",
       " 78: 'hair drier',\n",
       " 79: 'toothbrush'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2eb543c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Model.info of YOLO(\n",
       "  (model): DetectionModel(\n",
       "    (model): Sequential(\n",
       "      (0): Conv(\n",
       "        (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv(\n",
       "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (2): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): Conv(\n",
       "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (4): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-1): 2 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): Conv(\n",
       "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (6): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-1): 2 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): Conv(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (8): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): SPPF(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (10): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (11): Concat()\n",
       "      (12): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (14): Concat()\n",
       "      (15): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (16): Conv(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (17): Concat()\n",
       "      (18): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (19): Conv(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (20): Concat()\n",
       "      (21): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (22): Detect(\n",
       "        (cv2): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (cv3): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(64, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(128, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(256, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (dfl): DFL(\n",
       "          (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad64ed94",
   "metadata": {},
   "source": [
    "# Basketball Court - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc0dbb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 175.9ms\n",
      "Speed: 3.0ms preprocess, 175.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 163.3ms\n",
      "Speed: 5.0ms preprocess, 163.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 117.4ms\n",
      "Speed: 4.2ms preprocess, 117.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 122.7ms\n",
      "Speed: 3.2ms preprocess, 122.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 126.3ms\n",
      "Speed: 4.3ms preprocess, 126.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 121.5ms\n",
      "Speed: 4.0ms preprocess, 121.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 155.3ms\n",
      "Speed: 4.0ms preprocess, 155.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 74.9ms\n",
      "Speed: 3.8ms preprocess, 74.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 73.6ms\n",
      "Speed: 1.0ms preprocess, 73.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 68.4ms\n",
      "Speed: 2.2ms preprocess, 68.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 70.1ms\n",
      "Speed: 2.0ms preprocess, 70.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 70.5ms\n",
      "Speed: 1.9ms preprocess, 70.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 72.5ms\n",
      "Speed: 3.0ms preprocess, 72.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 73.9ms\n",
      "Speed: 2.0ms preprocess, 73.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 68.6ms\n",
      "Speed: 2.0ms preprocess, 68.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 60.5ms\n",
      "Speed: 4.0ms preprocess, 60.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.8ms\n",
      "Speed: 2.4ms preprocess, 66.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 71.1ms\n",
      "Speed: 2.0ms preprocess, 71.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.2ms\n",
      "Speed: 3.0ms preprocess, 66.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 70.3ms\n",
      "Speed: 2.0ms preprocess, 70.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 68.0ms\n",
      "Speed: 3.0ms preprocess, 68.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 63.8ms\n",
      "Speed: 1.0ms preprocess, 63.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 74.8ms\n",
      "Speed: 4.0ms preprocess, 74.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 69.8ms\n",
      "Speed: 1.9ms preprocess, 69.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 74.7ms\n",
      "Speed: 2.0ms preprocess, 74.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.9ms\n",
      "Speed: 2.0ms preprocess, 65.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 72.9ms\n",
      "Speed: 2.0ms preprocess, 72.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 68.9ms\n",
      "Speed: 2.0ms preprocess, 68.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.8ms\n",
      "Speed: 1.9ms preprocess, 65.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.0ms\n",
      "Speed: 2.0ms preprocess, 66.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.5ms\n",
      "Speed: 2.0ms preprocess, 67.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 64.5ms\n",
      "Speed: 1.9ms preprocess, 64.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.7ms\n",
      "Speed: 1.0ms preprocess, 66.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 69.8ms\n",
      "Speed: 1.9ms preprocess, 69.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 74.1ms\n",
      "Speed: 2.0ms preprocess, 74.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.2ms\n",
      "Speed: 2.0ms preprocess, 65.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 64.4ms\n",
      "Speed: 2.0ms preprocess, 64.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.6ms\n",
      "Speed: 2.1ms preprocess, 67.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 69.4ms\n",
      "Speed: 1.0ms preprocess, 69.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 79.5ms\n",
      "Speed: 2.0ms preprocess, 79.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 74.4ms\n",
      "Speed: 2.0ms preprocess, 74.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.1ms\n",
      "Speed: 2.0ms preprocess, 65.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 69.7ms\n",
      "Speed: 3.0ms preprocess, 69.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.9ms\n",
      "Speed: 2.0ms preprocess, 66.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.6ms\n",
      "Speed: 2.0ms preprocess, 65.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 72.0ms\n",
      "Speed: 2.0ms preprocess, 72.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 69.3ms\n",
      "Speed: 2.0ms preprocess, 69.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 70.3ms\n",
      "Speed: 1.9ms preprocess, 70.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 69.1ms\n",
      "Speed: 2.0ms preprocess, 69.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 74.0ms\n",
      "Speed: 2.1ms preprocess, 74.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.2ms\n",
      "Speed: 2.0ms preprocess, 66.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.2ms\n",
      "Speed: 2.0ms preprocess, 66.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.7ms\n",
      "Speed: 2.0ms preprocess, 65.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.1ms\n",
      "Speed: 1.9ms preprocess, 66.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.9ms\n",
      "Speed: 2.1ms preprocess, 66.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 61.7ms\n",
      "Speed: 2.0ms preprocess, 61.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 60.8ms\n",
      "Speed: 2.0ms preprocess, 60.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 70.5ms\n",
      "Speed: 2.0ms preprocess, 70.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 59.9ms\n",
      "Speed: 2.0ms preprocess, 59.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 99.1ms\n",
      "Speed: 2.0ms preprocess, 99.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 68.0ms\n",
      "Speed: 2.3ms preprocess, 68.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 88.4ms\n",
      "Speed: 3.1ms preprocess, 88.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.8ms\n",
      "Speed: 1.0ms preprocess, 66.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 77.3ms\n",
      "Speed: 2.7ms preprocess, 77.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 70.7ms\n",
      "Speed: 3.0ms preprocess, 70.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.0ms\n",
      "Speed: 1.0ms preprocess, 67.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 74.5ms\n",
      "Speed: 2.1ms preprocess, 74.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 70.0ms\n",
      "Speed: 2.5ms preprocess, 70.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 71.5ms\n",
      "Speed: 2.0ms preprocess, 71.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 69.4ms\n",
      "Speed: 2.1ms preprocess, 69.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 64.7ms\n",
      "Speed: 2.0ms preprocess, 64.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 69.0ms\n",
      "Speed: 1.0ms preprocess, 69.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 68.9ms\n",
      "Speed: 2.1ms preprocess, 68.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 68.3ms\n",
      "Speed: 2.0ms preprocess, 68.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 64.0ms\n",
      "Speed: 1.5ms preprocess, 64.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.6ms\n",
      "Speed: 2.0ms preprocess, 67.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.8ms\n",
      "Speed: 2.0ms preprocess, 65.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 70.7ms\n",
      "Speed: 3.0ms preprocess, 70.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 71.0ms\n",
      "Speed: 2.0ms preprocess, 71.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 64.0ms\n",
      "Speed: 3.0ms preprocess, 64.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.5ms\n",
      "Speed: 2.0ms preprocess, 67.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 69.5ms\n",
      "Speed: 2.1ms preprocess, 69.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.8ms\n",
      "Speed: 3.0ms preprocess, 66.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.9ms\n",
      "Speed: 2.0ms preprocess, 65.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 73.6ms\n",
      "Speed: 1.0ms preprocess, 73.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.5ms\n",
      "Speed: 1.9ms preprocess, 65.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 69.6ms\n",
      "Speed: 1.0ms preprocess, 69.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.2ms\n",
      "Speed: 2.0ms preprocess, 66.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 63.8ms\n",
      "Speed: 2.0ms preprocess, 63.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.1ms\n",
      "Speed: 2.0ms preprocess, 65.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 64.2ms\n",
      "Speed: 1.0ms preprocess, 64.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.8ms\n",
      "Speed: 2.0ms preprocess, 67.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.2ms\n",
      "Speed: 2.0ms preprocess, 67.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.9ms\n",
      "Speed: 2.1ms preprocess, 65.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.2ms\n",
      "Speed: 2.0ms preprocess, 67.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 72.3ms\n",
      "Speed: 2.0ms preprocess, 72.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.5ms\n",
      "Speed: 3.0ms preprocess, 67.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.8ms\n",
      "Speed: 2.0ms preprocess, 67.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 75.0ms\n",
      "Speed: 2.0ms preprocess, 75.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 80.0ms\n",
      "Speed: 2.0ms preprocess, 80.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 72.0ms\n",
      "Speed: 2.0ms preprocess, 72.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 69.8ms\n",
      "Speed: 2.0ms preprocess, 69.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 63.1ms\n",
      "Speed: 2.0ms preprocess, 63.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 71.6ms\n",
      "Speed: 3.0ms preprocess, 71.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 70.4ms\n",
      "Speed: 2.0ms preprocess, 70.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.7ms\n",
      "Speed: 2.0ms preprocess, 66.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 63.0ms\n",
      "Speed: 2.0ms preprocess, 63.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 92.6ms\n",
      "Speed: 2.0ms preprocess, 92.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 69.0ms\n",
      "Speed: 3.0ms preprocess, 69.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.1ms\n",
      "Speed: 2.1ms preprocess, 65.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 70.6ms\n",
      "Speed: 2.0ms preprocess, 70.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 62.8ms\n",
      "Speed: 2.4ms preprocess, 62.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.0ms\n",
      "Speed: 3.0ms preprocess, 67.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 69.8ms\n",
      "Speed: 1.0ms preprocess, 69.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.1ms\n",
      "Speed: 2.0ms preprocess, 66.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.3ms\n",
      "Speed: 1.0ms preprocess, 65.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.7ms\n",
      "Speed: 1.9ms preprocess, 67.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 64.7ms\n",
      "Speed: 3.0ms preprocess, 64.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.1ms\n",
      "Speed: 2.0ms preprocess, 66.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 70.5ms\n",
      "Speed: 1.9ms preprocess, 70.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 71.5ms\n",
      "Speed: 2.0ms preprocess, 71.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 78.0ms\n",
      "Speed: 3.1ms preprocess, 78.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 58.0ms\n",
      "Speed: 2.0ms preprocess, 58.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 74.0ms\n",
      "Speed: 3.0ms preprocess, 74.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 61.4ms\n",
      "Speed: 2.0ms preprocess, 61.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 76.1ms\n",
      "Speed: 2.0ms preprocess, 76.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.7ms\n",
      "Speed: 2.0ms preprocess, 67.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 69.1ms\n",
      "Speed: 2.0ms preprocess, 69.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 81.7ms\n",
      "Speed: 1.9ms preprocess, 81.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.6ms\n",
      "Speed: 2.0ms preprocess, 66.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 64.9ms\n",
      "Speed: 1.1ms preprocess, 64.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.4ms\n",
      "Speed: 2.1ms preprocess, 65.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 68.4ms\n",
      "Speed: 3.0ms preprocess, 68.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 72.2ms\n",
      "Speed: 2.0ms preprocess, 72.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 63.0ms\n",
      "Speed: 2.0ms preprocess, 63.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.0ms\n",
      "Speed: 2.0ms preprocess, 65.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 72.5ms\n",
      "Speed: 2.0ms preprocess, 72.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 76.7ms\n",
      "Speed: 2.0ms preprocess, 76.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 74.9ms\n",
      "Speed: 2.0ms preprocess, 74.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 69.6ms\n",
      "Speed: 2.0ms preprocess, 69.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.1ms\n",
      "Speed: 2.0ms preprocess, 67.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.3ms\n",
      "Speed: 1.9ms preprocess, 67.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 85.4ms\n",
      "Speed: 2.0ms preprocess, 85.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 63.6ms\n",
      "Speed: 2.1ms preprocess, 63.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.1ms\n",
      "Speed: 2.0ms preprocess, 65.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 69.1ms\n",
      "Speed: 2.2ms preprocess, 69.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 68.1ms\n",
      "Speed: 2.0ms preprocess, 68.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 69.9ms\n",
      "Speed: 2.0ms preprocess, 69.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 69.9ms\n",
      "Speed: 2.0ms preprocess, 69.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.2ms\n",
      "Speed: 1.9ms preprocess, 67.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 69.1ms\n",
      "Speed: 2.0ms preprocess, 69.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 71.6ms\n",
      "Speed: 2.1ms preprocess, 71.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.0ms\n",
      "Speed: 3.0ms preprocess, 65.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 68.5ms\n",
      "Speed: 2.1ms preprocess, 68.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 80.2ms\n",
      "Speed: 1.0ms preprocess, 80.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 63.9ms\n",
      "Speed: 3.0ms preprocess, 63.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 69.7ms\n",
      "Speed: 1.0ms preprocess, 69.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.9ms\n",
      "Speed: 2.9ms preprocess, 67.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 62.6ms\n",
      "Speed: 1.0ms preprocess, 62.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 64.9ms\n",
      "Speed: 2.0ms preprocess, 64.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 65.0ms\n",
      "Speed: 2.0ms preprocess, 65.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 68.8ms\n",
      "Speed: 2.0ms preprocess, 68.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 66.8ms\n",
      "Speed: 1.0ms preprocess, 66.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 64.7ms\n",
      "Speed: 1.9ms preprocess, 64.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 78.4ms\n",
      "Speed: 2.1ms preprocess, 78.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 67.5ms\n",
      "Speed: 2.0ms preprocess, 67.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 91.9ms\n",
      "Speed: 2.0ms preprocess, 91.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 67.4ms\n",
      "Speed: 2.1ms preprocess, 67.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 69.2ms\n",
      "Speed: 2.0ms preprocess, 69.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 70.7ms\n",
      "Speed: 1.9ms preprocess, 70.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 75.8ms\n",
      "Speed: 2.0ms preprocess, 75.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 81.6ms\n",
      "Speed: 1.9ms preprocess, 81.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 64.3ms\n",
      "Speed: 2.0ms preprocess, 64.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 73.7ms\n",
      "Speed: 0.9ms preprocess, 73.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 80.9ms\n",
      "Speed: 2.0ms preprocess, 80.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 73.8ms\n",
      "Speed: 2.0ms preprocess, 73.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 68.6ms\n",
      "Speed: 2.0ms preprocess, 68.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 76.0ms\n",
      "Speed: 2.0ms preprocess, 76.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 63.4ms\n",
      "Speed: 2.1ms preprocess, 63.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 71.0ms\n",
      "Speed: 2.0ms preprocess, 71.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.6ms\n",
      "Speed: 2.0ms preprocess, 67.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 76.7ms\n",
      "Speed: 3.0ms preprocess, 76.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.2ms\n",
      "Speed: 2.0ms preprocess, 65.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.0ms\n",
      "Speed: 2.0ms preprocess, 65.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 91.3ms\n",
      "Speed: 2.0ms preprocess, 91.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 69.9ms\n",
      "Speed: 1.9ms preprocess, 69.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 69.3ms\n",
      "Speed: 2.0ms preprocess, 69.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.5ms\n",
      "Speed: 2.0ms preprocess, 67.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 69.0ms\n",
      "Speed: 3.0ms preprocess, 69.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.1ms\n",
      "Speed: 2.0ms preprocess, 66.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 68.5ms\n",
      "Speed: 2.1ms preprocess, 68.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 71.9ms\n",
      "Speed: 2.0ms preprocess, 71.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 63.7ms\n",
      "Speed: 2.0ms preprocess, 63.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.0ms\n",
      "Speed: 2.0ms preprocess, 66.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.6ms\n",
      "Speed: 2.0ms preprocess, 67.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.7ms\n",
      "Speed: 2.0ms preprocess, 66.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 68.2ms\n",
      "Speed: 1.7ms preprocess, 68.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 68.0ms\n",
      "Speed: 2.0ms preprocess, 68.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 68.8ms\n",
      "Speed: 2.0ms preprocess, 68.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.6ms\n",
      "Speed: 1.0ms preprocess, 66.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 72.5ms\n",
      "Speed: 2.0ms preprocess, 72.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 67.0ms\n",
      "Speed: 2.0ms preprocess, 67.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 64.1ms\n",
      "Speed: 3.0ms preprocess, 64.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 71.0ms\n",
      "Speed: 3.0ms preprocess, 71.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 72.3ms\n",
      "Speed: 2.0ms preprocess, 72.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 71.0ms\n",
      "Speed: 3.0ms preprocess, 71.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 66.1ms\n",
      "Speed: 1.0ms preprocess, 66.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 69.1ms\n",
      "Speed: 2.0ms preprocess, 69.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 67.4ms\n",
      "Speed: 2.0ms preprocess, 67.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 72.0ms\n",
      "Speed: 2.0ms preprocess, 72.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 68.5ms\n",
      "Speed: 3.0ms preprocess, 68.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 71.4ms\n",
      "Speed: 2.0ms preprocess, 71.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 69.9ms\n",
      "Speed: 2.0ms preprocess, 69.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 80.5ms\n",
      "Speed: 3.0ms preprocess, 80.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 67.2ms\n",
      "Speed: 2.0ms preprocess, 67.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 72.5ms\n",
      "Speed: 3.0ms preprocess, 72.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 68.0ms\n",
      "Speed: 3.0ms preprocess, 68.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 68.1ms\n",
      "Speed: 2.0ms preprocess, 68.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 64.5ms\n",
      "Speed: 2.0ms preprocess, 64.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 70.0ms\n",
      "Speed: 2.0ms preprocess, 70.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 69.1ms\n",
      "Speed: 2.0ms preprocess, 69.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 67.5ms\n",
      "Speed: 3.0ms preprocess, 67.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 69.5ms\n",
      "Speed: 2.0ms preprocess, 69.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 69.8ms\n",
      "Speed: 2.0ms preprocess, 69.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 69.1ms\n",
      "Speed: 2.0ms preprocess, 69.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 66.0ms\n",
      "Speed: 2.0ms preprocess, 66.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 68.5ms\n",
      "Speed: 2.0ms preprocess, 68.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 71.0ms\n",
      "Speed: 2.0ms preprocess, 71.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 75.2ms\n",
      "Speed: 2.0ms preprocess, 75.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 64.5ms\n",
      "Speed: 2.0ms preprocess, 64.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 68.0ms\n",
      "Speed: 2.0ms preprocess, 68.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 68.0ms\n",
      "Speed: 2.0ms preprocess, 68.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 72.5ms\n",
      "Speed: 1.0ms preprocess, 72.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 64.1ms\n",
      "Speed: 2.0ms preprocess, 64.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 64.1ms\n",
      "Speed: 1.0ms preprocess, 64.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 86.5ms\n",
      "Speed: 3.0ms preprocess, 86.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 63.5ms\n",
      "Speed: 2.0ms preprocess, 63.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 69.1ms\n",
      "Speed: 2.0ms preprocess, 69.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 69.0ms\n",
      "Speed: 2.0ms preprocess, 69.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 77.5ms\n",
      "Speed: 2.0ms preprocess, 77.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 81.1ms\n",
      "Speed: 1.0ms preprocess, 81.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 83.0ms\n",
      "Speed: 2.0ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 69.1ms\n",
      "Speed: 2.0ms preprocess, 69.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 67.4ms\n",
      "Speed: 2.0ms preprocess, 67.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 72.5ms\n",
      "Speed: 2.0ms preprocess, 72.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 66.9ms\n",
      "Speed: 1.1ms preprocess, 66.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 71.2ms\n",
      "Speed: 2.0ms preprocess, 71.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 66.5ms\n",
      "Speed: 2.0ms preprocess, 66.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 72.5ms\n",
      "Speed: 1.0ms preprocess, 72.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 68.0ms\n",
      "Speed: 1.0ms preprocess, 68.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 73.0ms\n",
      "Speed: 2.0ms preprocess, 73.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 71.5ms\n",
      "Speed: 2.0ms preprocess, 71.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 67.5ms\n",
      "Speed: 1.0ms preprocess, 67.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 65.0ms\n",
      "Speed: 3.0ms preprocess, 65.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 79.5ms\n",
      "Speed: 2.0ms preprocess, 79.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 66.5ms\n",
      "Speed: 2.0ms preprocess, 66.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 65.0ms\n",
      "Speed: 2.0ms preprocess, 65.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 65.0ms\n",
      "Speed: 2.0ms preprocess, 65.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 67.5ms\n",
      "Speed: 1.0ms preprocess, 67.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 70.5ms\n",
      "Speed: 2.0ms preprocess, 70.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 70.7ms\n",
      "Speed: 2.5ms preprocess, 70.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 81.5ms\n",
      "Speed: 3.0ms preprocess, 81.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 69.1ms\n",
      "Speed: 1.0ms preprocess, 69.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 68.2ms\n",
      "Speed: 1.0ms preprocess, 68.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 69.3ms\n",
      "Speed: 2.0ms preprocess, 69.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 59.6ms\n",
      "Speed: 2.0ms preprocess, 59.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 66.9ms\n",
      "Speed: 2.0ms preprocess, 66.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 69.3ms\n",
      "Speed: 2.0ms preprocess, 69.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 68.6ms\n",
      "Speed: 2.1ms preprocess, 68.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 84.8ms\n",
      "Speed: 2.0ms preprocess, 84.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.7ms\n",
      "Speed: 1.1ms preprocess, 67.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 69.1ms\n",
      "Speed: 2.0ms preprocess, 69.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.8ms\n",
      "Speed: 1.0ms preprocess, 65.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 64.3ms\n",
      "Speed: 2.0ms preprocess, 64.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 65.8ms\n",
      "Speed: 2.0ms preprocess, 65.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 69.3ms\n",
      "Speed: 2.0ms preprocess, 69.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 76.5ms\n",
      "Speed: 2.1ms preprocess, 76.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 75.3ms\n",
      "Speed: 2.0ms preprocess, 75.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 71.1ms\n",
      "Speed: 1.0ms preprocess, 71.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 73.0ms\n",
      "Speed: 2.0ms preprocess, 73.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 67.4ms\n",
      "Speed: 1.0ms preprocess, 67.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.5ms\n",
      "Speed: 3.0ms preprocess, 67.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.6ms\n",
      "Speed: 2.0ms preprocess, 67.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 70.3ms\n",
      "Speed: 2.0ms preprocess, 70.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 68.1ms\n",
      "Speed: 2.0ms preprocess, 68.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 72.1ms\n",
      "Speed: 2.0ms preprocess, 72.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 69.4ms\n",
      "Speed: 1.0ms preprocess, 69.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 66.2ms\n",
      "Speed: 1.0ms preprocess, 66.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 69.1ms\n",
      "Speed: 2.0ms preprocess, 69.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 69.5ms\n",
      "Speed: 1.0ms preprocess, 69.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 67.8ms\n",
      "Speed: 1.0ms preprocess, 67.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 73.8ms\n",
      "Speed: 2.0ms preprocess, 73.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 65.6ms\n",
      "Speed: 2.0ms preprocess, 65.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 70.5ms\n",
      "Speed: 2.4ms preprocess, 70.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 74.4ms\n",
      "Speed: 2.0ms preprocess, 74.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 66.4ms\n",
      "Speed: 1.0ms preprocess, 66.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 73.4ms\n",
      "Speed: 1.0ms preprocess, 73.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 68.2ms\n",
      "Speed: 3.0ms preprocess, 68.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.5ms\n",
      "Speed: 2.0ms preprocess, 67.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 59.9ms\n",
      "Speed: 2.0ms preprocess, 59.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 68.5ms\n",
      "Speed: 3.0ms preprocess, 68.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 81.2ms\n",
      "Speed: 2.0ms preprocess, 81.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 63.0ms\n",
      "Speed: 2.0ms preprocess, 63.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 64.9ms\n",
      "Speed: 2.0ms preprocess, 64.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.1ms\n",
      "Speed: 2.0ms preprocess, 66.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.5ms\n",
      "Speed: 2.0ms preprocess, 65.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 79.5ms\n",
      "Speed: 3.0ms preprocess, 79.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.0ms\n",
      "Speed: 2.0ms preprocess, 66.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 68.5ms\n",
      "Speed: 2.0ms preprocess, 68.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 66.1ms\n",
      "Speed: 2.0ms preprocess, 66.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 70.0ms\n",
      "Speed: 1.5ms preprocess, 70.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 66.0ms\n",
      "Speed: 2.0ms preprocess, 66.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 84.5ms\n",
      "Speed: 2.0ms preprocess, 84.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 66.1ms\n",
      "Speed: 1.0ms preprocess, 66.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 69.0ms\n",
      "Speed: 3.0ms preprocess, 69.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 67.5ms\n",
      "Speed: 3.5ms preprocess, 67.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 68.0ms\n",
      "Speed: 2.0ms preprocess, 68.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 68.0ms\n",
      "Speed: 2.0ms preprocess, 68.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 69.0ms\n",
      "Speed: 2.0ms preprocess, 69.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 64.0ms\n",
      "Speed: 2.0ms preprocess, 64.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 68.1ms\n",
      "Speed: 1.0ms preprocess, 68.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 67.0ms\n",
      "Speed: 2.1ms preprocess, 67.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 67.0ms\n",
      "Speed: 2.0ms preprocess, 67.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 73.1ms\n",
      "Speed: 2.0ms preprocess, 73.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 88.1ms\n",
      "Speed: 2.0ms preprocess, 88.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 71.0ms\n",
      "Speed: 1.0ms preprocess, 71.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 68.0ms\n",
      "Speed: 2.0ms preprocess, 68.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.5ms\n",
      "Speed: 1.0ms preprocess, 66.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 93.0ms\n",
      "Speed: 2.0ms preprocess, 93.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 75.0ms\n",
      "Speed: 2.0ms preprocess, 75.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.5ms\n",
      "Speed: 1.0ms preprocess, 67.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 70.0ms\n",
      "Speed: 2.0ms preprocess, 70.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 93.2ms\n",
      "Speed: 2.0ms preprocess, 93.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 70.0ms\n",
      "Speed: 4.0ms preprocess, 70.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.0ms\n",
      "Speed: 2.0ms preprocess, 67.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.2ms\n",
      "Speed: 2.0ms preprocess, 65.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 68.4ms\n",
      "Speed: 3.0ms preprocess, 68.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 68.2ms\n",
      "Speed: 2.0ms preprocess, 68.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.1ms\n",
      "Speed: 2.4ms preprocess, 66.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 75.0ms\n",
      "Speed: 2.0ms preprocess, 75.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.0ms\n",
      "Speed: 1.9ms preprocess, 67.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 63.0ms\n",
      "Speed: 1.0ms preprocess, 63.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 68.6ms\n",
      "Speed: 2.0ms preprocess, 68.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 68.4ms\n",
      "Speed: 2.0ms preprocess, 68.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 64.7ms\n",
      "Speed: 3.0ms preprocess, 64.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 68.2ms\n",
      "Speed: 2.0ms preprocess, 68.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.6ms\n",
      "Speed: 2.0ms preprocess, 67.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.5ms\n",
      "Speed: 2.0ms preprocess, 66.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 68.9ms\n",
      "Speed: 1.0ms preprocess, 68.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.3ms\n",
      "Speed: 3.0ms preprocess, 66.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.7ms\n",
      "Speed: 2.3ms preprocess, 67.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.3ms\n",
      "Speed: 1.0ms preprocess, 66.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 68.4ms\n",
      "Speed: 2.0ms preprocess, 68.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 93.4ms\n",
      "Speed: 2.0ms preprocess, 93.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 62.9ms\n",
      "Speed: 3.0ms preprocess, 62.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 68.8ms\n",
      "Speed: 2.0ms preprocess, 68.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 68.6ms\n",
      "Speed: 2.0ms preprocess, 68.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 67.1ms\n",
      "Speed: 2.0ms preprocess, 67.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 72.1ms\n",
      "Speed: 2.0ms preprocess, 72.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 68.6ms\n",
      "Speed: 1.0ms preprocess, 68.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.1ms\n",
      "Speed: 2.1ms preprocess, 66.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 65.6ms\n",
      "Speed: 2.0ms preprocess, 65.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 89.1ms\n",
      "Speed: 2.0ms preprocess, 89.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 66.1ms\n",
      "Speed: 2.0ms preprocess, 66.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.2ms\n",
      "Speed: 2.0ms preprocess, 65.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 73.8ms\n",
      "Speed: 2.0ms preprocess, 73.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.4ms\n",
      "Speed: 2.0ms preprocess, 67.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 68.6ms\n",
      "Speed: 0.9ms preprocess, 68.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 64.9ms\n",
      "Speed: 1.0ms preprocess, 64.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 68.8ms\n",
      "Speed: 2.3ms preprocess, 68.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 69.3ms\n",
      "Speed: 1.0ms preprocess, 69.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 69.3ms\n",
      "Speed: 2.0ms preprocess, 69.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 74.7ms\n",
      "Speed: 1.0ms preprocess, 74.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 84.5ms\n",
      "Speed: 2.0ms preprocess, 84.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 63.0ms\n",
      "Speed: 1.0ms preprocess, 63.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 64.9ms\n",
      "Speed: 2.0ms preprocess, 64.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 67.9ms\n",
      "Speed: 2.2ms preprocess, 67.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 61.2ms\n",
      "Speed: 2.0ms preprocess, 61.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 69.6ms\n",
      "Speed: 2.2ms preprocess, 69.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 69.8ms\n",
      "Speed: 2.0ms preprocess, 69.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 71.7ms\n",
      "Speed: 2.0ms preprocess, 71.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 70.6ms\n",
      "Speed: 2.1ms preprocess, 70.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 67.8ms\n",
      "Speed: 1.4ms preprocess, 67.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 64.3ms\n",
      "Speed: 2.0ms preprocess, 64.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 65.5ms\n",
      "Speed: 2.0ms preprocess, 65.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 66.9ms\n",
      "Speed: 2.0ms preprocess, 66.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 65.6ms\n",
      "Speed: 2.0ms preprocess, 65.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 73.1ms\n",
      "Speed: 2.3ms preprocess, 73.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 76.6ms\n",
      "Speed: 2.0ms preprocess, 76.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 85.6ms\n",
      "Speed: 2.1ms preprocess, 85.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 70.4ms\n",
      "Speed: 2.0ms preprocess, 70.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 65.2ms\n",
      "Speed: 2.4ms preprocess, 65.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 67.6ms\n",
      "Speed: 2.0ms preprocess, 67.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 66.3ms\n",
      "Speed: 3.0ms preprocess, 66.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.2ms\n",
      "Speed: 2.0ms preprocess, 65.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 68.7ms\n",
      "Speed: 2.0ms preprocess, 68.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.2ms\n",
      "Speed: 2.0ms preprocess, 67.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 70.1ms\n",
      "Speed: 2.0ms preprocess, 70.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 69.1ms\n",
      "Speed: 2.0ms preprocess, 69.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 75.3ms\n",
      "Speed: 2.0ms preprocess, 75.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.9ms\n",
      "Speed: 2.0ms preprocess, 66.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 64.2ms\n",
      "Speed: 2.0ms preprocess, 64.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 68.2ms\n",
      "Speed: 2.3ms preprocess, 68.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 77.4ms\n",
      "Speed: 1.9ms preprocess, 77.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 65.0ms\n",
      "Speed: 1.5ms preprocess, 65.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 74.3ms\n",
      "Speed: 2.0ms preprocess, 74.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.5ms\n",
      "Speed: 2.0ms preprocess, 65.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 77.5ms\n",
      "Speed: 2.0ms preprocess, 77.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.6ms\n",
      "Speed: 2.0ms preprocess, 66.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 74.3ms\n",
      "Speed: 1.0ms preprocess, 74.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 70.2ms\n",
      "Speed: 2.0ms preprocess, 70.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 61.8ms\n",
      "Speed: 2.0ms preprocess, 61.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 71.3ms\n",
      "Speed: 2.0ms preprocess, 71.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 72.1ms\n",
      "Speed: 2.1ms preprocess, 72.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 70.4ms\n",
      "Speed: 2.0ms preprocess, 70.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 65.7ms\n",
      "Speed: 1.0ms preprocess, 65.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 71.3ms\n",
      "Speed: 1.1ms preprocess, 71.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 65.2ms\n",
      "Speed: 2.0ms preprocess, 65.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 68.1ms\n",
      "Speed: 1.9ms preprocess, 68.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 82.9ms\n",
      "Speed: 2.0ms preprocess, 82.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 67.0ms\n",
      "Speed: 2.0ms preprocess, 67.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 68.6ms\n",
      "Speed: 1.0ms preprocess, 68.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 81.9ms\n",
      "Speed: 1.9ms preprocess, 81.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 80.8ms\n",
      "Speed: 1.9ms preprocess, 80.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 69.6ms\n",
      "Speed: 2.0ms preprocess, 69.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 66.7ms\n",
      "Speed: 2.9ms preprocess, 66.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 77.4ms\n",
      "Speed: 2.0ms preprocess, 77.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 71.0ms\n",
      "Speed: 2.0ms preprocess, 71.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 68.2ms\n",
      "Speed: 2.0ms preprocess, 68.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 63.0ms\n",
      "Speed: 1.0ms preprocess, 63.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 75.2ms\n",
      "Speed: 2.0ms preprocess, 75.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "classes = [0, 32]\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture('basketball_1.mp4')  # replace with your video file path\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Get the default resolutions\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "\n",
    "# Define the codec and create a VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # or use 'XVID'\n",
    "out = cv2.VideoWriter('output_basketball_1.mp4', fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "\n",
    "basketball_time_1=[]\n",
    "counter = 0  # Initialize counter\n",
    "continuous_detection = False\n",
    "\n",
    "while True:\n",
    "    # Read the frame from the video file\n",
    "    _, img = cap.read()\n",
    "    \n",
    "    if not _:\n",
    "        break\n",
    "    \n",
    "    frame_no = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "    timestamp = frame_no / fps\n",
    "    \n",
    "    # Run inference on the frame\n",
    "    results = model.predict(img,classes=classes)\n",
    "    \n",
    "    detected_classes = [box.cls for box in results[0].boxes]\n",
    "    if 0 in detected_classes:\n",
    "        counter += 1  # Increment counter if class 0 is detected\n",
    "        if counter >= 10 * fps:  # Check if class 0 has been detected for at least 10 seconds\n",
    "            continuous_detection = True\n",
    "    else:\n",
    "        counter = 0  # Reset counter if class 0 is not detected\n",
    "        continuous_detection = False\n",
    "\n",
    "    if continuous_detection and 32 in detected_classes:\n",
    "        print('Basketball Court: '+'\\033[31m' + '•' + '\\033[0m')\n",
    "        basketball_time_1.append(timestamp)\n",
    "    else:\n",
    "        print('Basketball Court: '+'\\033[32m' + '•' + '\\033[0m')\n",
    "    \n",
    "    for r in results:\n",
    "        # Create an annotator for the image\n",
    "        annotator = Annotator(img)\n",
    "\n",
    "        # Get the bounding boxes\n",
    "        boxes = r.boxes\n",
    "\n",
    "        # Draw each bounding box on the image\n",
    "        for box in boxes:\n",
    "            b = box.xyxy[0]  # get box coordinates in (left, top, right, bottom) format\n",
    "            c = box.cls\n",
    "            annotator.box_label(b, model.names[int(c)])  # draw the box and label on the image\n",
    "\n",
    "        \n",
    "        # Get the annotated image\n",
    "        img = annotator.result()\n",
    "        \n",
    "        out.write(img)\n",
    "        \n",
    "    # Display the image with bounding boxes\n",
    "    cv2.imshow('YOLO V8 Detection', img)\n",
    "\n",
    "    # Break the loop if the 'space' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord(' '):\n",
    "        break\n",
    "\n",
    "# Release the video file and close all windows\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fdf047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfa451c1",
   "metadata": {},
   "source": [
    "# Basketball Court - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cee419eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 sports ball, 125.1ms\n",
      "Speed: 3.1ms preprocess, 125.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 82.7ms\n",
      "Speed: 2.5ms preprocess, 82.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 71.6ms\n",
      "Speed: 3.0ms preprocess, 71.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 62.0ms\n",
      "Speed: 2.0ms preprocess, 62.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 79.3ms\n",
      "Speed: 2.0ms preprocess, 79.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 74.7ms\n",
      "Speed: 3.5ms preprocess, 74.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 87.4ms\n",
      "Speed: 2.0ms preprocess, 87.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 69.3ms\n",
      "Speed: 2.0ms preprocess, 69.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.8ms\n",
      "Speed: 1.0ms preprocess, 67.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 75.8ms\n",
      "Speed: 1.0ms preprocess, 75.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 89.4ms\n",
      "Speed: 4.0ms preprocess, 89.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.1ms\n",
      "Speed: 2.0ms preprocess, 66.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 64.2ms\n",
      "Speed: 1.0ms preprocess, 64.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 63.7ms\n",
      "Speed: 2.0ms preprocess, 63.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 82.3ms\n",
      "Speed: 2.0ms preprocess, 82.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 83.6ms\n",
      "Speed: 3.0ms preprocess, 83.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 86.5ms\n",
      "Speed: 3.4ms preprocess, 86.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 74.0ms\n",
      "Speed: 2.0ms preprocess, 74.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 76.7ms\n",
      "Speed: 2.1ms preprocess, 76.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 76.9ms\n",
      "Speed: 2.0ms preprocess, 76.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 88.2ms\n",
      "Speed: 4.4ms preprocess, 88.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 90.4ms\n",
      "Speed: 3.0ms preprocess, 90.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 76.0ms\n",
      "Speed: 2.0ms preprocess, 76.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 79.9ms\n",
      "Speed: 3.0ms preprocess, 79.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 68.6ms\n",
      "Speed: 2.0ms preprocess, 68.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 74.7ms\n",
      "Speed: 3.0ms preprocess, 74.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 72.1ms\n",
      "Speed: 3.0ms preprocess, 72.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 75.0ms\n",
      "Speed: 1.0ms preprocess, 75.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 70.4ms\n",
      "Speed: 2.0ms preprocess, 70.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 89.4ms\n",
      "Speed: 2.0ms preprocess, 89.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 85.5ms\n",
      "Speed: 1.1ms preprocess, 85.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 79.8ms\n",
      "Speed: 2.0ms preprocess, 79.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 85.5ms\n",
      "Speed: 1.0ms preprocess, 85.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 56.9ms\n",
      "Speed: 2.0ms preprocess, 56.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 61.0ms\n",
      "Speed: 1.0ms preprocess, 61.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 72.2ms\n",
      "Speed: 1.9ms preprocess, 72.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 68.7ms\n",
      "Speed: 2.0ms preprocess, 68.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 65.4ms\n",
      "Speed: 2.0ms preprocess, 65.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 64.4ms\n",
      "Speed: 3.0ms preprocess, 64.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 74.4ms\n",
      "Speed: 3.0ms preprocess, 74.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 64.7ms\n",
      "Speed: 1.0ms preprocess, 64.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 72.0ms\n",
      "Speed: 3.0ms preprocess, 72.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 62.5ms\n",
      "Speed: 2.0ms preprocess, 62.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 72.8ms\n",
      "Speed: 2.0ms preprocess, 72.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 71.5ms\n",
      "Speed: 1.9ms preprocess, 71.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 69.2ms\n",
      "Speed: 2.0ms preprocess, 69.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 67.1ms\n",
      "Speed: 2.0ms preprocess, 67.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 70.1ms\n",
      "Speed: 2.0ms preprocess, 70.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 66.1ms\n",
      "Speed: 1.0ms preprocess, 66.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 74.1ms\n",
      "Speed: 3.5ms preprocess, 74.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 98.3ms\n",
      "Speed: 2.0ms preprocess, 98.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 64.6ms\n",
      "Speed: 3.0ms preprocess, 64.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.0ms\n",
      "Speed: 2.0ms preprocess, 66.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 63.6ms\n",
      "Speed: 3.0ms preprocess, 63.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.1ms\n",
      "Speed: 2.0ms preprocess, 66.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 63.3ms\n",
      "Speed: 3.0ms preprocess, 63.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 75.1ms\n",
      "Speed: 2.0ms preprocess, 75.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.4ms\n",
      "Speed: 2.4ms preprocess, 66.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 83.0ms\n",
      "Speed: 1.0ms preprocess, 83.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 85.7ms\n",
      "Speed: 2.1ms preprocess, 85.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.7ms\n",
      "Speed: 2.0ms preprocess, 66.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 78.3ms\n",
      "Speed: 1.9ms preprocess, 78.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 86.2ms\n",
      "Speed: 3.0ms preprocess, 86.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 79.2ms\n",
      "Speed: 1.0ms preprocess, 79.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 70.2ms\n",
      "Speed: 2.0ms preprocess, 70.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 62.7ms\n",
      "Speed: 2.0ms preprocess, 62.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.3ms\n",
      "Speed: 1.0ms preprocess, 65.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.7ms\n",
      "Speed: 2.0ms preprocess, 65.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 64.0ms\n",
      "Speed: 2.0ms preprocess, 64.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 64.0ms\n",
      "Speed: 1.0ms preprocess, 64.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.2ms\n",
      "Speed: 1.0ms preprocess, 67.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 72.7ms\n",
      "Speed: 2.0ms preprocess, 72.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.3ms\n",
      "Speed: 3.0ms preprocess, 66.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 58.6ms\n",
      "Speed: 1.9ms preprocess, 58.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 64.0ms\n",
      "Speed: 2.0ms preprocess, 64.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 75.1ms\n",
      "Speed: 1.9ms preprocess, 75.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 59.3ms\n",
      "Speed: 1.0ms preprocess, 59.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 72.7ms\n",
      "Speed: 2.0ms preprocess, 72.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 62.6ms\n",
      "Speed: 2.0ms preprocess, 62.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.8ms\n",
      "Speed: 2.0ms preprocess, 65.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.8ms\n",
      "Speed: 2.0ms preprocess, 66.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 83.6ms\n",
      "Speed: 2.0ms preprocess, 83.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 64.3ms\n",
      "Speed: 1.9ms preprocess, 64.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 71.9ms\n",
      "Speed: 2.0ms preprocess, 71.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.0ms\n",
      "Speed: 2.0ms preprocess, 66.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 64.5ms\n",
      "Speed: 2.0ms preprocess, 64.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 64.8ms\n",
      "Speed: 2.0ms preprocess, 64.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 70.2ms\n",
      "Speed: 2.0ms preprocess, 70.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 84.5ms\n",
      "Speed: 3.0ms preprocess, 84.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 68.3ms\n",
      "Speed: 2.0ms preprocess, 68.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 77.7ms\n",
      "Speed: 2.0ms preprocess, 77.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 63.4ms\n",
      "Speed: 2.0ms preprocess, 63.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.3ms\n",
      "Speed: 2.0ms preprocess, 66.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 64.5ms\n",
      "Speed: 1.7ms preprocess, 64.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 63.8ms\n",
      "Speed: 2.0ms preprocess, 63.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 69.7ms\n",
      "Speed: 2.0ms preprocess, 69.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 71.9ms\n",
      "Speed: 1.0ms preprocess, 71.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 76.8ms\n",
      "Speed: 3.0ms preprocess, 76.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 63.1ms\n",
      "Speed: 3.0ms preprocess, 63.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 63.6ms\n",
      "Speed: 3.0ms preprocess, 63.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 70.7ms\n",
      "Speed: 2.0ms preprocess, 70.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 64.7ms\n",
      "Speed: 1.9ms preprocess, 64.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.8ms\n",
      "Speed: 2.0ms preprocess, 67.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 68.1ms\n",
      "Speed: 2.0ms preprocess, 68.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 71.6ms\n",
      "Speed: 2.0ms preprocess, 71.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.7ms\n",
      "Speed: 1.9ms preprocess, 65.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 60.6ms\n",
      "Speed: 2.0ms preprocess, 60.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 73.1ms\n",
      "Speed: 1.0ms preprocess, 73.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 62.1ms\n",
      "Speed: 1.0ms preprocess, 62.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 70.1ms\n",
      "Speed: 1.9ms preprocess, 70.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.5ms\n",
      "Speed: 2.0ms preprocess, 67.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 71.3ms\n",
      "Speed: 2.0ms preprocess, 71.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 62.2ms\n",
      "Speed: 2.0ms preprocess, 62.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.3ms\n",
      "Speed: 2.0ms preprocess, 65.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 61.5ms\n",
      "Speed: 2.0ms preprocess, 61.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 69.0ms\n",
      "Speed: 2.0ms preprocess, 69.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 64.0ms\n",
      "Speed: 2.0ms preprocess, 64.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.1ms\n",
      "Speed: 2.0ms preprocess, 65.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 63.1ms\n",
      "Speed: 2.0ms preprocess, 63.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 68.2ms\n",
      "Speed: 2.0ms preprocess, 68.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 88.0ms\n",
      "Speed: 2.0ms preprocess, 88.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.2ms\n",
      "Speed: 2.0ms preprocess, 67.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 74.5ms\n",
      "Speed: 1.0ms preprocess, 74.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.0ms\n",
      "Speed: 2.0ms preprocess, 66.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.0ms\n",
      "Speed: 2.0ms preprocess, 66.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.2ms\n",
      "Speed: 2.0ms preprocess, 65.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 71.1ms\n",
      "Speed: 2.0ms preprocess, 71.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.1ms\n",
      "Speed: 2.0ms preprocess, 65.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 75.7ms\n",
      "Speed: 2.0ms preprocess, 75.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.3ms\n",
      "Speed: 3.0ms preprocess, 66.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 79.1ms\n",
      "Speed: 2.0ms preprocess, 79.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 70.0ms\n",
      "Speed: 1.0ms preprocess, 70.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 72.0ms\n",
      "Speed: 2.0ms preprocess, 72.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 67.5ms\n",
      "Speed: 3.0ms preprocess, 67.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 79.5ms\n",
      "Speed: 2.0ms preprocess, 79.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.0ms\n",
      "Speed: 2.0ms preprocess, 65.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 77.0ms\n",
      "Speed: 2.0ms preprocess, 77.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 75.3ms\n",
      "Speed: 2.0ms preprocess, 75.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 81.0ms\n",
      "Speed: 2.0ms preprocess, 81.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 77.1ms\n",
      "Speed: 2.4ms preprocess, 77.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 80.2ms\n",
      "Speed: 2.0ms preprocess, 80.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 72.0ms\n",
      "Speed: 2.0ms preprocess, 72.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 69.5ms\n",
      "Speed: 2.0ms preprocess, 69.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 76.4ms\n",
      "Speed: 1.9ms preprocess, 76.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 80.5ms\n",
      "Speed: 3.0ms preprocess, 80.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 65.2ms\n",
      "Speed: 2.0ms preprocess, 65.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 61.0ms\n",
      "Speed: 4.1ms preprocess, 61.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 66.4ms\n",
      "Speed: 2.0ms preprocess, 66.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 62.0ms\n",
      "Speed: 2.0ms preprocess, 62.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 65.0ms\n",
      "Speed: 2.0ms preprocess, 65.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 64.8ms\n",
      "Speed: 1.0ms preprocess, 64.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.9ms\n",
      "Speed: 2.0ms preprocess, 65.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 61.0ms\n",
      "Speed: 3.0ms preprocess, 61.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 81.5ms\n",
      "Speed: 3.3ms preprocess, 81.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 83.4ms\n",
      "Speed: 2.0ms preprocess, 83.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 person, 64.3ms\n",
      "Speed: 1.0ms preprocess, 64.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 76.5ms\n",
      "Speed: 2.4ms preprocess, 76.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 65.7ms\n",
      "Speed: 2.9ms preprocess, 65.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.9ms\n",
      "Speed: 1.0ms preprocess, 65.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.2ms\n",
      "Speed: 1.9ms preprocess, 65.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 71.9ms\n",
      "Speed: 2.9ms preprocess, 71.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 66.2ms\n",
      "Speed: 2.0ms preprocess, 66.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 73.5ms\n",
      "Speed: 3.0ms preprocess, 73.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 67.3ms\n",
      "Speed: 2.0ms preprocess, 67.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 67.6ms\n",
      "Speed: 2.0ms preprocess, 67.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 73.8ms\n",
      "Speed: 3.4ms preprocess, 73.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 70.3ms\n",
      "Speed: 2.9ms preprocess, 70.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 65.1ms\n",
      "Speed: 2.0ms preprocess, 65.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 69.1ms\n",
      "Speed: 1.0ms preprocess, 69.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 90.3ms\n",
      "Speed: 2.0ms preprocess, 90.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 71.0ms\n",
      "Speed: 1.0ms preprocess, 71.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 66.5ms\n",
      "Speed: 2.0ms preprocess, 66.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 2 sports balls, 69.1ms\n",
      "Speed: 1.2ms preprocess, 69.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 2 sports balls, 67.5ms\n",
      "Speed: 3.0ms preprocess, 67.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 67.9ms\n",
      "Speed: 2.2ms preprocess, 67.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 2 sports balls, 71.4ms\n",
      "Speed: 2.0ms preprocess, 71.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 2 sports balls, 79.0ms\n",
      "Speed: 2.1ms preprocess, 79.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 64.5ms\n",
      "Speed: 2.0ms preprocess, 64.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 69.5ms\n",
      "Speed: 2.0ms preprocess, 69.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 64.4ms\n",
      "Speed: 1.9ms preprocess, 64.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 71.5ms\n",
      "Speed: 1.9ms preprocess, 71.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 78.4ms\n",
      "Speed: 3.0ms preprocess, 78.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 67.0ms\n",
      "Speed: 1.0ms preprocess, 67.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 58.4ms\n",
      "Speed: 2.0ms preprocess, 58.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 65.4ms\n",
      "Speed: 1.0ms preprocess, 65.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 68.9ms\n",
      "Speed: 1.0ms preprocess, 68.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 72.5ms\n",
      "Speed: 2.1ms preprocess, 72.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 58.0ms\n",
      "Speed: 3.0ms preprocess, 58.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 63.0ms\n",
      "Speed: 3.0ms preprocess, 63.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 64.3ms\n",
      "Speed: 1.0ms preprocess, 64.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.6ms\n",
      "Speed: 2.0ms preprocess, 67.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 80.0ms\n",
      "Speed: 1.0ms preprocess, 80.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 65.3ms\n",
      "Speed: 1.0ms preprocess, 65.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 62.2ms\n",
      "Speed: 2.0ms preprocess, 62.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 80.6ms\n",
      "Speed: 2.0ms preprocess, 80.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 79.6ms\n",
      "Speed: 2.0ms preprocess, 79.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.5ms\n",
      "Speed: 2.0ms preprocess, 67.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 89.5ms\n",
      "Speed: 3.0ms preprocess, 89.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 68.5ms\n",
      "Speed: 2.0ms preprocess, 68.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 67.2ms\n",
      "Speed: 3.0ms preprocess, 67.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 73.0ms\n",
      "Speed: 1.9ms preprocess, 73.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 79.3ms\n",
      "Speed: 2.0ms preprocess, 79.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 63.0ms\n",
      "Speed: 3.0ms preprocess, 63.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 64.5ms\n",
      "Speed: 1.0ms preprocess, 64.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 63.9ms\n",
      "Speed: 3.9ms preprocess, 63.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 81.1ms\n",
      "Speed: 3.0ms preprocess, 81.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 70.8ms\n",
      "Speed: 2.0ms preprocess, 70.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 84.9ms\n",
      "Speed: 3.0ms preprocess, 84.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 64.6ms\n",
      "Speed: 1.0ms preprocess, 64.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 77.3ms\n",
      "Speed: 2.0ms preprocess, 77.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 71.3ms\n",
      "Speed: 2.0ms preprocess, 71.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 62.6ms\n",
      "Speed: 2.0ms preprocess, 62.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 68.6ms\n",
      "Speed: 2.0ms preprocess, 68.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 78.7ms\n",
      "Speed: 2.0ms preprocess, 78.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 84.0ms\n",
      "Speed: 2.0ms preprocess, 84.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 63.5ms\n",
      "Speed: 2.0ms preprocess, 63.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 71.0ms\n",
      "Speed: 2.0ms preprocess, 71.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 73.4ms\n",
      "Speed: 2.0ms preprocess, 73.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 89.9ms\n",
      "Speed: 2.0ms preprocess, 89.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 68.0ms\n",
      "Speed: 2.0ms preprocess, 68.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 63.1ms\n",
      "Speed: 1.0ms preprocess, 63.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 61.2ms\n",
      "Speed: 2.0ms preprocess, 61.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 64.5ms\n",
      "Speed: 2.0ms preprocess, 64.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 59.8ms\n",
      "Speed: 2.0ms preprocess, 59.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 71.4ms\n",
      "Speed: 2.0ms preprocess, 71.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 58.0ms\n",
      "Speed: 2.1ms preprocess, 58.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 59.9ms\n",
      "Speed: 2.0ms preprocess, 59.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 91.8ms\n",
      "Speed: 3.0ms preprocess, 91.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 69.6ms\n",
      "Speed: 2.0ms preprocess, 69.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 64.0ms\n",
      "Speed: 2.0ms preprocess, 64.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 63.9ms\n",
      "Speed: 1.0ms preprocess, 63.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 64.7ms\n",
      "Speed: 1.0ms preprocess, 64.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.5ms\n",
      "Speed: 2.3ms preprocess, 67.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.0ms\n",
      "Speed: 2.0ms preprocess, 67.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.7ms\n",
      "Speed: 2.0ms preprocess, 65.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 64.9ms\n",
      "Speed: 2.0ms preprocess, 64.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 73.2ms\n",
      "Speed: 2.0ms preprocess, 73.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 69.7ms\n",
      "Speed: 1.0ms preprocess, 69.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 81.9ms\n",
      "Speed: 2.0ms preprocess, 81.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 64.8ms\n",
      "Speed: 2.0ms preprocess, 64.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 64.9ms\n",
      "Speed: 2.0ms preprocess, 64.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 68.1ms\n",
      "Speed: 3.3ms preprocess, 68.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 67.6ms\n",
      "Speed: 2.0ms preprocess, 67.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 63.9ms\n",
      "Speed: 2.0ms preprocess, 63.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 71.2ms\n",
      "Speed: 1.1ms preprocess, 71.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.8ms\n",
      "Speed: 3.0ms preprocess, 65.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 71.7ms\n",
      "Speed: 2.0ms preprocess, 71.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 69.0ms\n",
      "Speed: 2.0ms preprocess, 69.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.8ms\n",
      "Speed: 2.0ms preprocess, 67.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 64.9ms\n",
      "Speed: 2.0ms preprocess, 64.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 70.4ms\n",
      "Speed: 2.0ms preprocess, 70.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.8ms\n",
      "Speed: 2.0ms preprocess, 65.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 68.7ms\n",
      "Speed: 2.0ms preprocess, 68.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 70.4ms\n",
      "Speed: 3.0ms preprocess, 70.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 72.5ms\n",
      "Speed: 3.0ms preprocess, 72.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 69.8ms\n",
      "Speed: 1.5ms preprocess, 69.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 68.9ms\n",
      "Speed: 2.0ms preprocess, 68.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.9ms\n",
      "Speed: 2.0ms preprocess, 65.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 64.3ms\n",
      "Speed: 1.0ms preprocess, 64.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 62.0ms\n",
      "Speed: 2.0ms preprocess, 62.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 71.7ms\n",
      "Speed: 2.1ms preprocess, 71.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.7ms\n",
      "Speed: 3.0ms preprocess, 65.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 68.4ms\n",
      "Speed: 2.0ms preprocess, 68.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.4ms\n",
      "Speed: 3.0ms preprocess, 65.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 64.8ms\n",
      "Speed: 2.0ms preprocess, 64.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 64.1ms\n",
      "Speed: 1.0ms preprocess, 64.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 73.7ms\n",
      "Speed: 2.9ms preprocess, 73.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.8ms\n",
      "Speed: 2.0ms preprocess, 66.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 61.9ms\n",
      "Speed: 2.0ms preprocess, 61.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 69.5ms\n",
      "Speed: 1.0ms preprocess, 69.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 72.8ms\n",
      "Speed: 2.0ms preprocess, 72.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 71.2ms\n",
      "Speed: 2.0ms preprocess, 71.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.6ms\n",
      "Speed: 2.0ms preprocess, 67.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 69.1ms\n",
      "Speed: 2.0ms preprocess, 69.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 69.2ms\n",
      "Speed: 2.0ms preprocess, 69.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 85.7ms\n",
      "Speed: 2.0ms preprocess, 85.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 89.9ms\n",
      "Speed: 2.0ms preprocess, 89.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 64.7ms\n",
      "Speed: 2.0ms preprocess, 64.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.1ms\n",
      "Speed: 2.0ms preprocess, 65.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 69.4ms\n",
      "Speed: 2.0ms preprocess, 69.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 71.5ms\n",
      "Speed: 1.9ms preprocess, 71.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.3ms\n",
      "Speed: 2.1ms preprocess, 65.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.7ms\n",
      "Speed: 2.0ms preprocess, 66.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.2ms\n",
      "Speed: 2.9ms preprocess, 66.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 84.0ms\n",
      "Speed: 2.0ms preprocess, 84.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 71.1ms\n",
      "Speed: 1.0ms preprocess, 71.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 69.4ms\n",
      "Speed: 2.0ms preprocess, 69.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.7ms\n",
      "Speed: 1.9ms preprocess, 67.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 63.1ms\n",
      "Speed: 1.9ms preprocess, 63.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 83.9ms\n",
      "Speed: 2.0ms preprocess, 83.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 87.3ms\n",
      "Speed: 1.9ms preprocess, 87.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 63.8ms\n",
      "Speed: 2.0ms preprocess, 63.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 67.7ms\n",
      "Speed: 1.0ms preprocess, 67.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 62.7ms\n",
      "Speed: 1.0ms preprocess, 62.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 63.5ms\n",
      "Speed: 2.0ms preprocess, 63.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 72.7ms\n",
      "Speed: 2.0ms preprocess, 72.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 61.0ms\n",
      "Speed: 1.0ms preprocess, 61.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.4ms\n",
      "Speed: 1.0ms preprocess, 66.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 64.5ms\n",
      "Speed: 1.9ms preprocess, 64.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 61.6ms\n",
      "Speed: 2.0ms preprocess, 61.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.1ms\n",
      "Speed: 3.0ms preprocess, 67.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 61.0ms\n",
      "Speed: 2.0ms preprocess, 61.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 64.4ms\n",
      "Speed: 3.0ms preprocess, 64.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 65.0ms\n",
      "Speed: 2.1ms preprocess, 65.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 61.6ms\n",
      "Speed: 2.0ms preprocess, 61.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 73.2ms\n",
      "Speed: 3.0ms preprocess, 73.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 68.1ms\n",
      "Speed: 2.0ms preprocess, 68.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 71.0ms\n",
      "Speed: 1.6ms preprocess, 71.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 64.9ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 2.0ms preprocess, 64.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 63.3ms\n",
      "Speed: 2.0ms preprocess, 63.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.1ms\n",
      "Speed: 2.0ms preprocess, 67.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 67.5ms\n",
      "Speed: 3.0ms preprocess, 67.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 76.6ms\n",
      "Speed: 1.0ms preprocess, 76.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 62.2ms\n",
      "Speed: 2.0ms preprocess, 62.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 66.5ms\n",
      "Speed: 2.0ms preprocess, 66.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 75.7ms\n",
      "Speed: 2.0ms preprocess, 75.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 65.7ms\n",
      "Speed: 1.0ms preprocess, 65.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 81.7ms\n",
      "Speed: 1.9ms preprocess, 81.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 63.3ms\n",
      "Speed: 3.0ms preprocess, 63.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 69.2ms\n",
      "Speed: 2.0ms preprocess, 69.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 69.5ms\n",
      "Speed: 2.1ms preprocess, 69.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 70.7ms\n",
      "Speed: 2.0ms preprocess, 70.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 77.0ms\n",
      "Speed: 3.0ms preprocess, 77.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 72.8ms\n",
      "Speed: 2.0ms preprocess, 72.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 98.6ms\n",
      "Speed: 2.0ms preprocess, 98.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 103.6ms\n",
      "Speed: 5.2ms preprocess, 103.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 80.8ms\n",
      "Speed: 1.0ms preprocess, 80.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 68.7ms\n",
      "Speed: 3.0ms preprocess, 68.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 113.9ms\n",
      "Speed: 5.0ms preprocess, 113.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 67.0ms\n",
      "Speed: 1.0ms preprocess, 67.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 73.5ms\n",
      "Speed: 2.0ms preprocess, 73.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 72.1ms\n",
      "Speed: 2.0ms preprocess, 72.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 67.3ms\n",
      "Speed: 2.0ms preprocess, 67.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 74.4ms\n",
      "Speed: 2.0ms preprocess, 74.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 68.8ms\n",
      "Speed: 2.0ms preprocess, 68.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 71.6ms\n",
      "Speed: 2.0ms preprocess, 71.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 96.2ms\n",
      "Speed: 1.0ms preprocess, 96.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 89.4ms\n",
      "Speed: 5.0ms preprocess, 89.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 89.0ms\n",
      "Speed: 4.0ms preprocess, 89.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 74.5ms\n",
      "Speed: 2.0ms preprocess, 74.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 69.1ms\n",
      "Speed: 2.0ms preprocess, 69.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 88.5ms\n",
      "Speed: 1.0ms preprocess, 88.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 78.2ms\n",
      "Speed: 4.0ms preprocess, 78.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 65.0ms\n",
      "Speed: 1.0ms preprocess, 65.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 79.5ms\n",
      "Speed: 1.0ms preprocess, 79.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 127.1ms\n",
      "Speed: 3.0ms preprocess, 127.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 74.0ms\n",
      "Speed: 2.0ms preprocess, 74.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 75.0ms\n",
      "Speed: 3.0ms preprocess, 75.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 73.1ms\n",
      "Speed: 2.0ms preprocess, 73.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 70.4ms\n",
      "Speed: 2.1ms preprocess, 70.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 76.5ms\n",
      "Speed: 2.0ms preprocess, 76.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 71.0ms\n",
      "Speed: 2.0ms preprocess, 71.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 74.5ms\n",
      "Speed: 3.0ms preprocess, 74.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 81.8ms\n",
      "Speed: 2.0ms preprocess, 81.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 74.0ms\n",
      "Speed: 2.0ms preprocess, 74.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 91.5ms\n",
      "Speed: 2.9ms preprocess, 91.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 80.1ms\n",
      "Speed: 2.0ms preprocess, 80.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 72.0ms\n",
      "Speed: 2.0ms preprocess, 72.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 90.1ms\n",
      "Speed: 1.0ms preprocess, 90.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 158.7ms\n",
      "Speed: 5.0ms preprocess, 158.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 145.8ms\n",
      "Speed: 4.0ms preprocess, 145.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 139.3ms\n",
      "Speed: 4.0ms preprocess, 139.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 159.8ms\n",
      "Speed: 4.0ms preprocess, 159.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 143.0ms\n",
      "Speed: 4.9ms preprocess, 143.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 167.4ms\n",
      "Speed: 5.0ms preprocess, 167.4ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 2 sports balls, 135.7ms\n",
      "Speed: 4.9ms preprocess, 135.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 183.7ms\n",
      "Speed: 3.7ms preprocess, 183.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 142.0ms\n",
      "Speed: 4.0ms preprocess, 142.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 149.0ms\n",
      "Speed: 4.4ms preprocess, 149.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 149.5ms\n",
      "Speed: 5.4ms preprocess, 149.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 156.6ms\n",
      "Speed: 4.9ms preprocess, 156.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 140.9ms\n",
      "Speed: 4.9ms preprocess, 140.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 149.7ms\n",
      "Speed: 5.9ms preprocess, 149.7ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 150.0ms\n",
      "Speed: 3.3ms preprocess, 150.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 151.4ms\n",
      "Speed: 4.9ms preprocess, 151.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 152.2ms\n",
      "Speed: 3.1ms preprocess, 152.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 157.4ms\n",
      "Speed: 4.5ms preprocess, 157.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 130.3ms\n",
      "Speed: 4.5ms preprocess, 130.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 138.1ms\n",
      "Speed: 3.9ms preprocess, 138.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 132.0ms\n",
      "Speed: 5.1ms preprocess, 132.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 153.6ms\n",
      "Speed: 5.0ms preprocess, 153.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 133.7ms\n",
      "Speed: 5.1ms preprocess, 133.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 163.7ms\n",
      "Speed: 5.0ms preprocess, 163.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 157.4ms\n",
      "Speed: 5.0ms preprocess, 157.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 159.2ms\n",
      "Speed: 2.5ms preprocess, 159.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 128.4ms\n",
      "Speed: 3.0ms preprocess, 128.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 127.1ms\n",
      "Speed: 4.0ms preprocess, 127.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 152.0ms\n",
      "Speed: 5.0ms preprocess, 152.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 163.5ms\n",
      "Speed: 4.0ms preprocess, 163.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 137.0ms\n",
      "Speed: 5.0ms preprocess, 137.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 152.8ms\n",
      "Speed: 3.9ms preprocess, 152.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 161.3ms\n",
      "Speed: 5.0ms preprocess, 161.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 138.7ms\n",
      "Speed: 4.0ms preprocess, 138.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 135.5ms\n",
      "Speed: 4.0ms preprocess, 135.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 151.4ms\n",
      "Speed: 3.9ms preprocess, 151.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 145.8ms\n",
      "Speed: 3.0ms preprocess, 145.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 161.0ms\n",
      "Speed: 5.5ms preprocess, 161.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 146.8ms\n",
      "Speed: 4.3ms preprocess, 146.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 116.9ms\n",
      "Speed: 3.9ms preprocess, 116.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 113.0ms\n",
      "Speed: 4.0ms preprocess, 113.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 118.3ms\n",
      "Speed: 4.0ms preprocess, 118.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 114.5ms\n",
      "Speed: 4.4ms preprocess, 114.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 136.8ms\n",
      "Speed: 3.9ms preprocess, 136.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 166.6ms\n",
      "Speed: 3.0ms preprocess, 166.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 151.6ms\n",
      "Speed: 4.9ms preprocess, 151.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 149.5ms\n",
      "Speed: 2.3ms preprocess, 149.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 163.2ms\n",
      "Speed: 4.0ms preprocess, 163.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 163.1ms\n",
      "Speed: 4.0ms preprocess, 163.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 212.3ms\n",
      "Speed: 9.0ms preprocess, 212.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 165.3ms\n",
      "Speed: 5.3ms preprocess, 165.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 213.5ms\n",
      "Speed: 8.5ms preprocess, 213.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 166.5ms\n",
      "Speed: 4.0ms preprocess, 166.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 164.5ms\n",
      "Speed: 5.0ms preprocess, 164.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 165.7ms\n",
      "Speed: 4.0ms preprocess, 165.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 212.9ms\n",
      "Speed: 6.0ms preprocess, 212.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 162.8ms\n",
      "Speed: 6.0ms preprocess, 162.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 170.2ms\n",
      "Speed: 5.0ms preprocess, 170.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 148.6ms\n",
      "Speed: 5.0ms preprocess, 148.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 209.7ms\n",
      "Speed: 2.9ms preprocess, 209.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 158.4ms\n",
      "Speed: 4.0ms preprocess, 158.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 224.5ms\n",
      "Speed: 7.0ms preprocess, 224.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 121.5ms\n",
      "Speed: 3.0ms preprocess, 121.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 150.9ms\n",
      "Speed: 4.0ms preprocess, 150.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 159.5ms\n",
      "Speed: 5.0ms preprocess, 159.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 155.6ms\n",
      "Speed: 5.0ms preprocess, 155.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 167.3ms\n",
      "Speed: 5.0ms preprocess, 167.3ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 150.2ms\n",
      "Speed: 5.0ms preprocess, 150.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 169.2ms\n",
      "Speed: 5.0ms preprocess, 169.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 161.7ms\n",
      "Speed: 4.0ms preprocess, 161.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 144.1ms\n",
      "Speed: 4.0ms preprocess, 144.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 157.6ms\n",
      "Speed: 4.0ms preprocess, 157.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 167.8ms\n",
      "Speed: 5.0ms preprocess, 167.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 160.8ms\n",
      "Speed: 5.0ms preprocess, 160.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 168.3ms\n",
      "Speed: 5.0ms preprocess, 168.3ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 146.3ms\n",
      "Speed: 4.0ms preprocess, 146.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 180.6ms\n",
      "Speed: 6.0ms preprocess, 180.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 164.6ms\n",
      "Speed: 4.5ms preprocess, 164.6ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 171.5ms\n",
      "Speed: 6.0ms preprocess, 171.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 158.9ms\n",
      "Speed: 5.0ms preprocess, 158.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 164.0ms\n",
      "Speed: 5.0ms preprocess, 164.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 146.0ms\n",
      "Speed: 3.5ms preprocess, 146.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 216.5ms\n",
      "Speed: 6.1ms preprocess, 216.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 162.8ms\n",
      "Speed: 4.0ms preprocess, 162.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 164.8ms\n",
      "Speed: 5.9ms preprocess, 164.8ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 162.9ms\n",
      "Speed: 4.1ms preprocess, 162.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 245.7ms\n",
      "Speed: 4.1ms preprocess, 245.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 249.7ms\n",
      "Speed: 4.0ms preprocess, 249.7ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 146.6ms\n",
      "Speed: 4.0ms preprocess, 146.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 164.6ms\n",
      "Speed: 4.9ms preprocess, 164.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 161.6ms\n",
      "Speed: 5.1ms preprocess, 161.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 227.1ms\n",
      "Speed: 4.1ms preprocess, 227.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 153.9ms\n",
      "Speed: 4.1ms preprocess, 153.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 170.5ms\n",
      "Speed: 4.0ms preprocess, 170.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 158.2ms\n",
      "Speed: 4.9ms preprocess, 158.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 220.1ms\n",
      "Speed: 4.9ms preprocess, 220.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 178.7ms\n",
      "Speed: 6.9ms preprocess, 178.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 157.9ms\n",
      "Speed: 5.0ms preprocess, 157.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 156.7ms\n",
      "Speed: 5.0ms preprocess, 156.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 159.8ms\n",
      "Speed: 4.7ms preprocess, 159.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 152.6ms\n",
      "Speed: 5.0ms preprocess, 152.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 203.4ms\n",
      "Speed: 4.9ms preprocess, 203.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 159.9ms\n",
      "Speed: 4.9ms preprocess, 159.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 161.3ms\n",
      "Speed: 4.0ms preprocess, 161.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 163.4ms\n",
      "Speed: 5.0ms preprocess, 163.4ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 246.8ms\n",
      "Speed: 4.9ms preprocess, 246.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 161.8ms\n",
      "Speed: 4.0ms preprocess, 161.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 162.6ms\n",
      "Speed: 4.9ms preprocess, 162.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 185.4ms\n",
      "Speed: 7.0ms preprocess, 185.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 158.1ms\n",
      "Speed: 4.9ms preprocess, 158.1ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 127.6ms\n",
      "Speed: 3.0ms preprocess, 127.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 103.6ms\n",
      "Speed: 3.0ms preprocess, 103.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 117.3ms\n",
      "Speed: 3.0ms preprocess, 117.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 118.5ms\n",
      "Speed: 4.5ms preprocess, 118.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 146.2ms\n",
      "Speed: 4.0ms preprocess, 146.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 146.3ms\n",
      "Speed: 3.9ms preprocess, 146.3ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 121.3ms\n",
      "Speed: 3.0ms preprocess, 121.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 149.0ms\n",
      "Speed: 7.0ms preprocess, 149.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 135.4ms\n",
      "Speed: 3.0ms preprocess, 135.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 146.3ms\n",
      "Speed: 4.0ms preprocess, 146.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 153.7ms\n",
      "Speed: 3.9ms preprocess, 153.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 186.0ms\n",
      "Speed: 3.0ms preprocess, 186.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 153.6ms\n",
      "Speed: 5.0ms preprocess, 153.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 159.6ms\n",
      "Speed: 3.0ms preprocess, 159.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 159.6ms\n",
      "Speed: 5.0ms preprocess, 159.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 142.7ms\n",
      "Speed: 4.0ms preprocess, 142.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 165.9ms\n",
      "Speed: 4.0ms preprocess, 165.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 201.0ms\n",
      "Speed: 5.0ms preprocess, 201.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 152.0ms\n",
      "Speed: 4.0ms preprocess, 152.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 128.0ms\n",
      "Speed: 3.3ms preprocess, 128.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 134.0ms\n",
      "Speed: 4.0ms preprocess, 134.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 118.7ms\n",
      "Speed: 4.0ms preprocess, 118.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 171.6ms\n",
      "Speed: 4.0ms preprocess, 171.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 152.7ms\n",
      "Speed: 5.0ms preprocess, 152.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 155.0ms\n",
      "Speed: 4.9ms preprocess, 155.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 169.9ms\n",
      "Speed: 4.0ms preprocess, 169.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 189.8ms\n",
      "Speed: 7.0ms preprocess, 189.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 181.6ms\n",
      "Speed: 4.0ms preprocess, 181.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 (no detections), 140.9ms\n",
      "Speed: 5.0ms preprocess, 140.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 (no detections), 162.5ms\n",
      "Speed: 5.0ms preprocess, 162.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 (no detections), 248.0ms\n",
      "Speed: 4.9ms preprocess, 248.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 (no detections), 151.8ms\n",
      "Speed: 4.9ms preprocess, 151.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 (no detections), 128.7ms\n",
      "Speed: 4.0ms preprocess, 128.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 (no detections), 157.9ms\n",
      "Speed: 4.0ms preprocess, 157.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 (no detections), 150.9ms\n",
      "Speed: 3.9ms preprocess, 150.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 (no detections), 169.7ms\n",
      "Speed: 4.9ms preprocess, 169.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 (no detections), 185.8ms\n",
      "Speed: 4.9ms preprocess, 185.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 (no detections), 168.3ms\n",
      "Speed: 3.5ms preprocess, 168.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 (no detections), 146.3ms\n",
      "Speed: 4.0ms preprocess, 146.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 (no detections), 133.1ms\n",
      "Speed: 5.0ms preprocess, 133.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 (no detections), 202.5ms\n",
      "Speed: 7.0ms preprocess, 202.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 (no detections), 146.5ms\n",
      "Speed: 4.0ms preprocess, 146.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 (no detections), 170.4ms\n",
      "Speed: 4.9ms preprocess, 170.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 (no detections), 163.7ms\n",
      "Speed: 5.0ms preprocess, 163.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 (no detections), 189.5ms\n",
      "Speed: 5.9ms preprocess, 189.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 (no detections), 228.1ms\n",
      "Speed: 6.9ms preprocess, 228.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 (no detections), 157.8ms\n",
      "Speed: 4.9ms preprocess, 157.8ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 (no detections), 256.8ms\n",
      "Speed: 6.0ms preprocess, 256.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 (no detections), 170.6ms\n",
      "Speed: 5.1ms preprocess, 170.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 (no detections), 157.7ms\n",
      "Speed: 4.5ms preprocess, 157.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 (no detections), 249.7ms\n",
      "Speed: 6.9ms preprocess, 249.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 (no detections), 155.4ms\n",
      "Speed: 4.0ms preprocess, 155.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 (no detections), 172.0ms\n",
      "Speed: 4.0ms preprocess, 172.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 (no detections), 165.2ms\n",
      "Speed: 5.0ms preprocess, 165.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 (no detections), 195.3ms\n",
      "Speed: 6.0ms preprocess, 195.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 (no detections), 170.8ms\n",
      "Speed: 7.0ms preprocess, 170.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 (no detections), 251.9ms\n",
      "Speed: 5.0ms preprocess, 251.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 (no detections), 172.6ms\n",
      "Speed: 4.0ms preprocess, 172.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 (no detections), 106.0ms\n",
      "Speed: 3.0ms preprocess, 106.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 (no detections), 128.6ms\n",
      "Speed: 3.0ms preprocess, 128.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 (no detections), 146.9ms\n",
      "Speed: 3.0ms preprocess, 146.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 (no detections), 121.9ms\n",
      "Speed: 3.0ms preprocess, 121.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 (no detections), 146.8ms\n",
      "Speed: 4.1ms preprocess, 146.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 (no detections), 176.2ms\n",
      "Speed: 4.0ms preprocess, 176.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 (no detections), 199.7ms\n",
      "Speed: 5.0ms preprocess, 199.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 (no detections), 170.7ms\n",
      "Speed: 5.5ms preprocess, 170.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Basketball Court: \u001b[32m•\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "classes = [0, 32]\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture('basketball_2.mp4')  # replace with your video file path\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Get the default resolutions\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "\n",
    "# Define the codec and create a VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # or use 'XVID'\n",
    "out = cv2.VideoWriter('output_basketball_2.mp4', fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "\n",
    "basketball_time_2=[]\n",
    "counter = 0  # Initialize counter\n",
    "continuous_detection = False\n",
    "\n",
    "while True:\n",
    "    # Read the frame from the video file\n",
    "    _, img = cap.read()\n",
    "    \n",
    "    if not _:\n",
    "        break\n",
    "    \n",
    "    frame_no = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "    timestamp = frame_no / fps\n",
    "    \n",
    "    # Run inference on the frame\n",
    "    results = model.predict(img,classes=classes)\n",
    "    \n",
    "    detected_classes = [box.cls for box in results[0].boxes]\n",
    "    if 0 in detected_classes:\n",
    "        counter += 1  # Increment counter if class 0 is detected\n",
    "        if counter >= 10 * fps:  # Check if class 0 has been detected for at least 10 seconds\n",
    "            continuous_detection = True\n",
    "    else:\n",
    "        counter = 0  # Reset counter if class 0 is not detected\n",
    "        continuous_detection = False\n",
    "\n",
    "    if continuous_detection and 32 in detected_classes:\n",
    "        print('Basketball Court: '+'\\033[31m' + '•' + '\\033[0m')\n",
    "        basketball_time_2.append(timestamp)\n",
    "    else:\n",
    "        print('Basketball Court: '+'\\033[32m' + '•' + '\\033[0m')\n",
    "    \n",
    "    for r in results:\n",
    "        # Create an annotator for the image\n",
    "        annotator = Annotator(img)\n",
    "\n",
    "        # Get the bounding boxes\n",
    "        boxes = r.boxes\n",
    "\n",
    "        # Draw each bounding box on the image\n",
    "        for box in boxes:\n",
    "            b = box.xyxy[0]  # get box coordinates in (left, top, right, bottom) format\n",
    "            c = box.cls\n",
    "            annotator.box_label(b, model.names[int(c)])  # draw the box and label on the image\n",
    "\n",
    "        \n",
    "        # Get the annotated image\n",
    "        img = annotator.result()\n",
    "        \n",
    "        out.write(img)\n",
    "        \n",
    "    # Display the image with bounding boxes\n",
    "    cv2.imshow('YOLO V8 Detection', img)\n",
    "\n",
    "    # Break the loop if the 'space' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord(' '):\n",
    "        break\n",
    "\n",
    "# Release the video file and close all windows\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30a9b78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3c8c57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf56efbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d67798ab",
   "metadata": {},
   "source": [
    "# Table Tennis-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37708db7-08b3-437d-a021-4406bce00657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 115.9ms\n",
      "Speed: 4.0ms preprocess, 115.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 119.0ms\n",
      "Speed: 3.1ms preprocess, 119.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 113.2ms\n",
      "Speed: 4.0ms preprocess, 113.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 125.5ms\n",
      "Speed: 3.0ms preprocess, 125.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 115.5ms\n",
      "Speed: 4.0ms preprocess, 115.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 118.5ms\n",
      "Speed: 4.0ms preprocess, 118.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 110.4ms\n",
      "Speed: 3.0ms preprocess, 110.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 118.5ms\n",
      "Speed: 4.0ms preprocess, 118.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 113.4ms\n",
      "Speed: 4.0ms preprocess, 113.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 114.5ms\n",
      "Speed: 4.0ms preprocess, 114.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 111.8ms\n",
      "Speed: 3.0ms preprocess, 111.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 111.3ms\n",
      "Speed: 4.0ms preprocess, 111.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 127.2ms\n",
      "Speed: 4.0ms preprocess, 127.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 112.5ms\n",
      "Speed: 3.0ms preprocess, 112.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 118.2ms\n",
      "Speed: 3.0ms preprocess, 118.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 137.4ms\n",
      "Speed: 4.0ms preprocess, 137.4ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 170.5ms\n",
      "Speed: 4.9ms preprocess, 170.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 157.0ms\n",
      "Speed: 4.9ms preprocess, 157.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 158.2ms\n",
      "Speed: 5.0ms preprocess, 158.2ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 69.8ms\n",
      "Speed: 2.0ms preprocess, 69.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 77.0ms\n",
      "Speed: 2.0ms preprocess, 77.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 78.1ms\n",
      "Speed: 2.0ms preprocess, 78.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 71.1ms\n",
      "Speed: 3.0ms preprocess, 71.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 77.2ms\n",
      "Speed: 2.0ms preprocess, 77.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 94.5ms\n",
      "Speed: 3.0ms preprocess, 94.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 103.5ms\n",
      "Speed: 2.0ms preprocess, 103.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 106.9ms\n",
      "Speed: 3.0ms preprocess, 106.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 85.1ms\n",
      "Speed: 2.0ms preprocess, 85.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 78.0ms\n",
      "Speed: 2.0ms preprocess, 78.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 75.5ms\n",
      "Speed: 3.0ms preprocess, 75.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 76.3ms\n",
      "Speed: 3.0ms preprocess, 76.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 77.5ms\n",
      "Speed: 1.0ms preprocess, 77.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 76.5ms\n",
      "Speed: 2.0ms preprocess, 76.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 77.2ms\n",
      "Speed: 2.0ms preprocess, 77.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 78.5ms\n",
      "Speed: 2.0ms preprocess, 78.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 76.0ms\n",
      "Speed: 1.1ms preprocess, 76.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 94.5ms\n",
      "Speed: 4.0ms preprocess, 94.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 78.0ms\n",
      "Speed: 2.0ms preprocess, 78.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 66.5ms\n",
      "Speed: 4.0ms preprocess, 66.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 67.1ms\n",
      "Speed: 2.0ms preprocess, 67.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 69.0ms\n",
      "Speed: 3.0ms preprocess, 69.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 68.3ms\n",
      "Speed: 3.0ms preprocess, 68.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 70.1ms\n",
      "Speed: 3.0ms preprocess, 70.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 71.0ms\n",
      "Speed: 2.0ms preprocess, 71.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 71.1ms\n",
      "Speed: 2.0ms preprocess, 71.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 65.5ms\n",
      "Speed: 2.0ms preprocess, 65.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 76.0ms\n",
      "Speed: 2.2ms preprocess, 76.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 66.1ms\n",
      "Speed: 2.5ms preprocess, 66.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 88.5ms\n",
      "Speed: 2.0ms preprocess, 88.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 69.5ms\n",
      "Speed: 2.0ms preprocess, 69.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 70.6ms\n",
      "Speed: 2.0ms preprocess, 70.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 79.0ms\n",
      "Speed: 2.0ms preprocess, 79.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 170.1ms\n",
      "Speed: 5.1ms preprocess, 170.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 167.5ms\n",
      "Speed: 5.0ms preprocess, 167.5ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 178.6ms\n",
      "Speed: 4.9ms preprocess, 178.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 152.1ms\n",
      "Speed: 3.9ms preprocess, 152.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 176.0ms\n",
      "Speed: 4.9ms preprocess, 176.0ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 160.8ms\n",
      "Speed: 4.0ms preprocess, 160.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 145.5ms\n",
      "Speed: 5.0ms preprocess, 145.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 181.5ms\n",
      "Speed: 4.1ms preprocess, 181.5ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 144.8ms\n",
      "Speed: 5.0ms preprocess, 144.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 150.8ms\n",
      "Speed: 5.0ms preprocess, 150.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 138.5ms\n",
      "Speed: 3.0ms preprocess, 138.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 153.0ms\n",
      "Speed: 2.9ms preprocess, 153.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 150.5ms\n",
      "Speed: 3.9ms preprocess, 150.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 152.5ms\n",
      "Speed: 4.0ms preprocess, 152.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 146.4ms\n",
      "Speed: 4.0ms preprocess, 146.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 224.8ms\n",
      "Speed: 8.0ms preprocess, 224.8ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 140.0ms\n",
      "Speed: 4.0ms preprocess, 140.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 257.5ms\n",
      "Speed: 4.9ms preprocess, 257.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 216.7ms\n",
      "Speed: 5.9ms preprocess, 216.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 152.7ms\n",
      "Speed: 5.0ms preprocess, 152.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 175.9ms\n",
      "Speed: 5.0ms preprocess, 175.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 198.8ms\n",
      "Speed: 7.2ms preprocess, 198.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 167.7ms\n",
      "Speed: 5.0ms preprocess, 167.7ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 173.9ms\n",
      "Speed: 5.0ms preprocess, 173.9ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 154.6ms\n",
      "Speed: 5.0ms preprocess, 154.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 168.6ms\n",
      "Speed: 4.0ms preprocess, 168.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 162.2ms\n",
      "Speed: 4.0ms preprocess, 162.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 156.2ms\n",
      "Speed: 4.5ms preprocess, 156.2ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 153.4ms\n",
      "Speed: 6.9ms preprocess, 153.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 144.5ms\n",
      "Speed: 4.2ms preprocess, 144.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 161.7ms\n",
      "Speed: 6.5ms preprocess, 161.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 135.1ms\n",
      "Speed: 4.0ms preprocess, 135.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 138.5ms\n",
      "Speed: 6.0ms preprocess, 138.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 170.6ms\n",
      "Speed: 5.0ms preprocess, 170.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 161.8ms\n",
      "Speed: 4.4ms preprocess, 161.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 153.0ms\n",
      "Speed: 5.0ms preprocess, 153.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 152.8ms\n",
      "Speed: 5.5ms preprocess, 152.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 137.6ms\n",
      "Speed: 4.0ms preprocess, 137.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 149.4ms\n",
      "Speed: 5.0ms preprocess, 149.4ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 135.1ms\n",
      "Speed: 4.0ms preprocess, 135.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 170.5ms\n",
      "Speed: 8.0ms preprocess, 170.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 175.1ms\n",
      "Speed: 4.6ms preprocess, 175.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 231.3ms\n",
      "Speed: 8.0ms preprocess, 231.3ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 230.6ms\n",
      "Speed: 6.1ms preprocess, 230.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 131.9ms\n",
      "Speed: 5.2ms preprocess, 131.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 224.6ms\n",
      "Speed: 7.4ms preprocess, 224.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 132.9ms\n",
      "Speed: 4.0ms preprocess, 132.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 155.7ms\n",
      "Speed: 4.0ms preprocess, 155.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 184.2ms\n",
      "Speed: 3.9ms preprocess, 184.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 171.1ms\n",
      "Speed: 3.7ms preprocess, 171.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 154.0ms\n",
      "Speed: 4.0ms preprocess, 154.0ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 151.6ms\n",
      "Speed: 4.1ms preprocess, 151.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 156.9ms\n",
      "Speed: 6.0ms preprocess, 156.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 166.2ms\n",
      "Speed: 5.0ms preprocess, 166.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 131.1ms\n",
      "Speed: 4.0ms preprocess, 131.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 171.8ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 4.0ms preprocess, 171.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 127.0ms\n",
      "Speed: 4.0ms preprocess, 127.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 170.1ms\n",
      "Speed: 4.9ms preprocess, 170.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 151.3ms\n",
      "Speed: 5.0ms preprocess, 151.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 162.0ms\n",
      "Speed: 5.0ms preprocess, 162.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 289.2ms\n",
      "Speed: 5.0ms preprocess, 289.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 187.3ms\n",
      "Speed: 5.0ms preprocess, 187.3ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 167.7ms\n",
      "Speed: 5.0ms preprocess, 167.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 172.2ms\n",
      "Speed: 5.0ms preprocess, 172.2ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 139.2ms\n",
      "Speed: 3.0ms preprocess, 139.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 120.4ms\n",
      "Speed: 4.0ms preprocess, 120.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 207.4ms\n",
      "Speed: 8.0ms preprocess, 207.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 159.2ms\n",
      "Speed: 6.0ms preprocess, 159.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 173.4ms\n",
      "Speed: 3.0ms preprocess, 173.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 154.1ms\n",
      "Speed: 5.0ms preprocess, 154.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 145.9ms\n",
      "Speed: 5.0ms preprocess, 145.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 264.1ms\n",
      "Speed: 5.0ms preprocess, 264.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 149.7ms\n",
      "Speed: 4.0ms preprocess, 149.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 184.3ms\n",
      "Speed: 8.0ms preprocess, 184.3ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 160.5ms\n",
      "Speed: 5.0ms preprocess, 160.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 145.9ms\n",
      "Speed: 5.0ms preprocess, 145.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 148.1ms\n",
      "Speed: 4.0ms preprocess, 148.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 174.3ms\n",
      "Speed: 4.0ms preprocess, 174.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 266.6ms\n",
      "Speed: 6.0ms preprocess, 266.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 138.5ms\n",
      "Speed: 3.2ms preprocess, 138.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 134.2ms\n",
      "Speed: 5.0ms preprocess, 134.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 159.8ms\n",
      "Speed: 4.0ms preprocess, 159.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 252.5ms\n",
      "Speed: 5.3ms preprocess, 252.5ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 141.2ms\n",
      "Speed: 3.0ms preprocess, 141.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 213.7ms\n",
      "Speed: 8.1ms preprocess, 213.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 257.9ms\n",
      "Speed: 6.0ms preprocess, 257.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 168.0ms\n",
      "Speed: 5.0ms preprocess, 168.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 129.0ms\n",
      "Speed: 5.0ms preprocess, 129.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 142.9ms\n",
      "Speed: 5.4ms preprocess, 142.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 169.1ms\n",
      "Speed: 4.0ms preprocess, 169.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 136.9ms\n",
      "Speed: 4.0ms preprocess, 136.9ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 166.0ms\n",
      "Speed: 4.0ms preprocess, 166.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 264.4ms\n",
      "Speed: 6.9ms preprocess, 264.4ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 129.5ms\n",
      "Speed: 4.0ms preprocess, 129.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 237.8ms\n",
      "Speed: 8.0ms preprocess, 237.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 150.5ms\n",
      "Speed: 3.0ms preprocess, 150.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 201.6ms\n",
      "Speed: 4.0ms preprocess, 201.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 182.9ms\n",
      "Speed: 5.9ms preprocess, 182.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 208.6ms\n",
      "Speed: 5.2ms preprocess, 208.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 183.1ms\n",
      "Speed: 5.0ms preprocess, 183.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 199.0ms\n",
      "Speed: 3.0ms preprocess, 199.0ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 139.8ms\n",
      "Speed: 4.3ms preprocess, 139.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 170.7ms\n",
      "Speed: 6.1ms preprocess, 170.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 138.7ms\n",
      "Speed: 4.0ms preprocess, 138.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 129.3ms\n",
      "Speed: 3.0ms preprocess, 129.3ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 171.6ms\n",
      "Speed: 5.0ms preprocess, 171.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 282.6ms\n",
      "Speed: 8.0ms preprocess, 282.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 137.8ms\n",
      "Speed: 4.0ms preprocess, 137.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 193.6ms\n",
      "Speed: 6.7ms preprocess, 193.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 147.6ms\n",
      "Speed: 4.0ms preprocess, 147.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 173.7ms\n",
      "Speed: 10.0ms preprocess, 173.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 162.2ms\n",
      "Speed: 3.5ms preprocess, 162.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 139.6ms\n",
      "Speed: 3.9ms preprocess, 139.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 183.6ms\n",
      "Speed: 5.0ms preprocess, 183.6ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 167.8ms\n",
      "Speed: 5.5ms preprocess, 167.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 169.1ms\n",
      "Speed: 4.9ms preprocess, 169.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 147.1ms\n",
      "Speed: 6.2ms preprocess, 147.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 219.1ms\n",
      "Speed: 5.0ms preprocess, 219.1ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 138.9ms\n",
      "Speed: 4.0ms preprocess, 138.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 153.7ms\n",
      "Speed: 5.0ms preprocess, 153.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 172.4ms\n",
      "Speed: 6.2ms preprocess, 172.4ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 141.2ms\n",
      "Speed: 3.8ms preprocess, 141.2ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 132.4ms\n",
      "Speed: 4.2ms preprocess, 132.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 134.1ms\n",
      "Speed: 4.0ms preprocess, 134.1ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 132.2ms\n",
      "Speed: 5.0ms preprocess, 132.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 149.0ms\n",
      "Speed: 3.0ms preprocess, 149.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 130.4ms\n",
      "Speed: 4.0ms preprocess, 130.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 142.5ms\n",
      "Speed: 5.4ms preprocess, 142.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 172.6ms\n",
      "Speed: 5.0ms preprocess, 172.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 122.5ms\n",
      "Speed: 4.0ms preprocess, 122.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 150.1ms\n",
      "Speed: 4.9ms preprocess, 150.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 190.9ms\n",
      "Speed: 5.0ms preprocess, 190.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 132.9ms\n",
      "Speed: 4.0ms preprocess, 132.9ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 152.3ms\n",
      "Speed: 3.0ms preprocess, 152.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 148.7ms\n",
      "Speed: 4.0ms preprocess, 148.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 163.1ms\n",
      "Speed: 5.0ms preprocess, 163.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 103.1ms\n",
      "Speed: 3.0ms preprocess, 103.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 103.8ms\n",
      "Speed: 4.3ms preprocess, 103.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 136.5ms\n",
      "Speed: 4.0ms preprocess, 136.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 135.4ms\n",
      "Speed: 4.0ms preprocess, 135.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 163.3ms\n",
      "Speed: 4.0ms preprocess, 163.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 163.4ms\n",
      "Speed: 4.0ms preprocess, 163.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 149.7ms\n",
      "Speed: 3.0ms preprocess, 149.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 171.5ms\n",
      "Speed: 5.0ms preprocess, 171.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 149.6ms\n",
      "Speed: 4.0ms preprocess, 149.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 174.7ms\n",
      "Speed: 6.0ms preprocess, 174.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 183.9ms\n",
      "Speed: 5.0ms preprocess, 183.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 130.3ms\n",
      "Speed: 4.2ms preprocess, 130.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 106.3ms\n",
      "Speed: 4.0ms preprocess, 106.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 115.0ms\n",
      "Speed: 4.0ms preprocess, 115.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 112.6ms\n",
      "Speed: 3.0ms preprocess, 112.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 104.3ms\n",
      "Speed: 4.1ms preprocess, 104.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 115.0ms\n",
      "Speed: 4.0ms preprocess, 115.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 138.0ms\n",
      "Speed: 4.0ms preprocess, 138.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 215.1ms\n",
      "Speed: 6.0ms preprocess, 215.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 167.5ms\n",
      "Speed: 4.0ms preprocess, 167.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 218.4ms\n",
      "Speed: 8.0ms preprocess, 218.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 240.6ms\n",
      "Speed: 7.9ms preprocess, 240.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 172.2ms\n",
      "Speed: 4.9ms preprocess, 172.2ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 155.5ms\n",
      "Speed: 4.0ms preprocess, 155.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 156.6ms\n",
      "Speed: 5.0ms preprocess, 156.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 152.8ms\n",
      "Speed: 4.9ms preprocess, 152.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 154.7ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 4.1ms preprocess, 154.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 153.4ms\n",
      "Speed: 4.0ms preprocess, 153.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 168.5ms\n",
      "Speed: 4.0ms preprocess, 168.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 208.0ms\n",
      "Speed: 4.0ms preprocess, 208.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 265.7ms\n",
      "Speed: 5.0ms preprocess, 265.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 181.6ms\n",
      "Speed: 4.0ms preprocess, 181.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 167.3ms\n",
      "Speed: 5.0ms preprocess, 167.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 169.8ms\n",
      "Speed: 4.9ms preprocess, 169.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 189.1ms\n",
      "Speed: 9.2ms preprocess, 189.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 113.3ms\n",
      "Speed: 3.0ms preprocess, 113.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 151.7ms\n",
      "Speed: 4.9ms preprocess, 151.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 174.9ms\n",
      "Speed: 4.9ms preprocess, 174.9ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 148.5ms\n",
      "Speed: 4.0ms preprocess, 148.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 176.9ms\n",
      "Speed: 5.0ms preprocess, 176.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 216.6ms\n",
      "Speed: 5.9ms preprocess, 216.6ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 168.2ms\n",
      "Speed: 4.0ms preprocess, 168.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 177.9ms\n",
      "Speed: 4.0ms preprocess, 177.9ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 210.4ms\n",
      "Speed: 6.0ms preprocess, 210.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 201.3ms\n",
      "Speed: 4.0ms preprocess, 201.3ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 172.3ms\n",
      "Speed: 4.5ms preprocess, 172.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 178.0ms\n",
      "Speed: 5.3ms preprocess, 178.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 200.4ms\n",
      "Speed: 5.0ms preprocess, 200.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 176.3ms\n",
      "Speed: 5.0ms preprocess, 176.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 165.2ms\n",
      "Speed: 4.0ms preprocess, 165.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 186.9ms\n",
      "Speed: 5.0ms preprocess, 186.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 166.8ms\n",
      "Speed: 5.0ms preprocess, 166.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 158.1ms\n",
      "Speed: 4.9ms preprocess, 158.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 206.0ms\n",
      "Speed: 5.0ms preprocess, 206.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 262.6ms\n",
      "Speed: 7.0ms preprocess, 262.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 163.4ms\n",
      "Speed: 4.9ms preprocess, 163.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 173.6ms\n",
      "Speed: 3.9ms preprocess, 173.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 158.2ms\n",
      "Speed: 4.5ms preprocess, 158.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 186.3ms\n",
      "Speed: 4.9ms preprocess, 186.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 210.1ms\n",
      "Speed: 4.9ms preprocess, 210.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 235.0ms\n",
      "Speed: 7.0ms preprocess, 235.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 175.1ms\n",
      "Speed: 4.2ms preprocess, 175.1ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 168.2ms\n",
      "Speed: 4.0ms preprocess, 168.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 209.1ms\n",
      "Speed: 7.4ms preprocess, 209.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 179.1ms\n",
      "Speed: 4.0ms preprocess, 179.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 153.9ms\n",
      "Speed: 5.0ms preprocess, 153.9ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 163.6ms\n",
      "Speed: 5.4ms preprocess, 163.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 161.0ms\n",
      "Speed: 5.0ms preprocess, 161.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 208.7ms\n",
      "Speed: 6.0ms preprocess, 208.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 166.8ms\n",
      "Speed: 5.0ms preprocess, 166.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 172.5ms\n",
      "Speed: 6.0ms preprocess, 172.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 154.1ms\n",
      "Speed: 5.4ms preprocess, 154.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 140.0ms\n",
      "Speed: 4.0ms preprocess, 140.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 213.5ms\n",
      "Speed: 5.0ms preprocess, 213.5ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 201.9ms\n",
      "Speed: 5.6ms preprocess, 201.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 230.1ms\n",
      "Speed: 6.0ms preprocess, 230.1ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 157.7ms\n",
      "Speed: 6.0ms preprocess, 157.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 279.3ms\n",
      "Speed: 6.5ms preprocess, 279.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 173.9ms\n",
      "Speed: 5.0ms preprocess, 173.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 156.0ms\n",
      "Speed: 3.0ms preprocess, 156.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 173.6ms\n",
      "Speed: 4.0ms preprocess, 173.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 185.1ms\n",
      "Speed: 4.0ms preprocess, 185.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 163.8ms\n",
      "Speed: 5.0ms preprocess, 163.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 246.0ms\n",
      "Speed: 9.6ms preprocess, 246.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 170.7ms\n",
      "Speed: 5.0ms preprocess, 170.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 168.2ms\n",
      "Speed: 4.0ms preprocess, 168.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 180.0ms\n",
      "Speed: 4.0ms preprocess, 180.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 179.8ms\n",
      "Speed: 4.0ms preprocess, 179.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 159.2ms\n",
      "Speed: 5.0ms preprocess, 159.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 170.8ms\n",
      "Speed: 4.0ms preprocess, 170.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 161.2ms\n",
      "Speed: 4.1ms preprocess, 161.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 178.7ms\n",
      "Speed: 4.0ms preprocess, 178.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 177.6ms\n",
      "Speed: 5.0ms preprocess, 177.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 154.6ms\n",
      "Speed: 4.4ms preprocess, 154.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 244.9ms\n",
      "Speed: 4.0ms preprocess, 244.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 165.9ms\n",
      "Speed: 4.0ms preprocess, 165.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 158.3ms\n",
      "Speed: 3.1ms preprocess, 158.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 167.0ms\n",
      "Speed: 4.1ms preprocess, 167.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 238.5ms\n",
      "Speed: 4.0ms preprocess, 238.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 159.1ms\n",
      "Speed: 6.1ms preprocess, 159.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 156.7ms\n",
      "Speed: 4.6ms preprocess, 156.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 165.9ms\n",
      "Speed: 3.9ms preprocess, 165.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 180.6ms\n",
      "Speed: 3.9ms preprocess, 180.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 156.7ms\n",
      "Speed: 4.0ms preprocess, 156.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 164.4ms\n",
      "Speed: 4.0ms preprocess, 164.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 189.3ms\n",
      "Speed: 5.1ms preprocess, 189.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 178.3ms\n",
      "Speed: 3.4ms preprocess, 178.3ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 206.5ms\n",
      "Speed: 5.0ms preprocess, 206.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 234.5ms\n",
      "Speed: 5.4ms preprocess, 234.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 183.6ms\n",
      "Speed: 4.5ms preprocess, 183.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 154.5ms\n",
      "Speed: 3.0ms preprocess, 154.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 166.7ms\n",
      "Speed: 5.0ms preprocess, 166.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 169.8ms\n",
      "Speed: 4.0ms preprocess, 169.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 172.3ms\n",
      "Speed: 4.0ms preprocess, 172.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 132.6ms\n",
      "Speed: 4.0ms preprocess, 132.6ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 175.4ms\n",
      "Speed: 4.9ms preprocess, 175.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 161.0ms\n",
      "Speed: 5.2ms preprocess, 161.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 174.1ms\n",
      "Speed: 6.0ms preprocess, 174.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 206.8ms\n",
      "Speed: 4.9ms preprocess, 206.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 253.6ms\n",
      "Speed: 7.4ms preprocess, 253.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 167.8ms\n",
      "Speed: 4.0ms preprocess, 167.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 156.8ms\n",
      "Speed: 5.0ms preprocess, 156.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 194.9ms\n",
      "Speed: 6.0ms preprocess, 194.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 130.3ms\n",
      "Speed: 4.5ms preprocess, 130.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 179.2ms\n",
      "Speed: 5.0ms preprocess, 179.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 209.3ms\n",
      "Speed: 7.9ms preprocess, 209.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 179.5ms\n",
      "Speed: 5.0ms preprocess, 179.5ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 154.8ms\n",
      "Speed: 4.9ms preprocess, 154.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 170.2ms\n",
      "Speed: 4.0ms preprocess, 170.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 157.9ms\n",
      "Speed: 5.0ms preprocess, 157.9ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 160.3ms\n",
      "Speed: 4.0ms preprocess, 160.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 154.0ms\n",
      "Speed: 4.0ms preprocess, 154.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 181.2ms\n",
      "Speed: 5.5ms preprocess, 181.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 172.9ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 5.2ms preprocess, 172.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 178.0ms\n",
      "Speed: 5.2ms preprocess, 178.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 240.2ms\n",
      "Speed: 4.1ms preprocess, 240.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 173.4ms\n",
      "Speed: 5.0ms preprocess, 173.4ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 195.7ms\n",
      "Speed: 5.0ms preprocess, 195.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 194.2ms\n",
      "Speed: 4.0ms preprocess, 194.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 134.1ms\n",
      "Speed: 5.0ms preprocess, 134.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 167.1ms\n",
      "Speed: 4.0ms preprocess, 167.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 157.5ms\n",
      "Speed: 4.0ms preprocess, 157.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 181.8ms\n",
      "Speed: 4.9ms preprocess, 181.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 7 persons, 152.3ms\n",
      "Speed: 4.5ms preprocess, 152.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 175.7ms\n",
      "Speed: 4.0ms preprocess, 175.7ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 146.4ms\n",
      "Speed: 4.0ms preprocess, 146.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 165.1ms\n",
      "Speed: 5.0ms preprocess, 165.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 155.3ms\n",
      "Speed: 4.0ms preprocess, 155.3ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 174.2ms\n",
      "Speed: 4.0ms preprocess, 174.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 124.9ms\n",
      "Speed: 3.5ms preprocess, 124.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 138.0ms\n",
      "Speed: 3.3ms preprocess, 138.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 137.3ms\n",
      "Speed: 4.0ms preprocess, 137.3ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 131.9ms\n",
      "Speed: 4.0ms preprocess, 131.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 186.6ms\n",
      "Speed: 4.0ms preprocess, 186.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 164.5ms\n",
      "Speed: 3.0ms preprocess, 164.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 168.0ms\n",
      "Speed: 4.0ms preprocess, 168.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 147.0ms\n",
      "Speed: 5.0ms preprocess, 147.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 7 persons, 191.0ms\n",
      "Speed: 4.1ms preprocess, 191.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 223.5ms\n",
      "Speed: 9.3ms preprocess, 223.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 169.3ms\n",
      "Speed: 4.0ms preprocess, 169.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 180.5ms\n",
      "Speed: 6.0ms preprocess, 180.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 7 persons, 190.3ms\n",
      "Speed: 4.0ms preprocess, 190.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 7 persons, 169.3ms\n",
      "Speed: 4.0ms preprocess, 169.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 186.3ms\n",
      "Speed: 4.0ms preprocess, 186.3ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 176.7ms\n",
      "Speed: 4.1ms preprocess, 176.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 177.9ms\n",
      "Speed: 4.9ms preprocess, 177.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 138.8ms\n",
      "Speed: 4.0ms preprocess, 138.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 146.5ms\n",
      "Speed: 4.0ms preprocess, 146.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 170.8ms\n",
      "Speed: 4.2ms preprocess, 170.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 7 persons, 148.1ms\n",
      "Speed: 3.0ms preprocess, 148.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 140.3ms\n",
      "Speed: 4.0ms preprocess, 140.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 149.8ms\n",
      "Speed: 4.0ms preprocess, 149.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 240.2ms\n",
      "Speed: 7.5ms preprocess, 240.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 178.2ms\n",
      "Speed: 5.0ms preprocess, 178.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 157.5ms\n",
      "Speed: 5.1ms preprocess, 157.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 187.5ms\n",
      "Speed: 2.0ms preprocess, 187.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 165.7ms\n",
      "Speed: 4.9ms preprocess, 165.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 168.4ms\n",
      "Speed: 3.9ms preprocess, 168.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 182.1ms\n",
      "Speed: 4.0ms preprocess, 182.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 168.2ms\n",
      "Speed: 6.0ms preprocess, 168.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 133.3ms\n",
      "Speed: 2.9ms preprocess, 133.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 163.8ms\n",
      "Speed: 4.0ms preprocess, 163.8ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 156.3ms\n",
      "Speed: 4.0ms preprocess, 156.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 142.8ms\n",
      "Speed: 3.9ms preprocess, 142.8ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 155.1ms\n",
      "Speed: 5.0ms preprocess, 155.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 216.2ms\n",
      "Speed: 4.1ms preprocess, 216.2ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 137.5ms\n",
      "Speed: 4.0ms preprocess, 137.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 144.1ms\n",
      "Speed: 3.0ms preprocess, 144.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 177.5ms\n",
      "Speed: 5.0ms preprocess, 177.5ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 135.8ms\n",
      "Speed: 5.0ms preprocess, 135.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 128.4ms\n",
      "Speed: 4.0ms preprocess, 128.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 135.1ms\n",
      "Speed: 5.0ms preprocess, 135.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 163.3ms\n",
      "Speed: 8.0ms preprocess, 163.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 137.2ms\n",
      "Speed: 5.0ms preprocess, 137.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 136.0ms\n",
      "Speed: 5.0ms preprocess, 136.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 236.1ms\n",
      "Speed: 6.4ms preprocess, 236.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 170.5ms\n",
      "Speed: 4.0ms preprocess, 170.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 140.8ms\n",
      "Speed: 4.0ms preprocess, 140.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 142.2ms\n",
      "Speed: 4.4ms preprocess, 142.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 164.2ms\n",
      "Speed: 4.0ms preprocess, 164.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 151.4ms\n",
      "Speed: 4.9ms preprocess, 151.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 164.1ms\n",
      "Speed: 3.9ms preprocess, 164.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 143.4ms\n",
      "Speed: 4.1ms preprocess, 143.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 123.0ms\n",
      "Speed: 4.0ms preprocess, 123.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 161.7ms\n",
      "Speed: 3.0ms preprocess, 161.7ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 153.5ms\n",
      "Speed: 6.0ms preprocess, 153.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 146.2ms\n",
      "Speed: 4.0ms preprocess, 146.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 150.5ms\n",
      "Speed: 3.2ms preprocess, 150.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 128.1ms\n",
      "Speed: 4.4ms preprocess, 128.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 172.2ms\n",
      "Speed: 7.0ms preprocess, 172.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 122.7ms\n",
      "Speed: 5.0ms preprocess, 122.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 122.2ms\n",
      "Speed: 3.7ms preprocess, 122.2ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 132.7ms\n",
      "Speed: 4.0ms preprocess, 132.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 134.0ms\n",
      "Speed: 4.0ms preprocess, 134.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 158.3ms\n",
      "Speed: 4.0ms preprocess, 158.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 112.0ms\n",
      "Speed: 4.0ms preprocess, 112.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 117.4ms\n",
      "Speed: 3.0ms preprocess, 117.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 138.9ms\n",
      "Speed: 3.1ms preprocess, 138.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 129.3ms\n",
      "Speed: 3.9ms preprocess, 129.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 7 persons, 148.9ms\n",
      "Speed: 3.0ms preprocess, 148.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 7 persons, 164.2ms\n",
      "Speed: 2.9ms preprocess, 164.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 130.2ms\n",
      "Speed: 4.0ms preprocess, 130.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 130.0ms\n",
      "Speed: 4.0ms preprocess, 130.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 130.7ms\n",
      "Speed: 4.1ms preprocess, 130.7ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 159.1ms\n",
      "Speed: 4.9ms preprocess, 159.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 173.6ms\n",
      "Speed: 5.0ms preprocess, 173.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 156.8ms\n",
      "Speed: 3.0ms preprocess, 156.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 154.5ms\n",
      "Speed: 3.7ms preprocess, 154.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 172.7ms\n",
      "Speed: 7.0ms preprocess, 172.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 160.4ms\n",
      "Speed: 4.0ms preprocess, 160.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 132.8ms\n",
      "Speed: 5.0ms preprocess, 132.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 142.5ms\n",
      "Speed: 3.0ms preprocess, 142.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 128.3ms\n",
      "Speed: 3.0ms preprocess, 128.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 138.3ms\n",
      "Speed: 5.1ms preprocess, 138.3ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 154.2ms\n",
      "Speed: 4.0ms preprocess, 154.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 7 persons, 240.0ms\n",
      "Speed: 7.0ms preprocess, 240.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 7 persons, 169.3ms\n",
      "Speed: 4.5ms preprocess, 169.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 155.3ms\n",
      "Speed: 5.1ms preprocess, 155.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 154.1ms\n",
      "Speed: 4.0ms preprocess, 154.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 154.4ms\n",
      "Speed: 4.3ms preprocess, 154.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 162.9ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 4.0ms preprocess, 162.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 150.3ms\n",
      "Speed: 4.3ms preprocess, 150.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 156.5ms\n",
      "Speed: 4.0ms preprocess, 156.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 146.7ms\n",
      "Speed: 5.0ms preprocess, 146.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 149.4ms\n",
      "Speed: 7.4ms preprocess, 149.4ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 161.8ms\n",
      "Speed: 4.0ms preprocess, 161.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 194.3ms\n",
      "Speed: 5.0ms preprocess, 194.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 141.3ms\n",
      "Speed: 3.9ms preprocess, 141.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 181.6ms\n",
      "Speed: 5.0ms preprocess, 181.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 162.4ms\n",
      "Speed: 4.9ms preprocess, 162.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 7 persons, 165.7ms\n",
      "Speed: 5.0ms preprocess, 165.7ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 148.9ms\n",
      "Speed: 5.0ms preprocess, 148.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 156.0ms\n",
      "Speed: 5.1ms preprocess, 156.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 132.6ms\n",
      "Speed: 5.0ms preprocess, 132.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 150.4ms\n",
      "Speed: 4.0ms preprocess, 150.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 135.9ms\n",
      "Speed: 3.4ms preprocess, 135.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 133.9ms\n",
      "Speed: 4.0ms preprocess, 133.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 174.2ms\n",
      "Speed: 5.0ms preprocess, 174.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 163.8ms\n",
      "Speed: 4.9ms preprocess, 163.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 165.4ms\n",
      "Speed: 6.8ms preprocess, 165.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 151.0ms\n",
      "Speed: 4.0ms preprocess, 151.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 171.2ms\n",
      "Speed: 4.9ms preprocess, 171.2ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 141.5ms\n",
      "Speed: 3.1ms preprocess, 141.5ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 197.8ms\n",
      "Speed: 7.0ms preprocess, 197.8ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 158.5ms\n",
      "Speed: 5.0ms preprocess, 158.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 164.8ms\n",
      "Speed: 5.0ms preprocess, 164.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 7 persons, 160.3ms\n",
      "Speed: 4.0ms preprocess, 160.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 156.6ms\n",
      "Speed: 3.0ms preprocess, 156.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 166.4ms\n",
      "Speed: 4.5ms preprocess, 166.4ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 136.4ms\n",
      "Speed: 5.0ms preprocess, 136.4ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 137.4ms\n",
      "Speed: 3.0ms preprocess, 137.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 165.8ms\n",
      "Speed: 4.0ms preprocess, 165.8ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 164.1ms\n",
      "Speed: 5.0ms preprocess, 164.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 152.5ms\n",
      "Speed: 3.0ms preprocess, 152.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 173.9ms\n",
      "Speed: 5.0ms preprocess, 173.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 221.9ms\n",
      "Speed: 7.0ms preprocess, 221.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 119.6ms\n",
      "Speed: 3.0ms preprocess, 119.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 183.3ms\n",
      "Speed: 6.0ms preprocess, 183.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 132.2ms\n",
      "Speed: 3.9ms preprocess, 132.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 242.1ms\n",
      "Speed: 6.0ms preprocess, 242.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 158.7ms\n",
      "Speed: 3.3ms preprocess, 158.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 135.5ms\n",
      "Speed: 3.0ms preprocess, 135.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 130.8ms\n",
      "Speed: 4.6ms preprocess, 130.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 144.3ms\n",
      "Speed: 4.0ms preprocess, 144.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 137.2ms\n",
      "Speed: 5.4ms preprocess, 137.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 147.4ms\n",
      "Speed: 4.0ms preprocess, 147.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 147.6ms\n",
      "Speed: 4.0ms preprocess, 147.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 127.6ms\n",
      "Speed: 5.4ms preprocess, 127.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 131.8ms\n",
      "Speed: 5.0ms preprocess, 131.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 136.1ms\n",
      "Speed: 5.0ms preprocess, 136.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 128.4ms\n",
      "Speed: 3.3ms preprocess, 128.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 131.1ms\n",
      "Speed: 4.0ms preprocess, 131.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 206.4ms\n",
      "Speed: 5.0ms preprocess, 206.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 157.2ms\n",
      "Speed: 4.0ms preprocess, 157.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 121.0ms\n",
      "Speed: 4.0ms preprocess, 121.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 163.1ms\n",
      "Speed: 5.0ms preprocess, 163.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 166.4ms\n",
      "Speed: 5.0ms preprocess, 166.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 165.1ms\n",
      "Speed: 4.5ms preprocess, 165.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 182.9ms\n",
      "Speed: 5.1ms preprocess, 182.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 155.5ms\n",
      "Speed: 5.7ms preprocess, 155.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 158.9ms\n",
      "Speed: 4.0ms preprocess, 158.9ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 165.3ms\n",
      "Speed: 3.9ms preprocess, 165.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 177.6ms\n",
      "Speed: 3.0ms preprocess, 177.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 152.4ms\n",
      "Speed: 4.0ms preprocess, 152.4ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 134.1ms\n",
      "Speed: 5.0ms preprocess, 134.1ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 164.0ms\n",
      "Speed: 7.0ms preprocess, 164.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 131.5ms\n",
      "Speed: 5.3ms preprocess, 131.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 158.2ms\n",
      "Speed: 4.0ms preprocess, 158.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 173.0ms\n",
      "Speed: 7.9ms preprocess, 173.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 152.5ms\n",
      "Speed: 4.9ms preprocess, 152.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 183.5ms\n",
      "Speed: 4.0ms preprocess, 183.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 260.2ms\n",
      "Speed: 9.5ms preprocess, 260.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 179.7ms\n",
      "Speed: 4.0ms preprocess, 179.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 166.2ms\n",
      "Speed: 5.1ms preprocess, 166.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 171.6ms\n",
      "Speed: 4.9ms preprocess, 171.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 170.5ms\n",
      "Speed: 5.0ms preprocess, 170.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 155.7ms\n",
      "Speed: 5.2ms preprocess, 155.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 210.3ms\n",
      "Speed: 5.0ms preprocess, 210.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 162.2ms\n",
      "Speed: 5.0ms preprocess, 162.2ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 141.9ms\n",
      "Speed: 6.0ms preprocess, 141.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 171.1ms\n",
      "Speed: 4.0ms preprocess, 171.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 139.4ms\n",
      "Speed: 6.0ms preprocess, 139.4ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 147.8ms\n",
      "Speed: 4.0ms preprocess, 147.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 165.2ms\n",
      "Speed: 5.1ms preprocess, 165.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 154.1ms\n",
      "Speed: 4.9ms preprocess, 154.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 171.5ms\n",
      "Speed: 4.0ms preprocess, 171.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 208.6ms\n",
      "Speed: 4.9ms preprocess, 208.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 159.9ms\n",
      "Speed: 3.9ms preprocess, 159.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 149.5ms\n",
      "Speed: 4.9ms preprocess, 149.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 166.2ms\n",
      "Speed: 5.0ms preprocess, 166.2ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 135.4ms\n",
      "Speed: 5.7ms preprocess, 135.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 162.8ms\n",
      "Speed: 5.0ms preprocess, 162.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 163.4ms\n",
      "Speed: 4.0ms preprocess, 163.4ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 172.8ms\n",
      "Speed: 4.1ms preprocess, 172.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 7 persons, 162.9ms\n",
      "Speed: 5.0ms preprocess, 162.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 216.3ms\n",
      "Speed: 7.6ms preprocess, 216.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 148.6ms\n",
      "Speed: 4.0ms preprocess, 148.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 126.0ms\n",
      "Speed: 5.2ms preprocess, 126.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 129.1ms\n",
      "Speed: 4.0ms preprocess, 129.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 160.3ms\n",
      "Speed: 5.0ms preprocess, 160.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 148.7ms\n",
      "Speed: 4.0ms preprocess, 148.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 182.2ms\n",
      "Speed: 5.0ms preprocess, 182.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 179.4ms\n",
      "Speed: 5.0ms preprocess, 179.4ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 162.9ms\n",
      "Speed: 5.0ms preprocess, 162.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 181.1ms\n",
      "Speed: 3.9ms preprocess, 181.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 180.9ms\n",
      "Speed: 4.9ms preprocess, 180.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 208.7ms\n",
      "Speed: 6.0ms preprocess, 208.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 264.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 5.1ms preprocess, 264.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 153.1ms\n",
      "Speed: 5.0ms preprocess, 153.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 116.6ms\n",
      "Speed: 4.0ms preprocess, 116.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 216.4ms\n",
      "Speed: 4.0ms preprocess, 216.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 130.5ms\n",
      "Speed: 8.0ms preprocess, 130.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 112.6ms\n",
      "Speed: 4.4ms preprocess, 112.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 126.2ms\n",
      "Speed: 6.0ms preprocess, 126.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 111.2ms\n",
      "Speed: 4.0ms preprocess, 111.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 140.3ms\n",
      "Speed: 4.0ms preprocess, 140.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 7 persons, 132.2ms\n",
      "Speed: 4.0ms preprocess, 132.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 155.6ms\n",
      "Speed: 4.3ms preprocess, 155.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 185.5ms\n",
      "Speed: 3.9ms preprocess, 185.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 192.8ms\n",
      "Speed: 6.0ms preprocess, 192.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 197.5ms\n",
      "Speed: 5.0ms preprocess, 197.5ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 263.8ms\n",
      "Speed: 6.0ms preprocess, 263.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 248.6ms\n",
      "Speed: 6.9ms preprocess, 248.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 172.7ms\n",
      "Speed: 3.9ms preprocess, 172.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 233.5ms\n",
      "Speed: 9.1ms preprocess, 233.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 127.5ms\n",
      "Speed: 3.0ms preprocess, 127.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 128.2ms\n",
      "Speed: 5.0ms preprocess, 128.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 154.2ms\n",
      "Speed: 4.0ms preprocess, 154.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 140.0ms\n",
      "Speed: 4.0ms preprocess, 140.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 126.1ms\n",
      "Speed: 3.1ms preprocess, 126.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 105.1ms\n",
      "Speed: 3.4ms preprocess, 105.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 123.1ms\n",
      "Speed: 3.0ms preprocess, 123.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 225.8ms\n",
      "Speed: 4.9ms preprocess, 225.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 231.1ms\n",
      "Speed: 6.1ms preprocess, 231.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 239.0ms\n",
      "Speed: 6.9ms preprocess, 239.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 228.5ms\n",
      "Speed: 5.0ms preprocess, 228.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 244.4ms\n",
      "Speed: 4.0ms preprocess, 244.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 217.6ms\n",
      "Speed: 4.4ms preprocess, 217.6ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 160.2ms\n",
      "Speed: 4.9ms preprocess, 160.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 268.6ms\n",
      "Speed: 6.9ms preprocess, 268.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 175.3ms\n",
      "Speed: 5.0ms preprocess, 175.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 168.8ms\n",
      "Speed: 5.0ms preprocess, 168.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 168.7ms\n",
      "Speed: 5.6ms preprocess, 168.7ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 169.3ms\n",
      "Speed: 4.0ms preprocess, 169.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 217.7ms\n",
      "Speed: 3.0ms preprocess, 217.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 216.1ms\n",
      "Speed: 4.6ms preprocess, 216.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 167.5ms\n",
      "Speed: 4.0ms preprocess, 167.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 179.8ms\n",
      "Speed: 3.9ms preprocess, 179.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 162.5ms\n",
      "Speed: 4.9ms preprocess, 162.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 169.2ms\n",
      "Speed: 6.0ms preprocess, 169.2ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 161.5ms\n",
      "Speed: 4.0ms preprocess, 161.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 165.6ms\n",
      "Speed: 5.0ms preprocess, 165.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 175.0ms\n",
      "Speed: 4.0ms preprocess, 175.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 149.5ms\n",
      "Speed: 7.0ms preprocess, 149.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 179.5ms\n",
      "Speed: 5.1ms preprocess, 179.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 160.1ms\n",
      "Speed: 4.9ms preprocess, 160.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 156.2ms\n",
      "Speed: 5.0ms preprocess, 156.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 127.6ms\n",
      "Speed: 4.0ms preprocess, 127.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 195.6ms\n",
      "Speed: 5.0ms preprocess, 195.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 234.0ms\n",
      "Speed: 4.1ms preprocess, 234.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 166.4ms\n",
      "Speed: 5.0ms preprocess, 166.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 164.2ms\n",
      "Speed: 4.9ms preprocess, 164.2ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 202.8ms\n",
      "Speed: 4.0ms preprocess, 202.8ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 177.0ms\n",
      "Speed: 5.0ms preprocess, 177.0ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 183.6ms\n",
      "Speed: 6.0ms preprocess, 183.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 163.0ms\n",
      "Speed: 4.0ms preprocess, 163.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 162.7ms\n",
      "Speed: 4.9ms preprocess, 162.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 176.4ms\n",
      "Speed: 6.1ms preprocess, 176.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 230.8ms\n",
      "Speed: 6.9ms preprocess, 230.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 183.4ms\n",
      "Speed: 5.0ms preprocess, 183.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 235.5ms\n",
      "Speed: 4.9ms preprocess, 235.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 169.0ms\n",
      "Speed: 4.0ms preprocess, 169.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 183.3ms\n",
      "Speed: 5.0ms preprocess, 183.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 165.4ms\n",
      "Speed: 4.0ms preprocess, 165.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 219.7ms\n",
      "Speed: 5.1ms preprocess, 219.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 215.9ms\n",
      "Speed: 4.9ms preprocess, 215.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 179.6ms\n",
      "Speed: 3.9ms preprocess, 179.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 148.1ms\n",
      "Speed: 3.0ms preprocess, 148.1ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 199.9ms\n",
      "Speed: 5.0ms preprocess, 199.9ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 161.3ms\n",
      "Speed: 3.1ms preprocess, 161.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 249.1ms\n",
      "Speed: 5.9ms preprocess, 249.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 235.6ms\n",
      "Speed: 5.0ms preprocess, 235.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 154.6ms\n",
      "Speed: 5.0ms preprocess, 154.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 232.1ms\n",
      "Speed: 4.0ms preprocess, 232.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 174.3ms\n",
      "Speed: 4.0ms preprocess, 174.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 166.9ms\n",
      "Speed: 5.0ms preprocess, 166.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 214.2ms\n",
      "Speed: 5.0ms preprocess, 214.2ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 176.3ms\n",
      "Speed: 5.9ms preprocess, 176.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 173.3ms\n",
      "Speed: 4.0ms preprocess, 173.3ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 180.9ms\n",
      "Speed: 6.0ms preprocess, 180.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 168.3ms\n",
      "Speed: 6.0ms preprocess, 168.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 202.4ms\n",
      "Speed: 4.6ms preprocess, 202.4ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 158.8ms\n",
      "Speed: 5.0ms preprocess, 158.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 183.7ms\n",
      "Speed: 5.0ms preprocess, 183.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 175.5ms\n",
      "Speed: 7.0ms preprocess, 175.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 196.5ms\n",
      "Speed: 5.1ms preprocess, 196.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 135.9ms\n",
      "Speed: 5.4ms preprocess, 135.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 154.2ms\n",
      "Speed: 4.0ms preprocess, 154.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 184.4ms\n",
      "Speed: 8.0ms preprocess, 184.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 142.1ms\n",
      "Speed: 4.0ms preprocess, 142.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 160.3ms\n",
      "Speed: 4.0ms preprocess, 160.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 139.5ms\n",
      "Speed: 4.0ms preprocess, 139.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 227.9ms\n",
      "Speed: 5.0ms preprocess, 227.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 169.0ms\n",
      "Speed: 4.9ms preprocess, 169.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 169.8ms\n",
      "Speed: 7.0ms preprocess, 169.8ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 145.7ms\n",
      "Speed: 4.1ms preprocess, 145.7ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 135.9ms\n",
      "Speed: 4.0ms preprocess, 135.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 209.5ms\n",
      "Speed: 5.0ms preprocess, 209.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 151.0ms\n",
      "Speed: 4.0ms preprocess, 151.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 129.6ms\n",
      "Speed: 4.3ms preprocess, 129.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 159.1ms\n",
      "Speed: 4.0ms preprocess, 159.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 7 persons, 168.1ms\n",
      "Speed: 4.1ms preprocess, 168.1ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 177.2ms\n",
      "Speed: 5.5ms preprocess, 177.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 137.3ms\n",
      "Speed: 3.4ms preprocess, 137.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 136.6ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 4.0ms preprocess, 136.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 129.6ms\n",
      "Speed: 5.0ms preprocess, 129.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 168.1ms\n",
      "Speed: 4.0ms preprocess, 168.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 151.6ms\n",
      "Speed: 5.0ms preprocess, 151.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 152.6ms\n",
      "Speed: 4.0ms preprocess, 152.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 196.6ms\n",
      "Speed: 9.3ms preprocess, 196.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 144.8ms\n",
      "Speed: 7.0ms preprocess, 144.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 142.1ms\n",
      "Speed: 4.0ms preprocess, 142.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 205.2ms\n",
      "Speed: 5.0ms preprocess, 205.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 208.1ms\n",
      "Speed: 8.8ms preprocess, 208.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 142.5ms\n",
      "Speed: 3.0ms preprocess, 142.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 223.3ms\n",
      "Speed: 6.0ms preprocess, 223.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 161.4ms\n",
      "Speed: 5.0ms preprocess, 161.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 148.4ms\n",
      "Speed: 5.0ms preprocess, 148.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 153.9ms\n",
      "Speed: 4.6ms preprocess, 153.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 136.8ms\n",
      "Speed: 4.9ms preprocess, 136.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 132.2ms\n",
      "Speed: 3.5ms preprocess, 132.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 132.7ms\n",
      "Speed: 4.0ms preprocess, 132.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 128.4ms\n",
      "Speed: 3.6ms preprocess, 128.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 157.5ms\n",
      "Speed: 4.5ms preprocess, 157.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 132.3ms\n",
      "Speed: 4.0ms preprocess, 132.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 146.1ms\n",
      "Speed: 4.0ms preprocess, 146.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 192.9ms\n",
      "Speed: 7.0ms preprocess, 192.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 142.3ms\n",
      "Speed: 5.3ms preprocess, 142.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 121.9ms\n",
      "Speed: 4.0ms preprocess, 121.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 128.5ms\n",
      "Speed: 4.0ms preprocess, 128.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 179.9ms\n",
      "Speed: 5.5ms preprocess, 179.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 152.2ms\n",
      "Speed: 4.0ms preprocess, 152.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 143.5ms\n",
      "Speed: 4.0ms preprocess, 143.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 213.5ms\n",
      "Speed: 7.1ms preprocess, 213.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 175.1ms\n",
      "Speed: 4.4ms preprocess, 175.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 164.6ms\n",
      "Speed: 6.0ms preprocess, 164.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 215.1ms\n",
      "Speed: 4.0ms preprocess, 215.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 183.8ms\n",
      "Speed: 9.6ms preprocess, 183.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 159.2ms\n",
      "Speed: 4.4ms preprocess, 159.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 166.6ms\n",
      "Speed: 3.9ms preprocess, 166.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 169.8ms\n",
      "Speed: 4.0ms preprocess, 169.8ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 238.0ms\n",
      "Speed: 5.0ms preprocess, 238.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 166.7ms\n",
      "Speed: 4.0ms preprocess, 166.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 162.1ms\n",
      "Speed: 4.7ms preprocess, 162.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 223.1ms\n",
      "Speed: 5.1ms preprocess, 223.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 176.8ms\n",
      "Speed: 5.0ms preprocess, 176.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 173.9ms\n",
      "Speed: 5.0ms preprocess, 173.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 209.1ms\n",
      "Speed: 5.0ms preprocess, 209.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 221.8ms\n",
      "Speed: 9.0ms preprocess, 221.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 167.6ms\n",
      "Speed: 5.0ms preprocess, 167.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 243.7ms\n",
      "Speed: 5.1ms preprocess, 243.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 175.8ms\n",
      "Speed: 4.0ms preprocess, 175.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 167.8ms\n",
      "Speed: 4.0ms preprocess, 167.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 174.5ms\n",
      "Speed: 4.0ms preprocess, 174.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 159.7ms\n",
      "Speed: 3.5ms preprocess, 159.7ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 152.1ms\n",
      "Speed: 5.0ms preprocess, 152.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 172.1ms\n",
      "Speed: 5.0ms preprocess, 172.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 161.0ms\n",
      "Speed: 7.0ms preprocess, 161.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 170.2ms\n",
      "Speed: 4.0ms preprocess, 170.2ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 172.3ms\n",
      "Speed: 5.0ms preprocess, 172.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 217.7ms\n",
      "Speed: 4.0ms preprocess, 217.7ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 183.5ms\n",
      "Speed: 8.1ms preprocess, 183.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 169.3ms\n",
      "Speed: 4.0ms preprocess, 169.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 178.6ms\n",
      "Speed: 4.0ms preprocess, 178.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 191.1ms\n",
      "Speed: 4.1ms preprocess, 191.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 157.4ms\n",
      "Speed: 5.2ms preprocess, 157.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 170.0ms\n",
      "Speed: 3.0ms preprocess, 170.0ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 175.0ms\n",
      "Speed: 5.0ms preprocess, 175.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 183.7ms\n",
      "Speed: 4.8ms preprocess, 183.7ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 165.9ms\n",
      "Speed: 5.4ms preprocess, 165.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 177.5ms\n",
      "Speed: 4.0ms preprocess, 177.5ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 158.0ms\n",
      "Speed: 4.4ms preprocess, 158.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 156.7ms\n",
      "Speed: 4.0ms preprocess, 156.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 176.1ms\n",
      "Speed: 4.4ms preprocess, 176.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 175.5ms\n",
      "Speed: 6.1ms preprocess, 175.5ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 176.5ms\n",
      "Speed: 5.0ms preprocess, 176.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 188.1ms\n",
      "Speed: 5.0ms preprocess, 188.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 186.2ms\n",
      "Speed: 4.9ms preprocess, 186.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 177.9ms\n",
      "Speed: 4.9ms preprocess, 177.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 172.4ms\n",
      "Speed: 4.0ms preprocess, 172.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 180.7ms\n",
      "Speed: 4.4ms preprocess, 180.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 242.6ms\n",
      "Speed: 5.9ms preprocess, 242.6ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 176.7ms\n",
      "Speed: 4.0ms preprocess, 176.7ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 152.8ms\n",
      "Speed: 5.0ms preprocess, 152.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 154.7ms\n",
      "Speed: 2.9ms preprocess, 154.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 163.7ms\n",
      "Speed: 4.9ms preprocess, 163.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 154.4ms\n",
      "Speed: 4.0ms preprocess, 154.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 162.0ms\n",
      "Speed: 4.0ms preprocess, 162.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 163.9ms\n",
      "Speed: 3.9ms preprocess, 163.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 172.1ms\n",
      "Speed: 4.5ms preprocess, 172.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 158.0ms\n",
      "Speed: 4.0ms preprocess, 158.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 193.3ms\n",
      "Speed: 6.2ms preprocess, 193.3ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 163.3ms\n",
      "Speed: 5.1ms preprocess, 163.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 158.7ms\n",
      "Speed: 5.5ms preprocess, 158.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 166.0ms\n",
      "Speed: 4.9ms preprocess, 166.0ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 212.2ms\n",
      "Speed: 7.5ms preprocess, 212.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 170.2ms\n",
      "Speed: 5.0ms preprocess, 170.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 163.3ms\n",
      "Speed: 4.0ms preprocess, 163.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 278.8ms\n",
      "Speed: 3.0ms preprocess, 278.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 256.7ms\n",
      "Speed: 4.9ms preprocess, 256.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 178.4ms\n",
      "Speed: 4.9ms preprocess, 178.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 272.1ms\n",
      "Speed: 4.0ms preprocess, 272.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 227.1ms\n",
      "Speed: 5.0ms preprocess, 227.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 165.4ms\n",
      "Speed: 4.9ms preprocess, 165.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 186.4ms\n",
      "Speed: 5.1ms preprocess, 186.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 126.6ms\n",
      "Speed: 5.0ms preprocess, 126.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 136.6ms\n",
      "Speed: 4.0ms preprocess, 136.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 178.8ms\n",
      "Speed: 3.9ms preprocess, 178.8ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 170.4ms\n",
      "Speed: 4.6ms preprocess, 170.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 239.0ms\n",
      "Speed: 8.0ms preprocess, 239.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 162.7ms\n",
      "Speed: 5.0ms preprocess, 162.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 220.3ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 5.1ms preprocess, 220.3ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 224.1ms\n",
      "Speed: 6.0ms preprocess, 224.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 209.1ms\n",
      "Speed: 5.3ms preprocess, 209.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 237.8ms\n",
      "Speed: 9.0ms preprocess, 237.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 185.4ms\n",
      "Speed: 3.9ms preprocess, 185.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 145.7ms\n",
      "Speed: 3.0ms preprocess, 145.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 243.9ms\n",
      "Speed: 7.0ms preprocess, 243.9ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 186.5ms\n",
      "Speed: 6.0ms preprocess, 186.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 148.7ms\n",
      "Speed: 3.9ms preprocess, 148.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 181.2ms\n",
      "Speed: 5.0ms preprocess, 181.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 165.6ms\n",
      "Speed: 4.1ms preprocess, 165.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 181.3ms\n",
      "Speed: 5.0ms preprocess, 181.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 275.0ms\n",
      "Speed: 6.9ms preprocess, 275.0ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 257.1ms\n",
      "Speed: 4.0ms preprocess, 257.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 195.5ms\n",
      "Speed: 9.0ms preprocess, 195.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 253.0ms\n",
      "Speed: 4.0ms preprocess, 253.0ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 298.1ms\n",
      "Speed: 7.0ms preprocess, 298.1ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 171.9ms\n",
      "Speed: 4.9ms preprocess, 171.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 180.4ms\n",
      "Speed: 3.0ms preprocess, 180.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 223.0ms\n",
      "Speed: 5.0ms preprocess, 223.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 229.7ms\n",
      "Speed: 4.0ms preprocess, 229.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 179.3ms\n",
      "Speed: 5.0ms preprocess, 179.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 271.2ms\n",
      "Speed: 6.9ms preprocess, 271.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 156.2ms\n",
      "Speed: 3.0ms preprocess, 156.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 216.9ms\n",
      "Speed: 5.1ms preprocess, 216.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 161.4ms\n",
      "Speed: 5.0ms preprocess, 161.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 187.8ms\n",
      "Speed: 4.9ms preprocess, 187.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 229.0ms\n",
      "Speed: 3.9ms preprocess, 229.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 200.2ms\n",
      "Speed: 9.0ms preprocess, 200.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 230.6ms\n",
      "Speed: 5.0ms preprocess, 230.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 175.2ms\n",
      "Speed: 4.0ms preprocess, 175.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 296.8ms\n",
      "Speed: 7.0ms preprocess, 296.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 179.1ms\n",
      "Speed: 4.1ms preprocess, 179.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 148.8ms\n",
      "Speed: 4.0ms preprocess, 148.8ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 180.8ms\n",
      "Speed: 2.9ms preprocess, 180.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 229.3ms\n",
      "Speed: 5.0ms preprocess, 229.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 7 persons, 170.8ms\n",
      "Speed: 5.1ms preprocess, 170.8ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 151.4ms\n",
      "Speed: 4.9ms preprocess, 151.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 174.1ms\n",
      "Speed: 5.0ms preprocess, 174.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 162.1ms\n",
      "Speed: 5.1ms preprocess, 162.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 158.9ms\n",
      "Speed: 3.9ms preprocess, 158.9ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 157.6ms\n",
      "Speed: 4.9ms preprocess, 157.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 165.3ms\n",
      "Speed: 4.9ms preprocess, 165.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 152.4ms\n",
      "Speed: 5.6ms preprocess, 152.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 176.5ms\n",
      "Speed: 5.0ms preprocess, 176.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 204.4ms\n",
      "Speed: 4.9ms preprocess, 204.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 301.1ms\n",
      "Speed: 5.0ms preprocess, 301.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 175.2ms\n",
      "Speed: 4.0ms preprocess, 175.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 161.3ms\n",
      "Speed: 4.0ms preprocess, 161.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 181.9ms\n",
      "Speed: 5.0ms preprocess, 181.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 247.3ms\n",
      "Speed: 8.1ms preprocess, 247.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 160.5ms\n",
      "Speed: 3.0ms preprocess, 160.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 166.5ms\n",
      "Speed: 4.0ms preprocess, 166.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 164.9ms\n",
      "Speed: 4.0ms preprocess, 164.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 148.5ms\n",
      "Speed: 5.0ms preprocess, 148.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 181.0ms\n",
      "Speed: 5.0ms preprocess, 181.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 188.8ms\n",
      "Speed: 4.9ms preprocess, 188.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 186.5ms\n",
      "Speed: 5.0ms preprocess, 186.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 174.1ms\n",
      "Speed: 4.0ms preprocess, 174.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 223.7ms\n",
      "Speed: 6.0ms preprocess, 223.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 162.1ms\n",
      "Speed: 4.9ms preprocess, 162.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 163.0ms\n",
      "Speed: 4.0ms preprocess, 163.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 234.4ms\n",
      "Speed: 5.9ms preprocess, 234.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 173.5ms\n",
      "Speed: 4.0ms preprocess, 173.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 166.8ms\n",
      "Speed: 5.0ms preprocess, 166.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 164.7ms\n",
      "Speed: 3.9ms preprocess, 164.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 137.5ms\n",
      "Speed: 5.0ms preprocess, 137.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 143.4ms\n",
      "Speed: 4.9ms preprocess, 143.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 131.2ms\n",
      "Speed: 4.0ms preprocess, 131.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 116.0ms\n",
      "Speed: 4.0ms preprocess, 116.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 145.3ms\n",
      "Speed: 5.2ms preprocess, 145.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 181.7ms\n",
      "Speed: 5.5ms preprocess, 181.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 158.5ms\n",
      "Speed: 3.9ms preprocess, 158.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 173.7ms\n",
      "Speed: 4.0ms preprocess, 173.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 176.3ms\n",
      "Speed: 5.0ms preprocess, 176.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 144.7ms\n",
      "Speed: 4.1ms preprocess, 144.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 152.2ms\n",
      "Speed: 3.6ms preprocess, 152.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 177.6ms\n",
      "Speed: 7.3ms preprocess, 177.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 72.6ms\n",
      "Speed: 4.3ms preprocess, 72.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 86.1ms\n",
      "Speed: 2.0ms preprocess, 86.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 75.3ms\n",
      "Speed: 2.0ms preprocess, 75.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 80.6ms\n",
      "Speed: 3.0ms preprocess, 80.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 94.7ms\n",
      "Speed: 3.3ms preprocess, 94.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 63.4ms\n",
      "Speed: 1.0ms preprocess, 63.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 95.8ms\n",
      "Speed: 2.8ms preprocess, 95.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 71.1ms\n",
      "Speed: 2.0ms preprocess, 71.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 80.9ms\n",
      "Speed: 2.5ms preprocess, 80.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 92.2ms\n",
      "Speed: 2.4ms preprocess, 92.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 74.3ms\n",
      "Speed: 2.0ms preprocess, 74.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 83.9ms\n",
      "Speed: 2.1ms preprocess, 83.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 119.3ms\n",
      "Speed: 4.5ms preprocess, 119.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 124.1ms\n",
      "Speed: 3.0ms preprocess, 124.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 120.4ms\n",
      "Speed: 4.0ms preprocess, 120.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 155.7ms\n",
      "Speed: 6.0ms preprocess, 155.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 117.7ms\n",
      "Speed: 3.0ms preprocess, 117.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 190.4ms\n",
      "Speed: 5.0ms preprocess, 190.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 125.3ms\n",
      "Speed: 3.9ms preprocess, 125.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 160.9ms\n",
      "Speed: 4.1ms preprocess, 160.9ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 186.2ms\n",
      "Speed: 6.9ms preprocess, 186.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 154.7ms\n",
      "Speed: 4.0ms preprocess, 154.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 197.2ms\n",
      "Speed: 4.0ms preprocess, 197.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 143.9ms\n",
      "Speed: 3.0ms preprocess, 143.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 141.3ms\n",
      "Speed: 5.5ms preprocess, 141.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 139.5ms\n",
      "Speed: 5.0ms preprocess, 139.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 152.5ms\n",
      "Speed: 3.0ms preprocess, 152.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 214.0ms\n",
      "Speed: 7.5ms preprocess, 214.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 133.5ms\n",
      "Speed: 3.9ms preprocess, 133.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 142.3ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 3.0ms preprocess, 142.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 150.8ms\n",
      "Speed: 4.0ms preprocess, 150.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 150.8ms\n",
      "Speed: 5.0ms preprocess, 150.8ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 142.2ms\n",
      "Speed: 4.0ms preprocess, 142.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 138.1ms\n",
      "Speed: 3.0ms preprocess, 138.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 134.6ms\n",
      "Speed: 4.0ms preprocess, 134.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 142.6ms\n",
      "Speed: 4.0ms preprocess, 142.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 120.3ms\n",
      "Speed: 4.0ms preprocess, 120.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 135.0ms\n",
      "Speed: 4.0ms preprocess, 135.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 171.2ms\n",
      "Speed: 4.0ms preprocess, 171.2ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 173.3ms\n",
      "Speed: 4.0ms preprocess, 173.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 160.0ms\n",
      "Speed: 4.0ms preprocess, 160.0ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 164.5ms\n",
      "Speed: 4.9ms preprocess, 164.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 159.9ms\n",
      "Speed: 4.0ms preprocess, 159.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 165.4ms\n",
      "Speed: 3.9ms preprocess, 165.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 154.1ms\n",
      "Speed: 5.0ms preprocess, 154.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 128.1ms\n",
      "Speed: 4.0ms preprocess, 128.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 253.0ms\n",
      "Speed: 6.9ms preprocess, 253.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 155.9ms\n",
      "Speed: 4.0ms preprocess, 155.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 149.4ms\n",
      "Speed: 3.9ms preprocess, 149.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 244.9ms\n",
      "Speed: 4.3ms preprocess, 244.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 144.1ms\n",
      "Speed: 3.9ms preprocess, 144.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 151.2ms\n",
      "Speed: 4.0ms preprocess, 151.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 138.8ms\n",
      "Speed: 4.0ms preprocess, 138.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 158.8ms\n",
      "Speed: 10.0ms preprocess, 158.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 137.0ms\n",
      "Speed: 4.9ms preprocess, 137.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 131.9ms\n",
      "Speed: 3.9ms preprocess, 131.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 172.7ms\n",
      "Speed: 5.0ms preprocess, 172.7ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 168.6ms\n",
      "Speed: 8.0ms preprocess, 168.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 145.0ms\n",
      "Speed: 5.0ms preprocess, 145.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 162.7ms\n",
      "Speed: 4.5ms preprocess, 162.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 249.0ms\n",
      "Speed: 6.4ms preprocess, 249.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 160.5ms\n",
      "Speed: 4.5ms preprocess, 160.5ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 104.1ms\n",
      "Speed: 4.0ms preprocess, 104.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 126.6ms\n",
      "Speed: 3.5ms preprocess, 126.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 131.8ms\n",
      "Speed: 3.0ms preprocess, 131.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 170.7ms\n",
      "Speed: 4.9ms preprocess, 170.7ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 135.8ms\n",
      "Speed: 3.0ms preprocess, 135.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 6 persons, 169.4ms\n",
      "Speed: 4.0ms preprocess, 169.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 149.0ms\n",
      "Speed: 4.1ms preprocess, 149.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 120.1ms\n",
      "Speed: 5.0ms preprocess, 120.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 151.4ms\n",
      "Speed: 5.0ms preprocess, 151.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 155.5ms\n",
      "Speed: 4.0ms preprocess, 155.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 158.7ms\n",
      "Speed: 3.0ms preprocess, 158.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 160.3ms\n",
      "Speed: 5.0ms preprocess, 160.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 112.7ms\n",
      "Speed: 3.0ms preprocess, 112.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 108.9ms\n",
      "Speed: 3.0ms preprocess, 108.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 121.5ms\n",
      "Speed: 4.0ms preprocess, 121.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 99.5ms\n",
      "Speed: 3.5ms preprocess, 99.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 110.5ms\n",
      "Speed: 3.0ms preprocess, 110.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 218.5ms\n",
      "Speed: 6.0ms preprocess, 218.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 206.0ms\n",
      "Speed: 5.0ms preprocess, 206.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 239.6ms\n",
      "Speed: 5.4ms preprocess, 239.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 162.0ms\n",
      "Speed: 4.0ms preprocess, 162.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 244.3ms\n",
      "Speed: 8.4ms preprocess, 244.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 175.9ms\n",
      "Speed: 6.0ms preprocess, 175.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 168.7ms\n",
      "Speed: 5.0ms preprocess, 168.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 275.1ms\n",
      "Speed: 5.0ms preprocess, 275.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 179.0ms\n",
      "Speed: 4.1ms preprocess, 179.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 194.7ms\n",
      "Speed: 8.0ms preprocess, 194.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 162.5ms\n",
      "Speed: 4.4ms preprocess, 162.5ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 153.8ms\n",
      "Speed: 5.5ms preprocess, 153.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 158.7ms\n",
      "Speed: 5.1ms preprocess, 158.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 169.4ms\n",
      "Speed: 5.0ms preprocess, 169.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 206.8ms\n",
      "Speed: 4.9ms preprocess, 206.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 193.0ms\n",
      "Speed: 6.9ms preprocess, 193.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 153.0ms\n",
      "Speed: 4.9ms preprocess, 153.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 248.7ms\n",
      "Speed: 5.0ms preprocess, 248.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 171.9ms\n",
      "Speed: 4.0ms preprocess, 171.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 164.0ms\n",
      "Speed: 5.0ms preprocess, 164.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 166.8ms\n",
      "Speed: 5.0ms preprocess, 166.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 153.8ms\n",
      "Speed: 5.1ms preprocess, 153.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 266.4ms\n",
      "Speed: 5.9ms preprocess, 266.4ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 164.7ms\n",
      "Speed: 5.0ms preprocess, 164.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 223.4ms\n",
      "Speed: 9.5ms preprocess, 223.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 158.3ms\n",
      "Speed: 5.0ms preprocess, 158.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 178.1ms\n",
      "Speed: 7.0ms preprocess, 178.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 226.5ms\n",
      "Speed: 6.1ms preprocess, 226.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 176.0ms\n",
      "Speed: 4.0ms preprocess, 176.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 173.8ms\n",
      "Speed: 5.0ms preprocess, 173.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 192.2ms\n",
      "Speed: 4.9ms preprocess, 192.2ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 157.5ms\n",
      "Speed: 5.7ms preprocess, 157.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 251.6ms\n",
      "Speed: 5.9ms preprocess, 251.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 159.7ms\n",
      "Speed: 5.1ms preprocess, 159.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 171.3ms\n",
      "Speed: 4.8ms preprocess, 171.3ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 162.3ms\n",
      "Speed: 4.6ms preprocess, 162.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 132.2ms\n",
      "Speed: 4.0ms preprocess, 132.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 144.9ms\n",
      "Speed: 3.9ms preprocess, 144.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 247.4ms\n",
      "Speed: 7.9ms preprocess, 247.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 248.4ms\n",
      "Speed: 6.0ms preprocess, 248.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 155.5ms\n",
      "Speed: 3.2ms preprocess, 155.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 136.6ms\n",
      "Speed: 5.0ms preprocess, 136.6ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 143.0ms\n",
      "Speed: 4.0ms preprocess, 143.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 167.4ms\n",
      "Speed: 3.0ms preprocess, 167.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 119.6ms\n",
      "Speed: 4.0ms preprocess, 119.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 135.4ms\n",
      "Speed: 3.0ms preprocess, 135.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 134.1ms\n",
      "Speed: 3.0ms preprocess, 134.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 137.2ms\n",
      "Speed: 3.0ms preprocess, 137.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 172.8ms\n",
      "Speed: 3.9ms preprocess, 172.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 128.8ms\n",
      "Speed: 3.1ms preprocess, 128.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 133.9ms\n",
      "Speed: 3.5ms preprocess, 133.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 134.9ms\n",
      "Speed: 4.0ms preprocess, 134.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 149.8ms\n",
      "Speed: 4.4ms preprocess, 149.8ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 223.7ms\n",
      "Speed: 5.0ms preprocess, 223.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 130.8ms\n",
      "Speed: 4.0ms preprocess, 130.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 143.6ms\n",
      "Speed: 3.9ms preprocess, 143.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 146.0ms\n",
      "Speed: 4.0ms preprocess, 146.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 245.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 7.3ms preprocess, 245.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 237.7ms\n",
      "Speed: 4.0ms preprocess, 237.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 177.9ms\n",
      "Speed: 4.4ms preprocess, 177.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 159.4ms\n",
      "Speed: 4.0ms preprocess, 159.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 186.7ms\n",
      "Speed: 5.0ms preprocess, 186.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 179.6ms\n",
      "Speed: 6.0ms preprocess, 179.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 244.5ms\n",
      "Speed: 5.1ms preprocess, 244.5ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 208.6ms\n",
      "Speed: 4.0ms preprocess, 208.6ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 188.3ms\n",
      "Speed: 5.0ms preprocess, 188.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 181.1ms\n",
      "Speed: 5.0ms preprocess, 181.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 177.6ms\n",
      "Speed: 5.0ms preprocess, 177.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 204.3ms\n",
      "Speed: 4.0ms preprocess, 204.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 169.9ms\n",
      "Speed: 5.0ms preprocess, 169.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 170.9ms\n",
      "Speed: 4.5ms preprocess, 170.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 167.0ms\n",
      "Speed: 5.0ms preprocess, 167.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 164.6ms\n",
      "Speed: 5.0ms preprocess, 164.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 177.1ms\n",
      "Speed: 4.0ms preprocess, 177.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 179.0ms\n",
      "Speed: 5.0ms preprocess, 179.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 182.3ms\n",
      "Speed: 4.0ms preprocess, 182.3ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 223.0ms\n",
      "Speed: 5.0ms preprocess, 223.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 151.8ms\n",
      "Speed: 5.0ms preprocess, 151.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 206.2ms\n",
      "Speed: 5.0ms preprocess, 206.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 241.8ms\n",
      "Speed: 4.9ms preprocess, 241.8ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 171.5ms\n",
      "Speed: 3.0ms preprocess, 171.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 180.4ms\n",
      "Speed: 6.0ms preprocess, 180.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 193.7ms\n",
      "Speed: 6.0ms preprocess, 193.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 176.3ms\n",
      "Speed: 5.0ms preprocess, 176.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 275.1ms\n",
      "Speed: 5.5ms preprocess, 275.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 184.2ms\n",
      "Speed: 4.5ms preprocess, 184.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 158.0ms\n",
      "Speed: 4.0ms preprocess, 158.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 217.8ms\n",
      "Speed: 4.5ms preprocess, 217.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 194.2ms\n",
      "Speed: 4.1ms preprocess, 194.2ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 168.4ms\n",
      "Speed: 4.4ms preprocess, 168.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 229.6ms\n",
      "Speed: 5.4ms preprocess, 229.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 244.8ms\n",
      "Speed: 6.0ms preprocess, 244.8ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 196.5ms\n",
      "Speed: 5.0ms preprocess, 196.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 205.1ms\n",
      "Speed: 4.4ms preprocess, 205.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 175.6ms\n",
      "Speed: 2.9ms preprocess, 175.6ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 160.4ms\n",
      "Speed: 3.7ms preprocess, 160.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 178.3ms\n",
      "Speed: 6.0ms preprocess, 178.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 170.4ms\n",
      "Speed: 4.9ms preprocess, 170.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 169.7ms\n",
      "Speed: 5.2ms preprocess, 169.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 164.0ms\n",
      "Speed: 4.1ms preprocess, 164.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 170.5ms\n",
      "Speed: 5.0ms preprocess, 170.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 186.0ms\n",
      "Speed: 5.0ms preprocess, 186.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 164.6ms\n",
      "Speed: 4.0ms preprocess, 164.6ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 235.0ms\n",
      "Speed: 4.4ms preprocess, 235.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 185.5ms\n",
      "Speed: 3.9ms preprocess, 185.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 165.7ms\n",
      "Speed: 4.0ms preprocess, 165.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 145.5ms\n",
      "Speed: 4.5ms preprocess, 145.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 142.8ms\n",
      "Speed: 4.0ms preprocess, 142.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 142.0ms\n",
      "Speed: 3.0ms preprocess, 142.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 247.3ms\n",
      "Speed: 5.1ms preprocess, 247.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 152.2ms\n",
      "Speed: 3.9ms preprocess, 152.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 279.0ms\n",
      "Speed: 10.0ms preprocess, 279.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 228.3ms\n",
      "Speed: 5.0ms preprocess, 228.3ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 171.9ms\n",
      "Speed: 4.1ms preprocess, 171.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 216.7ms\n",
      "Speed: 8.9ms preprocess, 216.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 200.3ms\n",
      "Speed: 8.9ms preprocess, 200.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 148.0ms\n",
      "Speed: 3.4ms preprocess, 148.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 143.1ms\n",
      "Speed: 5.0ms preprocess, 143.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 146.7ms\n",
      "Speed: 4.9ms preprocess, 146.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 136.4ms\n",
      "Speed: 4.0ms preprocess, 136.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 158.6ms\n",
      "Speed: 5.0ms preprocess, 158.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 125.3ms\n",
      "Speed: 4.0ms preprocess, 125.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 137.0ms\n",
      "Speed: 4.0ms preprocess, 137.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 188.3ms\n",
      "Speed: 4.0ms preprocess, 188.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 197.0ms\n",
      "Speed: 4.0ms preprocess, 197.0ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 166.4ms\n",
      "Speed: 4.3ms preprocess, 166.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 152.3ms\n",
      "Speed: 6.0ms preprocess, 152.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 206.7ms\n",
      "Speed: 5.0ms preprocess, 206.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 170.3ms\n",
      "Speed: 5.0ms preprocess, 170.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 175.0ms\n",
      "Speed: 4.0ms preprocess, 175.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 162.7ms\n",
      "Speed: 4.5ms preprocess, 162.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 159.7ms\n",
      "Speed: 4.0ms preprocess, 159.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 165.7ms\n",
      "Speed: 5.4ms preprocess, 165.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 200.2ms\n",
      "Speed: 5.0ms preprocess, 200.2ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 176.8ms\n",
      "Speed: 6.0ms preprocess, 176.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 171.6ms\n",
      "Speed: 5.2ms preprocess, 171.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 164.0ms\n",
      "Speed: 3.9ms preprocess, 164.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 209.4ms\n",
      "Speed: 5.5ms preprocess, 209.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 190.5ms\n",
      "Speed: 3.0ms preprocess, 190.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 201.0ms\n",
      "Speed: 6.4ms preprocess, 201.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 179.2ms\n",
      "Speed: 5.0ms preprocess, 179.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 175.1ms\n",
      "Speed: 4.0ms preprocess, 175.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 169.0ms\n",
      "Speed: 4.9ms preprocess, 169.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 188.9ms\n",
      "Speed: 5.0ms preprocess, 188.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 179.5ms\n",
      "Speed: 4.0ms preprocess, 179.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 214.3ms\n",
      "Speed: 5.5ms preprocess, 214.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 165.7ms\n",
      "Speed: 3.1ms preprocess, 165.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 153.0ms\n",
      "Speed: 5.0ms preprocess, 153.0ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 169.0ms\n",
      "Speed: 4.9ms preprocess, 169.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 158.7ms\n",
      "Speed: 3.9ms preprocess, 158.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 263.1ms\n",
      "Speed: 8.0ms preprocess, 263.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 183.0ms\n",
      "Speed: 3.1ms preprocess, 183.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 184.7ms\n",
      "Speed: 4.9ms preprocess, 184.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 215.5ms\n",
      "Speed: 5.0ms preprocess, 215.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 156.7ms\n",
      "Speed: 3.9ms preprocess, 156.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 173.3ms\n",
      "Speed: 4.0ms preprocess, 173.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 189.5ms\n",
      "Speed: 4.0ms preprocess, 189.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 162.4ms\n",
      "Speed: 5.0ms preprocess, 162.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 165.5ms\n",
      "Speed: 3.9ms preprocess, 165.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 202.5ms\n",
      "Speed: 5.0ms preprocess, 202.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 158.1ms\n",
      "Speed: 3.9ms preprocess, 158.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 128.6ms\n",
      "Speed: 4.0ms preprocess, 128.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 144.7ms\n",
      "Speed: 3.9ms preprocess, 144.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 163.4ms\n",
      "Speed: 4.9ms preprocess, 163.4ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 147.5ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 5.0ms preprocess, 147.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 183.9ms\n",
      "Speed: 5.9ms preprocess, 183.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 164.9ms\n",
      "Speed: 3.9ms preprocess, 164.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 249.1ms\n",
      "Speed: 8.6ms preprocess, 249.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 234.4ms\n",
      "Speed: 6.0ms preprocess, 234.4ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 185.8ms\n",
      "Speed: 4.0ms preprocess, 185.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 168.5ms\n",
      "Speed: 5.0ms preprocess, 168.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 169.7ms\n",
      "Speed: 4.9ms preprocess, 169.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 168.4ms\n",
      "Speed: 3.0ms preprocess, 168.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 189.9ms\n",
      "Speed: 5.1ms preprocess, 189.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 164.3ms\n",
      "Speed: 4.0ms preprocess, 164.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 179.0ms\n",
      "Speed: 5.5ms preprocess, 179.0ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 175.4ms\n",
      "Speed: 4.0ms preprocess, 175.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 159.1ms\n",
      "Speed: 4.0ms preprocess, 159.1ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 242.8ms\n",
      "Speed: 5.0ms preprocess, 242.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 194.9ms\n",
      "Speed: 5.0ms preprocess, 194.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 177.0ms\n",
      "Speed: 5.2ms preprocess, 177.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 202.5ms\n",
      "Speed: 5.0ms preprocess, 202.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 163.6ms\n",
      "Speed: 3.9ms preprocess, 163.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 180.7ms\n",
      "Speed: 5.0ms preprocess, 180.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 187.0ms\n",
      "Speed: 4.5ms preprocess, 187.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 131.1ms\n",
      "Speed: 3.9ms preprocess, 131.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 138.5ms\n",
      "Speed: 4.0ms preprocess, 138.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 166.4ms\n",
      "Speed: 5.2ms preprocess, 166.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 164.1ms\n",
      "Speed: 4.0ms preprocess, 164.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 157.3ms\n",
      "Speed: 5.0ms preprocess, 157.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 155.7ms\n",
      "Speed: 5.0ms preprocess, 155.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 111.3ms\n",
      "Speed: 4.2ms preprocess, 111.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 167.0ms\n",
      "Speed: 5.0ms preprocess, 167.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 199.6ms\n",
      "Speed: 5.0ms preprocess, 199.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 155.2ms\n",
      "Speed: 5.0ms preprocess, 155.2ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 170.7ms\n",
      "Speed: 5.0ms preprocess, 170.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 205.4ms\n",
      "Speed: 4.0ms preprocess, 205.4ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 186.4ms\n",
      "Speed: 3.9ms preprocess, 186.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 124.6ms\n",
      "Speed: 3.0ms preprocess, 124.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 164.2ms\n",
      "Speed: 5.0ms preprocess, 164.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 146.6ms\n",
      "Speed: 3.4ms preprocess, 146.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 135.4ms\n",
      "Speed: 5.0ms preprocess, 135.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 136.8ms\n",
      "Speed: 4.0ms preprocess, 136.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 138.2ms\n",
      "Speed: 3.9ms preprocess, 138.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 148.5ms\n",
      "Speed: 6.0ms preprocess, 148.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 148.5ms\n",
      "Speed: 4.0ms preprocess, 148.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 142.1ms\n",
      "Speed: 5.0ms preprocess, 142.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 146.3ms\n",
      "Speed: 3.2ms preprocess, 146.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 180.4ms\n",
      "Speed: 5.1ms preprocess, 180.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 152.1ms\n",
      "Speed: 4.0ms preprocess, 152.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 133.6ms\n",
      "Speed: 4.0ms preprocess, 133.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 143.1ms\n",
      "Speed: 4.0ms preprocess, 143.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 144.3ms\n",
      "Speed: 3.0ms preprocess, 144.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 181.4ms\n",
      "Speed: 4.0ms preprocess, 181.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 142.8ms\n",
      "Speed: 4.0ms preprocess, 142.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 128.1ms\n",
      "Speed: 3.1ms preprocess, 128.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 146.2ms\n",
      "Speed: 4.0ms preprocess, 146.2ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 182.8ms\n",
      "Speed: 5.0ms preprocess, 182.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 163.3ms\n",
      "Speed: 3.0ms preprocess, 163.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 174.7ms\n",
      "Speed: 3.9ms preprocess, 174.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 183.8ms\n",
      "Speed: 4.1ms preprocess, 183.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 159.3ms\n",
      "Speed: 4.9ms preprocess, 159.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 172.2ms\n",
      "Speed: 4.9ms preprocess, 172.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 184.7ms\n",
      "Speed: 5.0ms preprocess, 184.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 174.2ms\n",
      "Speed: 6.0ms preprocess, 174.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 166.2ms\n",
      "Speed: 5.0ms preprocess, 166.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 170.0ms\n",
      "Speed: 3.9ms preprocess, 170.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 186.1ms\n",
      "Speed: 4.9ms preprocess, 186.1ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 162.9ms\n",
      "Speed: 4.4ms preprocess, 162.9ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 203.0ms\n",
      "Speed: 5.0ms preprocess, 203.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 176.5ms\n",
      "Speed: 5.0ms preprocess, 176.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 164.9ms\n",
      "Speed: 3.1ms preprocess, 164.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 173.0ms\n",
      "Speed: 5.4ms preprocess, 173.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 156.1ms\n",
      "Speed: 4.0ms preprocess, 156.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 159.1ms\n",
      "Speed: 5.2ms preprocess, 159.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 149.7ms\n",
      "Speed: 4.0ms preprocess, 149.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 215.3ms\n",
      "Speed: 8.0ms preprocess, 215.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 229.1ms\n",
      "Speed: 9.0ms preprocess, 229.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 201.6ms\n",
      "Speed: 4.0ms preprocess, 201.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 183.3ms\n",
      "Speed: 5.0ms preprocess, 183.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 164.8ms\n",
      "Speed: 5.0ms preprocess, 164.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 167.3ms\n",
      "Speed: 4.1ms preprocess, 167.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 132.2ms\n",
      "Speed: 4.0ms preprocess, 132.2ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 179.8ms\n",
      "Speed: 5.0ms preprocess, 179.8ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 206.3ms\n",
      "Speed: 3.9ms preprocess, 206.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 162.1ms\n",
      "Speed: 5.0ms preprocess, 162.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 196.6ms\n",
      "Speed: 8.0ms preprocess, 196.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 168.1ms\n",
      "Speed: 4.0ms preprocess, 168.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 234.1ms\n",
      "Speed: 7.4ms preprocess, 234.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 165.4ms\n",
      "Speed: 5.0ms preprocess, 165.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 172.3ms\n",
      "Speed: 4.0ms preprocess, 172.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 166.9ms\n",
      "Speed: 5.6ms preprocess, 166.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 161.2ms\n",
      "Speed: 5.0ms preprocess, 161.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 241.8ms\n",
      "Speed: 9.3ms preprocess, 241.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 166.0ms\n",
      "Speed: 4.0ms preprocess, 166.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 150.7ms\n",
      "Speed: 3.5ms preprocess, 150.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 258.2ms\n",
      "Speed: 7.6ms preprocess, 258.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 164.4ms\n",
      "Speed: 5.0ms preprocess, 164.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 242.6ms\n",
      "Speed: 7.1ms preprocess, 242.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 167.3ms\n",
      "Speed: 4.3ms preprocess, 167.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 161.8ms\n",
      "Speed: 5.0ms preprocess, 161.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 231.6ms\n",
      "Speed: 5.0ms preprocess, 231.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 158.1ms\n",
      "Speed: 5.0ms preprocess, 158.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 170.6ms\n",
      "Speed: 3.9ms preprocess, 170.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 173.2ms\n",
      "Speed: 5.0ms preprocess, 173.2ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 148.1ms\n",
      "Speed: 4.9ms preprocess, 148.1ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 163.9ms\n",
      "Speed: 5.0ms preprocess, 163.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 158.5ms\n",
      "Speed: 5.0ms preprocess, 158.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 262.2ms\n",
      "Speed: 6.0ms preprocess, 262.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 153.1ms\n",
      "Speed: 4.9ms preprocess, 153.1ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 158.7ms\n",
      "Speed: 4.9ms preprocess, 158.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 169.3ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 5.0ms preprocess, 169.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 153.7ms\n",
      "Speed: 5.0ms preprocess, 153.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 172.4ms\n",
      "Speed: 4.9ms preprocess, 172.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 160.5ms\n",
      "Speed: 4.0ms preprocess, 160.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 182.1ms\n",
      "Speed: 4.0ms preprocess, 182.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 178.0ms\n",
      "Speed: 4.0ms preprocess, 178.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 172.7ms\n",
      "Speed: 3.9ms preprocess, 172.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 165.1ms\n",
      "Speed: 5.1ms preprocess, 165.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 168.3ms\n",
      "Speed: 4.9ms preprocess, 168.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 154.8ms\n",
      "Speed: 5.0ms preprocess, 154.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 176.4ms\n",
      "Speed: 4.0ms preprocess, 176.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 150.1ms\n",
      "Speed: 4.0ms preprocess, 150.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 190.7ms\n",
      "Speed: 5.0ms preprocess, 190.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 181.5ms\n",
      "Speed: 5.0ms preprocess, 181.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 167.5ms\n",
      "Speed: 3.9ms preprocess, 167.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 176.5ms\n",
      "Speed: 5.0ms preprocess, 176.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 171.0ms\n",
      "Speed: 4.0ms preprocess, 171.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 205.6ms\n",
      "Speed: 5.0ms preprocess, 205.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 165.1ms\n",
      "Speed: 4.0ms preprocess, 165.1ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 152.6ms\n",
      "Speed: 5.0ms preprocess, 152.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 164.4ms\n",
      "Speed: 4.0ms preprocess, 164.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 148.7ms\n",
      "Speed: 3.5ms preprocess, 148.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 151.5ms\n",
      "Speed: 3.0ms preprocess, 151.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 155.0ms\n",
      "Speed: 4.0ms preprocess, 155.0ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 188.3ms\n",
      "Speed: 5.0ms preprocess, 188.3ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 170.9ms\n",
      "Speed: 4.0ms preprocess, 170.9ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 170.9ms\n",
      "Speed: 4.9ms preprocess, 170.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 174.6ms\n",
      "Speed: 5.0ms preprocess, 174.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 172.8ms\n",
      "Speed: 4.0ms preprocess, 172.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 181.6ms\n",
      "Speed: 5.0ms preprocess, 181.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 174.1ms\n",
      "Speed: 3.1ms preprocess, 174.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 133.6ms\n",
      "Speed: 4.0ms preprocess, 133.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 119.0ms\n",
      "Speed: 3.0ms preprocess, 119.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 182.4ms\n",
      "Speed: 4.5ms preprocess, 182.4ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 129.5ms\n",
      "Speed: 3.0ms preprocess, 129.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 182.1ms\n",
      "Speed: 4.0ms preprocess, 182.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 221.4ms\n",
      "Speed: 5.0ms preprocess, 221.4ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 203.7ms\n",
      "Speed: 4.9ms preprocess, 203.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 173.2ms\n",
      "Speed: 4.0ms preprocess, 173.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 278.8ms\n",
      "Speed: 4.6ms preprocess, 278.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 181.3ms\n",
      "Speed: 4.1ms preprocess, 181.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 172.2ms\n",
      "Speed: 4.9ms preprocess, 172.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 118.6ms\n",
      "Speed: 4.1ms preprocess, 118.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 125.0ms\n",
      "Speed: 4.0ms preprocess, 125.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 181.8ms\n",
      "Speed: 4.0ms preprocess, 181.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 215.3ms\n",
      "Speed: 3.0ms preprocess, 215.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 109.4ms\n",
      "Speed: 3.0ms preprocess, 109.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 119.8ms\n",
      "Speed: 3.0ms preprocess, 119.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 122.0ms\n",
      "Speed: 3.0ms preprocess, 122.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 177.8ms\n",
      "Speed: 4.0ms preprocess, 177.8ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 195.0ms\n",
      "Speed: 6.0ms preprocess, 195.0ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 166.5ms\n",
      "Speed: 5.0ms preprocess, 166.5ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 478.2ms\n",
      "Speed: 8.0ms preprocess, 478.2ms inference, 8.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 531.4ms\n",
      "Speed: 3.8ms preprocess, 531.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 441.9ms\n",
      "Speed: 10.3ms preprocess, 441.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 510.6ms\n",
      "Speed: 63.1ms preprocess, 510.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 567.9ms\n",
      "Speed: 5.0ms preprocess, 567.9ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 414.2ms\n",
      "Speed: 5.0ms preprocess, 414.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 283.2ms\n",
      "Speed: 3.0ms preprocess, 283.2ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 276.9ms\n",
      "Speed: 8.7ms preprocess, 276.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 317.8ms\n",
      "Speed: 4.5ms preprocess, 317.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 316.6ms\n",
      "Speed: 7.0ms preprocess, 316.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 360.9ms\n",
      "Speed: 6.0ms preprocess, 360.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 321.0ms\n",
      "Speed: 3.5ms preprocess, 321.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 344.7ms\n",
      "Speed: 7.0ms preprocess, 344.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 281.9ms\n",
      "Speed: 6.0ms preprocess, 281.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 277.5ms\n",
      "Speed: 3.6ms preprocess, 277.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 263.6ms\n",
      "Speed: 6.9ms preprocess, 263.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 190.3ms\n",
      "Speed: 3.0ms preprocess, 190.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 325.0ms\n",
      "Speed: 6.0ms preprocess, 325.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 259.8ms\n",
      "Speed: 6.5ms preprocess, 259.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 333.0ms\n",
      "Speed: 4.0ms preprocess, 333.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 211.6ms\n",
      "Speed: 4.0ms preprocess, 211.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 201.2ms\n",
      "Speed: 3.6ms preprocess, 201.2ms inference, 7.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 327.6ms\n",
      "Speed: 4.3ms preprocess, 327.6ms inference, 14.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 190.7ms\n",
      "Speed: 5.8ms preprocess, 190.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 187.3ms\n",
      "Speed: 4.1ms preprocess, 187.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 262.6ms\n",
      "Speed: 7.0ms preprocess, 262.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 296.4ms\n",
      "Speed: 4.0ms preprocess, 296.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 196.8ms\n",
      "Speed: 3.4ms preprocess, 196.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 169.7ms\n",
      "Speed: 4.0ms preprocess, 169.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 237.4ms\n",
      "Speed: 7.0ms preprocess, 237.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 375.4ms\n",
      "Speed: 11.0ms preprocess, 375.4ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 356.4ms\n",
      "Speed: 23.9ms preprocess, 356.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[31m•\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "classes = [0]\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture('table_1.mp4')  # replace with your video file path\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Get the default resolutions\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "\n",
    "# Define the codec and create a VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # or use 'XVID'\n",
    "out = cv2.VideoWriter('table_tennis_output_1.mp4', fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "\n",
    "table_tennis_time_1=[]\n",
    "counter = 0  # Initialize counter\n",
    "continuous_detection = False\n",
    "\n",
    "while True:\n",
    "    # Read the frame from the video file\n",
    "    _, img = cap.read()\n",
    "    \n",
    "    if not _:\n",
    "        break\n",
    "    \n",
    "    frame_no = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "    timestamp = frame_no / fps\n",
    "    \n",
    "    # Run inference on the frame\n",
    "    results = model.predict(img,classes=classes)\n",
    "    \n",
    "    detected_classes = [box.cls for box in results[0].boxes]\n",
    "    if 0 in detected_classes:\n",
    "        counter += 1  # Increment counter if class 0 is detected\n",
    "        if counter >= 10 * fps:  # Check if class 0 has been detected for at least 10 seconds\n",
    "            continuous_detection = True\n",
    "    else:\n",
    "        counter = 0  # Reset counter if class 0 is not detected\n",
    "        continuous_detection = False\n",
    "\n",
    "    if continuous_detection:\n",
    "        print('Table Tennis: '+'\\033[31m' + '•' + '\\033[0m')\n",
    "        table_tennis_time_1.append(timestamp)\n",
    "    else:\n",
    "        print('Table Tennis: '+'\\033[32m' + '•' + '\\033[0m')\n",
    "    \n",
    "    for r in results:\n",
    "        # Create an annotator for the image\n",
    "        annotator = Annotator(img)\n",
    "\n",
    "        # Get the bounding boxes\n",
    "        boxes = r.boxes\n",
    "\n",
    "        # Draw each bounding box on the image\n",
    "        for box in boxes:\n",
    "            b = box.xyxy[0]  # get box coordinates in (left, top, right, bottom) format\n",
    "            c = box.cls\n",
    "            annotator.box_label(b, model.names[int(c)])  # draw the box and label on the image\n",
    "\n",
    "        \n",
    "        # Get the annotated image\n",
    "        img = annotator.result()\n",
    "        \n",
    "        out.write(img)\n",
    "        \n",
    "    # Display the image with bounding boxes\n",
    "    cv2.imshow('YOLO V8 Detection', img)\n",
    "\n",
    "    # Break the loop if the 'space' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord(' '):\n",
    "        break\n",
    "\n",
    "# Release the video file and close all windows\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc203d05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6e0ca13",
   "metadata": {},
   "source": [
    "# Table Tennis-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3b42275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 persons, 522.6ms\n",
      "Speed: 5.9ms preprocess, 522.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 255.9ms\n",
      "Speed: 4.0ms preprocess, 255.9ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 195.1ms\n",
      "Speed: 5.0ms preprocess, 195.1ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 191.7ms\n",
      "Speed: 5.0ms preprocess, 191.7ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 166.0ms\n",
      "Speed: 4.0ms preprocess, 166.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 386.6ms\n",
      "Speed: 12.0ms preprocess, 386.6ms inference, 38.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 454.8ms\n",
      "Speed: 6.0ms preprocess, 454.8ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 307.4ms\n",
      "Speed: 3.5ms preprocess, 307.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 409.0ms\n",
      "Speed: 2.5ms preprocess, 409.0ms inference, 14.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 355.6ms\n",
      "Speed: 6.8ms preprocess, 355.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 452.7ms\n",
      "Speed: 7.0ms preprocess, 452.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 367.6ms\n",
      "Speed: 5.0ms preprocess, 367.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 453.5ms\n",
      "Speed: 4.5ms preprocess, 453.5ms inference, 12.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 278.7ms\n",
      "Speed: 4.9ms preprocess, 278.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 333.4ms\n",
      "Speed: 4.9ms preprocess, 333.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 252.0ms\n",
      "Speed: 2.0ms preprocess, 252.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 394.7ms\n",
      "Speed: 7.0ms preprocess, 394.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 262.8ms\n",
      "Speed: 7.4ms preprocess, 262.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 351.7ms\n",
      "Speed: 8.0ms preprocess, 351.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 343.9ms\n",
      "Speed: 7.9ms preprocess, 343.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 377.4ms\n",
      "Speed: 3.5ms preprocess, 377.4ms inference, 106.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 352.6ms\n",
      "Speed: 7.0ms preprocess, 352.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 427.8ms\n",
      "Speed: 4.0ms preprocess, 427.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 268.3ms\n",
      "Speed: 7.5ms preprocess, 268.3ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 372.9ms\n",
      "Speed: 3.0ms preprocess, 372.9ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 276.8ms\n",
      "Speed: 6.1ms preprocess, 276.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 288.5ms\n",
      "Speed: 7.0ms preprocess, 288.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 267.3ms\n",
      "Speed: 7.0ms preprocess, 267.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 345.4ms\n",
      "Speed: 9.1ms preprocess, 345.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 265.6ms\n",
      "Speed: 4.0ms preprocess, 265.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 225.1ms\n",
      "Speed: 5.4ms preprocess, 225.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 327.6ms\n",
      "Speed: 7.0ms preprocess, 327.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 355.4ms\n",
      "Speed: 4.0ms preprocess, 355.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 376.2ms\n",
      "Speed: 3.6ms preprocess, 376.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 265.0ms\n",
      "Speed: 7.0ms preprocess, 265.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 266.8ms\n",
      "Speed: 2.0ms preprocess, 266.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 273.4ms\n",
      "Speed: 4.8ms preprocess, 273.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 252.1ms\n",
      "Speed: 3.0ms preprocess, 252.1ms inference, 14.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 347.2ms\n",
      "Speed: 3.0ms preprocess, 347.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 329.4ms\n",
      "Speed: 6.5ms preprocess, 329.4ms inference, 12.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 440.5ms\n",
      "Speed: 3.9ms preprocess, 440.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 362.1ms\n",
      "Speed: 8.0ms preprocess, 362.1ms inference, 13.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 380.5ms\n",
      "Speed: 9.0ms preprocess, 380.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 5 persons, 331.4ms\n",
      "Speed: 4.3ms preprocess, 331.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 369.2ms\n",
      "Speed: 7.0ms preprocess, 369.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 333.1ms\n",
      "Speed: 4.9ms preprocess, 333.1ms inference, 7.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 310.0ms\n",
      "Speed: 8.0ms preprocess, 310.0ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 367.7ms\n",
      "Speed: 10.5ms preprocess, 367.7ms inference, 13.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 364.3ms\n",
      "Speed: 2.6ms preprocess, 364.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 348.2ms\n",
      "Speed: 4.0ms preprocess, 348.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 390.0ms\n",
      "Speed: 10.0ms preprocess, 390.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 351.1ms\n",
      "Speed: 4.5ms preprocess, 351.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 423.6ms\n",
      "Speed: 5.0ms preprocess, 423.6ms inference, 13.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 282.5ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 4.0ms preprocess, 282.5ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 402.9ms\n",
      "Speed: 8.0ms preprocess, 402.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 272.2ms\n",
      "Speed: 3.0ms preprocess, 272.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 406.9ms\n",
      "Speed: 2.8ms preprocess, 406.9ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 351.2ms\n",
      "Speed: 5.0ms preprocess, 351.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 258.6ms\n",
      "Speed: 6.0ms preprocess, 258.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 343.5ms\n",
      "Speed: 3.3ms preprocess, 343.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 396.2ms\n",
      "Speed: 7.0ms preprocess, 396.2ms inference, 13.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 339.0ms\n",
      "Speed: 4.0ms preprocess, 339.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 284.7ms\n",
      "Speed: 6.0ms preprocess, 284.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 187.3ms\n",
      "Speed: 3.5ms preprocess, 187.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 261.9ms\n",
      "Speed: 3.0ms preprocess, 261.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 364.7ms\n",
      "Speed: 4.2ms preprocess, 364.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 351.5ms\n",
      "Speed: 3.0ms preprocess, 351.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 303.8ms\n",
      "Speed: 7.9ms preprocess, 303.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 327.8ms\n",
      "Speed: 5.3ms preprocess, 327.8ms inference, 27.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 256.0ms\n",
      "Speed: 5.8ms preprocess, 256.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 309.8ms\n",
      "Speed: 4.0ms preprocess, 309.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 266.2ms\n",
      "Speed: 6.0ms preprocess, 266.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 357.4ms\n",
      "Speed: 7.0ms preprocess, 357.4ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 369.1ms\n",
      "Speed: 6.0ms preprocess, 369.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 337.8ms\n",
      "Speed: 4.0ms preprocess, 337.8ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 375.1ms\n",
      "Speed: 19.0ms preprocess, 375.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 278.5ms\n",
      "Speed: 5.8ms preprocess, 278.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 260.9ms\n",
      "Speed: 5.0ms preprocess, 260.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 308.8ms\n",
      "Speed: 50.1ms preprocess, 308.8ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 279.6ms\n",
      "Speed: 5.0ms preprocess, 279.6ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 332.3ms\n",
      "Speed: 5.0ms preprocess, 332.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 378.8ms\n",
      "Speed: 7.0ms preprocess, 378.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 425.7ms\n",
      "Speed: 6.0ms preprocess, 425.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 298.0ms\n",
      "Speed: 3.0ms preprocess, 298.0ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 278.9ms\n",
      "Speed: 5.0ms preprocess, 278.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 284.6ms\n",
      "Speed: 6.0ms preprocess, 284.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 283.8ms\n",
      "Speed: 4.5ms preprocess, 283.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 332.2ms\n",
      "Speed: 19.6ms preprocess, 332.2ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 305.9ms\n",
      "Speed: 5.0ms preprocess, 305.9ms inference, 13.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 359.2ms\n",
      "Speed: 3.2ms preprocess, 359.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 345.3ms\n",
      "Speed: 6.5ms preprocess, 345.3ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 456.2ms\n",
      "Speed: 6.9ms preprocess, 456.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 269.5ms\n",
      "Speed: 10.8ms preprocess, 269.5ms inference, 15.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 391.9ms\n",
      "Speed: 6.9ms preprocess, 391.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 274.2ms\n",
      "Speed: 3.0ms preprocess, 274.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 306.2ms\n",
      "Speed: 6.0ms preprocess, 306.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 339.5ms\n",
      "Speed: 2.8ms preprocess, 339.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 365.1ms\n",
      "Speed: 2.1ms preprocess, 365.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 379.5ms\n",
      "Speed: 69.2ms preprocess, 379.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 328.6ms\n",
      "Speed: 8.0ms preprocess, 328.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 291.9ms\n",
      "Speed: 3.0ms preprocess, 291.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 456.2ms\n",
      "Speed: 5.0ms preprocess, 456.2ms inference, 14.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 238.8ms\n",
      "Speed: 6.0ms preprocess, 238.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 265.4ms\n",
      "Speed: 17.1ms preprocess, 265.4ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 275.7ms\n",
      "Speed: 5.0ms preprocess, 275.7ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 276.5ms\n",
      "Speed: 7.0ms preprocess, 276.5ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 413.6ms\n",
      "Speed: 22.7ms preprocess, 413.6ms inference, 16.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 418.5ms\n",
      "Speed: 6.1ms preprocess, 418.5ms inference, 13.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 344.8ms\n",
      "Speed: 6.0ms preprocess, 344.8ms inference, 12.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 444.9ms\n",
      "Speed: 3.0ms preprocess, 444.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 304.9ms\n",
      "Speed: 7.0ms preprocess, 304.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 389.3ms\n",
      "Speed: 6.0ms preprocess, 389.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 253.1ms\n",
      "Speed: 87.7ms preprocess, 253.1ms inference, 13.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 510.7ms\n",
      "Speed: 2.9ms preprocess, 510.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 350.4ms\n",
      "Speed: 6.1ms preprocess, 350.4ms inference, 12.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 280.6ms\n",
      "Speed: 7.0ms preprocess, 280.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 447.9ms\n",
      "Speed: 6.0ms preprocess, 447.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 356.0ms\n",
      "Speed: 5.9ms preprocess, 356.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 375.3ms\n",
      "Speed: 4.2ms preprocess, 375.3ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 290.6ms\n",
      "Speed: 7.0ms preprocess, 290.6ms inference, 10.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 448.0ms\n",
      "Speed: 2.6ms preprocess, 448.0ms inference, 16.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 342.6ms\n",
      "Speed: 4.7ms preprocess, 342.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 337.0ms\n",
      "Speed: 8.0ms preprocess, 337.0ms inference, 10.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 329.7ms\n",
      "Speed: 6.0ms preprocess, 329.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 371.5ms\n",
      "Speed: 4.9ms preprocess, 371.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 298.3ms\n",
      "Speed: 7.0ms preprocess, 298.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 188.2ms\n",
      "Speed: 4.7ms preprocess, 188.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 423.2ms\n",
      "Speed: 8.0ms preprocess, 423.2ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 543.9ms\n",
      "Speed: 5.0ms preprocess, 543.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 309.0ms\n",
      "Speed: 6.0ms preprocess, 309.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 431.4ms\n",
      "Speed: 5.0ms preprocess, 431.4ms inference, 12.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 209.9ms\n",
      "Speed: 5.0ms preprocess, 209.9ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 211.6ms\n",
      "Speed: 5.0ms preprocess, 211.6ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 200.1ms\n",
      "Speed: 3.2ms preprocess, 200.1ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 333.7ms\n",
      "Speed: 5.0ms preprocess, 333.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 346.5ms\n",
      "Speed: 6.0ms preprocess, 346.5ms inference, 9.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 332.3ms\n",
      "Speed: 5.0ms preprocess, 332.3ms inference, 13.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 341.8ms\n",
      "Speed: 6.0ms preprocess, 341.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 388.7ms\n",
      "Speed: 3.7ms preprocess, 388.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 409.8ms\n",
      "Speed: 3.5ms preprocess, 409.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 296.7ms\n",
      "Speed: 3.0ms preprocess, 296.7ms inference, 13.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 425.4ms\n",
      "Speed: 8.0ms preprocess, 425.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 336.7ms\n",
      "Speed: 4.0ms preprocess, 336.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 360.2ms\n",
      "Speed: 3.1ms preprocess, 360.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 432.9ms\n",
      "Speed: 7.0ms preprocess, 432.9ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 403.3ms\n",
      "Speed: 7.1ms preprocess, 403.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 541.5ms\n",
      "Speed: 7.0ms preprocess, 541.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 430.8ms\n",
      "Speed: 2.6ms preprocess, 430.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 448.3ms\n",
      "Speed: 2.9ms preprocess, 448.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 432.0ms\n",
      "Speed: 5.1ms preprocess, 432.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 352.1ms\n",
      "Speed: 5.9ms preprocess, 352.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 429.8ms\n",
      "Speed: 6.0ms preprocess, 429.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 482.3ms\n",
      "Speed: 4.7ms preprocess, 482.3ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 262.2ms\n",
      "Speed: 10.4ms preprocess, 262.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 446.8ms\n",
      "Speed: 4.0ms preprocess, 446.8ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 359.2ms\n",
      "Speed: 4.3ms preprocess, 359.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 526.4ms\n",
      "Speed: 3.5ms preprocess, 526.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 353.2ms\n",
      "Speed: 60.9ms preprocess, 353.2ms inference, 93.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 420.5ms\n",
      "Speed: 2.3ms preprocess, 420.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 538.9ms\n",
      "Speed: 10.0ms preprocess, 538.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 326.7ms\n",
      "Speed: 101.8ms preprocess, 326.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 389.8ms\n",
      "Speed: 4.2ms preprocess, 389.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 341.2ms\n",
      "Speed: 5.4ms preprocess, 341.2ms inference, 141.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 404.3ms\n",
      "Speed: 3.7ms preprocess, 404.3ms inference, 13.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 376.2ms\n",
      "Speed: 2.8ms preprocess, 376.2ms inference, 13.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 411.3ms\n",
      "Speed: 2.9ms preprocess, 411.3ms inference, 13.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 336.7ms\n",
      "Speed: 4.0ms preprocess, 336.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 365.4ms\n",
      "Speed: 13.4ms preprocess, 365.4ms inference, 13.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 555.5ms\n",
      "Speed: 7.0ms preprocess, 555.5ms inference, 13.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 360.9ms\n",
      "Speed: 7.0ms preprocess, 360.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 359.1ms\n",
      "Speed: 68.7ms preprocess, 359.1ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 312.7ms\n",
      "Speed: 7.0ms preprocess, 312.7ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 419.3ms\n",
      "Speed: 4.0ms preprocess, 419.3ms inference, 12.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 497.1ms\n",
      "Speed: 14.0ms preprocess, 497.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 319.3ms\n",
      "Speed: 7.0ms preprocess, 319.3ms inference, 12.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 1 person, 436.1ms\n",
      "Speed: 3.6ms preprocess, 436.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 366.2ms\n",
      "Speed: 4.7ms preprocess, 366.2ms inference, 52.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 323.4ms\n",
      "Speed: 3.4ms preprocess, 323.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 4 persons, 357.3ms\n",
      "Speed: 4.7ms preprocess, 357.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 401.3ms\n",
      "Speed: 3.0ms preprocess, 401.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 3 persons, 416.5ms\n",
      "Speed: 1.7ms preprocess, 416.5ms inference, 21.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 322.4ms\n",
      "Speed: 2.3ms preprocess, 322.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 371.4ms\n",
      "Speed: 2.5ms preprocess, 371.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 297.1ms\n",
      "Speed: 7.0ms preprocess, 297.1ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 391.6ms\n",
      "Speed: 23.0ms preprocess, 391.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 290.2ms\n",
      "Speed: 3.0ms preprocess, 290.2ms inference, 12.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 380.3ms\n",
      "Speed: 3.0ms preprocess, 380.3ms inference, 13.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 419.1ms\n",
      "Speed: 6.0ms preprocess, 419.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 331.8ms\n",
      "Speed: 3.7ms preprocess, 331.8ms inference, 54.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 415.6ms\n",
      "Speed: 7.0ms preprocess, 415.6ms inference, 14.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 384.4ms\n",
      "Speed: 6.0ms preprocess, 384.4ms inference, 12.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 384x640 2 persons, 424.7ms\n",
      "Speed: 3.3ms preprocess, 424.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Table Tennis: \u001b[32m•\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "classes = [0]\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture('table_2.mp4')  # replace with your video file path\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Get the default resolutions\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "\n",
    "# Define the codec and create a VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # or use 'XVID'\n",
    "out = cv2.VideoWriter('table_tennis_output_2.mp4', fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "\n",
    "table_tennis_time_2=[]\n",
    "counter = 0  # Initialize counter\n",
    "continuous_detection = False\n",
    "\n",
    "while True:\n",
    "    # Read the frame from the video file\n",
    "    _, img = cap.read()\n",
    "    \n",
    "    if not _:\n",
    "        break\n",
    "    \n",
    "    frame_no = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "    timestamp = frame_no / fps\n",
    "    \n",
    "    # Run inference on the frame\n",
    "    results = model.predict(img,classes=classes)\n",
    "    \n",
    "    detected_classes = [box.cls for box in results[0].boxes]\n",
    "    if 0 in detected_classes:\n",
    "        counter += 1  # Increment counter if class 0 is detected\n",
    "        if counter >= 10 * fps:  # Check if class 0 has been detected for at least 10 seconds\n",
    "            continuous_detection = True\n",
    "    else:\n",
    "        counter = 0  # Reset counter if class 0 is not detected\n",
    "        continuous_detection = False\n",
    "\n",
    "    if continuous_detection:\n",
    "        print('Table Tennis: '+'\\033[31m' + '•' + '\\033[0m')\n",
    "        table_tennis_time_2.append(timestamp)\n",
    "    else:\n",
    "        print('Table Tennis: '+'\\033[32m' + '•' + '\\033[0m')\n",
    "    \n",
    "    for r in results:\n",
    "        # Create an annotator for the image\n",
    "        annotator = Annotator(img)\n",
    "\n",
    "        # Get the bounding boxes\n",
    "        boxes = r.boxes\n",
    "\n",
    "        # Draw each bounding box on the image\n",
    "        for box in boxes:\n",
    "            b = box.xyxy[0]  # get box coordinates in (left, top, right, bottom) format\n",
    "            c = box.cls\n",
    "            annotator.box_label(b, model.names[int(c)])  # draw the box and label on the image\n",
    "\n",
    "        \n",
    "        # Get the annotated image\n",
    "        img = annotator.result()\n",
    "        \n",
    "        out.write(img)\n",
    "        \n",
    "    # Display the image with bounding boxes\n",
    "    cv2.imshow('YOLO V8 Detection', img)\n",
    "\n",
    "    # Break the loop if the 'space' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord(' '):\n",
    "        break\n",
    "\n",
    "# Release the video file and close all windows\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79515cf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a5fb07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014eccfe-09e4-4f82-b107-4b8b80f5b73e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b55dcce",
   "metadata": {},
   "source": [
    "# Gym Equipment - Treadmill-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4cee0f6-ad57-4e4d-b4a6-bfc66b16e43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x384 (no detections), 144.1ms\n",
      "Speed: 4.0ms preprocess, 144.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 125.2ms\n",
      "Speed: 2.0ms preprocess, 125.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 112.4ms\n",
      "Speed: 3.5ms preprocess, 112.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 149.5ms\n",
      "Speed: 4.0ms preprocess, 149.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 105.6ms\n",
      "Speed: 3.0ms preprocess, 105.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 267.2ms\n",
      "Speed: 5.0ms preprocess, 267.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 111.0ms\n",
      "Speed: 3.4ms preprocess, 111.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 154.8ms\n",
      "Speed: 4.9ms preprocess, 154.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 136.4ms\n",
      "Speed: 5.0ms preprocess, 136.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 132.9ms\n",
      "Speed: 4.0ms preprocess, 132.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 162.5ms\n",
      "Speed: 3.3ms preprocess, 162.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 144.9ms\n",
      "Speed: 4.2ms preprocess, 144.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 158.1ms\n",
      "Speed: 5.0ms preprocess, 158.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 164.9ms\n",
      "Speed: 3.9ms preprocess, 164.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 171.6ms\n",
      "Speed: 5.6ms preprocess, 171.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 170.3ms\n",
      "Speed: 4.1ms preprocess, 170.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 115.7ms\n",
      "Speed: 5.0ms preprocess, 115.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 84.5ms\n",
      "Speed: 1.0ms preprocess, 84.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 69.4ms\n",
      "Speed: 2.0ms preprocess, 69.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 87.0ms\n",
      "Speed: 2.1ms preprocess, 87.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 70.0ms\n",
      "Speed: 2.0ms preprocess, 70.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 76.9ms\n",
      "Speed: 2.0ms preprocess, 76.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 68.9ms\n",
      "Speed: 2.0ms preprocess, 68.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 87.2ms\n",
      "Speed: 2.1ms preprocess, 87.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 69.5ms\n",
      "Speed: 3.0ms preprocess, 69.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 64.3ms\n",
      "Speed: 3.0ms preprocess, 64.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 69.5ms\n",
      "Speed: 2.0ms preprocess, 69.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 65.5ms\n",
      "Speed: 2.0ms preprocess, 65.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 74.3ms\n",
      "Speed: 2.0ms preprocess, 74.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 70.0ms\n",
      "Speed: 2.0ms preprocess, 70.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 65.0ms\n",
      "Speed: 2.0ms preprocess, 65.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 74.1ms\n",
      "Speed: 1.9ms preprocess, 74.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 70.1ms\n",
      "Speed: 3.1ms preprocess, 70.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 75.1ms\n",
      "Speed: 2.0ms preprocess, 75.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 84.8ms\n",
      "Speed: 2.0ms preprocess, 84.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 79.8ms\n",
      "Speed: 2.1ms preprocess, 79.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 73.4ms\n",
      "Speed: 1.9ms preprocess, 73.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 77.2ms\n",
      "Speed: 3.0ms preprocess, 77.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 67.3ms\n",
      "Speed: 2.0ms preprocess, 67.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 70.0ms\n",
      "Speed: 2.0ms preprocess, 70.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 67.6ms\n",
      "Speed: 3.0ms preprocess, 67.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 68.7ms\n",
      "Speed: 2.0ms preprocess, 68.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 69.2ms\n",
      "Speed: 2.0ms preprocess, 69.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 68.2ms\n",
      "Speed: 2.0ms preprocess, 68.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 70.8ms\n",
      "Speed: 2.0ms preprocess, 70.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 73.8ms\n",
      "Speed: 2.0ms preprocess, 73.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 74.9ms\n",
      "Speed: 2.0ms preprocess, 74.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 68.9ms\n",
      "Speed: 3.0ms preprocess, 68.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 70.6ms\n",
      "Speed: 1.0ms preprocess, 70.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 70.1ms\n",
      "Speed: 3.0ms preprocess, 70.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 75.1ms\n",
      "Speed: 4.0ms preprocess, 75.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 69.7ms\n",
      "Speed: 1.0ms preprocess, 69.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 73.6ms\n",
      "Speed: 3.4ms preprocess, 73.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 134.9ms\n",
      "Speed: 2.0ms preprocess, 134.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 159.0ms\n",
      "Speed: 4.0ms preprocess, 159.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 207.7ms\n",
      "Speed: 6.0ms preprocess, 207.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 135.0ms\n",
      "Speed: 4.5ms preprocess, 135.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 143.4ms\n",
      "Speed: 4.0ms preprocess, 143.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 137.7ms\n",
      "Speed: 4.8ms preprocess, 137.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 195.3ms\n",
      "Speed: 4.3ms preprocess, 195.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 182.4ms\n",
      "Speed: 7.0ms preprocess, 182.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 135.3ms\n",
      "Speed: 4.0ms preprocess, 135.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 122.9ms\n",
      "Speed: 3.0ms preprocess, 122.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 166.4ms\n",
      "Speed: 4.0ms preprocess, 166.4ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 151.2ms\n",
      "Speed: 4.3ms preprocess, 151.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 156.0ms\n",
      "Speed: 4.6ms preprocess, 156.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 109.8ms\n",
      "Speed: 4.4ms preprocess, 109.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 126.9ms\n",
      "Speed: 3.4ms preprocess, 126.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 165.3ms\n",
      "Speed: 5.0ms preprocess, 165.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 134.8ms\n",
      "Speed: 4.0ms preprocess, 134.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 107.6ms\n",
      "Speed: 3.5ms preprocess, 107.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 163.2ms\n",
      "Speed: 5.2ms preprocess, 163.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 154.1ms\n",
      "Speed: 4.0ms preprocess, 154.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 154.4ms\n",
      "Speed: 4.0ms preprocess, 154.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 151.9ms\n",
      "Speed: 4.0ms preprocess, 151.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 108.3ms\n",
      "Speed: 4.0ms preprocess, 108.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 137.8ms\n",
      "Speed: 3.0ms preprocess, 137.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 127.5ms\n",
      "Speed: 3.0ms preprocess, 127.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 166.4ms\n",
      "Speed: 4.9ms preprocess, 166.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 181.2ms\n",
      "Speed: 3.0ms preprocess, 181.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 183.3ms\n",
      "Speed: 6.0ms preprocess, 183.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 188.0ms\n",
      "Speed: 4.9ms preprocess, 188.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 168.7ms\n",
      "Speed: 4.0ms preprocess, 168.7ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 218.9ms\n",
      "Speed: 4.1ms preprocess, 218.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 165.7ms\n",
      "Speed: 6.0ms preprocess, 165.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 195.7ms\n",
      "Speed: 6.0ms preprocess, 195.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 161.1ms\n",
      "Speed: 5.0ms preprocess, 161.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 193.7ms\n",
      "Speed: 6.1ms preprocess, 193.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 173.2ms\n",
      "Speed: 6.0ms preprocess, 173.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 165.9ms\n",
      "Speed: 5.3ms preprocess, 165.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 175.4ms\n",
      "Speed: 3.9ms preprocess, 175.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 142.9ms\n",
      "Speed: 5.0ms preprocess, 142.9ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 172.4ms\n",
      "Speed: 4.0ms preprocess, 172.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 127.0ms\n",
      "Speed: 4.1ms preprocess, 127.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 118.2ms\n",
      "Speed: 3.0ms preprocess, 118.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 168.8ms\n",
      "Speed: 4.0ms preprocess, 168.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 185.6ms\n",
      "Speed: 4.0ms preprocess, 185.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 140.0ms\n",
      "Speed: 3.0ms preprocess, 140.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 125.4ms\n",
      "Speed: 3.9ms preprocess, 125.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 152.4ms\n",
      "Speed: 4.0ms preprocess, 152.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 141.2ms\n",
      "Speed: 5.0ms preprocess, 141.2ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 167.5ms\n",
      "Speed: 5.0ms preprocess, 167.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 197.7ms\n",
      "Speed: 6.9ms preprocess, 197.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 175.5ms\n",
      "Speed: 4.0ms preprocess, 175.5ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 217.5ms\n",
      "Speed: 5.0ms preprocess, 217.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 156.8ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 4.9ms preprocess, 156.8ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 193.1ms\n",
      "Speed: 5.0ms preprocess, 193.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 185.0ms\n",
      "Speed: 4.9ms preprocess, 185.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 162.5ms\n",
      "Speed: 5.0ms preprocess, 162.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 198.7ms\n",
      "Speed: 4.9ms preprocess, 198.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 171.1ms\n",
      "Speed: 3.9ms preprocess, 171.1ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 203.8ms\n",
      "Speed: 3.0ms preprocess, 203.8ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 160.9ms\n",
      "Speed: 3.0ms preprocess, 160.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 183.1ms\n",
      "Speed: 4.9ms preprocess, 183.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 133.9ms\n",
      "Speed: 4.0ms preprocess, 133.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 242.0ms\n",
      "Speed: 5.0ms preprocess, 242.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 156.1ms\n",
      "Speed: 4.8ms preprocess, 156.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 143.0ms\n",
      "Speed: 4.0ms preprocess, 143.0ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 192.6ms\n",
      "Speed: 5.9ms preprocess, 192.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 226.2ms\n",
      "Speed: 9.0ms preprocess, 226.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 169.2ms\n",
      "Speed: 7.0ms preprocess, 169.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 135.3ms\n",
      "Speed: 3.0ms preprocess, 135.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 176.0ms\n",
      "Speed: 2.9ms preprocess, 176.0ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 169.0ms\n",
      "Speed: 5.0ms preprocess, 169.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 144.8ms\n",
      "Speed: 3.0ms preprocess, 144.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 173.2ms\n",
      "Speed: 4.1ms preprocess, 173.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 125.4ms\n",
      "Speed: 3.2ms preprocess, 125.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 165.2ms\n",
      "Speed: 3.9ms preprocess, 165.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 140.8ms\n",
      "Speed: 2.9ms preprocess, 140.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 193.4ms\n",
      "Speed: 4.0ms preprocess, 193.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 142.8ms\n",
      "Speed: 6.0ms preprocess, 142.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 149.8ms\n",
      "Speed: 5.0ms preprocess, 149.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 117.5ms\n",
      "Speed: 3.0ms preprocess, 117.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 126.9ms\n",
      "Speed: 5.0ms preprocess, 126.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 119.2ms\n",
      "Speed: 3.4ms preprocess, 119.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 114.3ms\n",
      "Speed: 4.0ms preprocess, 114.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 103.0ms\n",
      "Speed: 3.5ms preprocess, 103.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 109.9ms\n",
      "Speed: 4.1ms preprocess, 109.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 110.4ms\n",
      "Speed: 3.0ms preprocess, 110.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 101.5ms\n",
      "Speed: 2.0ms preprocess, 101.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 122.3ms\n",
      "Speed: 3.0ms preprocess, 122.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 119.2ms\n",
      "Speed: 2.1ms preprocess, 119.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 152.1ms\n",
      "Speed: 4.0ms preprocess, 152.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 114.2ms\n",
      "Speed: 4.0ms preprocess, 114.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 107.2ms\n",
      "Speed: 3.8ms preprocess, 107.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 103.4ms\n",
      "Speed: 3.0ms preprocess, 103.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 100.6ms\n",
      "Speed: 3.0ms preprocess, 100.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 106.7ms\n",
      "Speed: 3.0ms preprocess, 106.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 118.4ms\n",
      "Speed: 3.1ms preprocess, 118.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 115.6ms\n",
      "Speed: 3.0ms preprocess, 115.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 114.8ms\n",
      "Speed: 4.0ms preprocess, 114.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 118.2ms\n",
      "Speed: 4.0ms preprocess, 118.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 191.8ms\n",
      "Speed: 8.0ms preprocess, 191.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 153.1ms\n",
      "Speed: 4.0ms preprocess, 153.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 120.2ms\n",
      "Speed: 3.0ms preprocess, 120.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 146.0ms\n",
      "Speed: 4.0ms preprocess, 146.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 126.8ms\n",
      "Speed: 5.0ms preprocess, 126.8ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 149.9ms\n",
      "Speed: 4.0ms preprocess, 149.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 112.6ms\n",
      "Speed: 3.2ms preprocess, 112.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 113.5ms\n",
      "Speed: 4.0ms preprocess, 113.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 107.7ms\n",
      "Speed: 3.0ms preprocess, 107.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 187.8ms\n",
      "Speed: 5.0ms preprocess, 187.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 142.6ms\n",
      "Speed: 3.0ms preprocess, 142.6ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 115.4ms\n",
      "Speed: 3.0ms preprocess, 115.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 120.7ms\n",
      "Speed: 3.0ms preprocess, 120.7ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 146.2ms\n",
      "Speed: 4.5ms preprocess, 146.2ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 134.3ms\n",
      "Speed: 3.0ms preprocess, 134.3ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 172.2ms\n",
      "Speed: 5.0ms preprocess, 172.2ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 136.7ms\n",
      "Speed: 4.0ms preprocess, 136.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 128.2ms\n",
      "Speed: 4.0ms preprocess, 128.2ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 116.0ms\n",
      "Speed: 3.3ms preprocess, 116.0ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 108.9ms\n",
      "Speed: 3.8ms preprocess, 108.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 100.7ms\n",
      "Speed: 3.0ms preprocess, 100.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 126.7ms\n",
      "Speed: 4.0ms preprocess, 126.7ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 127.8ms\n",
      "Speed: 3.0ms preprocess, 127.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 130.2ms\n",
      "Speed: 4.3ms preprocess, 130.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 142.2ms\n",
      "Speed: 5.3ms preprocess, 142.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 122.1ms\n",
      "Speed: 2.7ms preprocess, 122.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 118.3ms\n",
      "Speed: 3.0ms preprocess, 118.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 105.9ms\n",
      "Speed: 4.0ms preprocess, 105.9ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 134.3ms\n",
      "Speed: 5.0ms preprocess, 134.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 123.7ms\n",
      "Speed: 3.0ms preprocess, 123.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 142.6ms\n",
      "Speed: 3.0ms preprocess, 142.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 139.8ms\n",
      "Speed: 4.4ms preprocess, 139.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 135.9ms\n",
      "Speed: 4.0ms preprocess, 135.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 179.4ms\n",
      "Speed: 4.8ms preprocess, 179.4ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 128.0ms\n",
      "Speed: 5.0ms preprocess, 128.0ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 149.6ms\n",
      "Speed: 3.5ms preprocess, 149.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 142.1ms\n",
      "Speed: 4.1ms preprocess, 142.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 158.1ms\n",
      "Speed: 3.4ms preprocess, 158.1ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 156.2ms\n",
      "Speed: 3.3ms preprocess, 156.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 177.1ms\n",
      "Speed: 4.0ms preprocess, 177.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 134.8ms\n",
      "Speed: 5.0ms preprocess, 134.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 146.8ms\n",
      "Speed: 4.0ms preprocess, 146.8ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 159.6ms\n",
      "Speed: 3.8ms preprocess, 159.6ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 165.6ms\n",
      "Speed: 4.5ms preprocess, 165.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 133.3ms\n",
      "Speed: 4.3ms preprocess, 133.3ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 138.1ms\n",
      "Speed: 5.0ms preprocess, 138.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 134.3ms\n",
      "Speed: 4.0ms preprocess, 134.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 136.3ms\n",
      "Speed: 4.4ms preprocess, 136.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 142.4ms\n",
      "Speed: 4.0ms preprocess, 142.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 131.7ms\n",
      "Speed: 4.0ms preprocess, 131.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 184.3ms\n",
      "Speed: 4.0ms preprocess, 184.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 109.8ms\n",
      "Speed: 4.0ms preprocess, 109.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 125.0ms\n",
      "Speed: 4.1ms preprocess, 125.0ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 130.1ms\n",
      "Speed: 4.9ms preprocess, 130.1ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 151.0ms\n",
      "Speed: 4.1ms preprocess, 151.0ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 115.6ms\n",
      "Speed: 4.0ms preprocess, 115.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 118.3ms\n",
      "Speed: 4.0ms preprocess, 118.3ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 126.3ms\n",
      "Speed: 5.0ms preprocess, 126.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 135.8ms\n",
      "Speed: 4.0ms preprocess, 135.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 134.0ms\n",
      "Speed: 4.0ms preprocess, 134.0ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 120.0ms\n",
      "Speed: 4.0ms preprocess, 120.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 119.0ms\n",
      "Speed: 5.3ms preprocess, 119.0ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 139.0ms\n",
      "Speed: 3.1ms preprocess, 139.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 150.9ms\n",
      "Speed: 5.9ms preprocess, 150.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 149.1ms\n",
      "Speed: 3.0ms preprocess, 149.1ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 126.2ms\n",
      "Speed: 3.9ms preprocess, 126.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 129.9ms\n",
      "Speed: 4.9ms preprocess, 129.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 132.9ms\n",
      "Speed: 4.0ms preprocess, 132.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 115.9ms\n",
      "Speed: 4.4ms preprocess, 115.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 132.7ms\n",
      "Speed: 4.2ms preprocess, 132.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 132.4ms\n",
      "Speed: 4.5ms preprocess, 132.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 132.1ms\n",
      "Speed: 3.9ms preprocess, 132.1ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 171.3ms\n",
      "Speed: 4.0ms preprocess, 171.3ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 147.4ms\n",
      "Speed: 4.0ms preprocess, 147.4ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 140.8ms\n",
      "Speed: 2.3ms preprocess, 140.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 169.0ms\n",
      "Speed: 5.0ms preprocess, 169.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 144.3ms\n",
      "Speed: 3.0ms preprocess, 144.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 144.7ms\n",
      "Speed: 4.0ms preprocess, 144.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 155.0ms\n",
      "Speed: 4.0ms preprocess, 155.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 162.6ms\n",
      "Speed: 4.1ms preprocess, 162.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 127.4ms\n",
      "Speed: 4.0ms preprocess, 127.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 162.5ms\n",
      "Speed: 4.1ms preprocess, 162.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 172.2ms\n",
      "Speed: 4.0ms preprocess, 172.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 165.7ms\n",
      "Speed: 4.0ms preprocess, 165.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 218.5ms\n",
      "Speed: 7.0ms preprocess, 218.5ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 135.7ms\n",
      "Speed: 4.0ms preprocess, 135.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 159.7ms\n",
      "Speed: 5.1ms preprocess, 159.7ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 147.4ms\n",
      "Speed: 4.9ms preprocess, 147.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 138.9ms\n",
      "Speed: 5.3ms preprocess, 138.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 119.0ms\n",
      "Speed: 3.5ms preprocess, 119.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 127.5ms\n",
      "Speed: 4.0ms preprocess, 127.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 130.5ms\n",
      "Speed: 3.0ms preprocess, 130.5ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 131.6ms\n",
      "Speed: 3.5ms preprocess, 131.6ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 168.3ms\n",
      "Speed: 3.1ms preprocess, 168.3ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 144.2ms\n",
      "Speed: 5.0ms preprocess, 144.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 122.6ms\n",
      "Speed: 5.0ms preprocess, 122.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 151.9ms\n",
      "Speed: 3.0ms preprocess, 151.9ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 133.7ms\n",
      "Speed: 4.0ms preprocess, 133.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 126.1ms\n",
      "Speed: 3.6ms preprocess, 126.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 135.8ms\n",
      "Speed: 4.5ms preprocess, 135.8ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 133.1ms\n",
      "Speed: 4.0ms preprocess, 133.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 159.1ms\n",
      "Speed: 3.2ms preprocess, 159.1ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 123.4ms\n",
      "Speed: 4.5ms preprocess, 123.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 157.1ms\n",
      "Speed: 3.5ms preprocess, 157.1ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 126.5ms\n",
      "Speed: 3.0ms preprocess, 126.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 191.2ms\n",
      "Speed: 5.0ms preprocess, 191.2ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 120.5ms\n",
      "Speed: 3.3ms preprocess, 120.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 176.6ms\n",
      "Speed: 3.6ms preprocess, 176.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 155.4ms\n",
      "Speed: 4.0ms preprocess, 155.4ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 166.1ms\n",
      "Speed: 5.4ms preprocess, 166.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 209.6ms\n",
      "Speed: 8.0ms preprocess, 209.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 156.6ms\n",
      "Speed: 5.0ms preprocess, 156.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 144.6ms\n",
      "Speed: 3.0ms preprocess, 144.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 124.8ms\n",
      "Speed: 3.0ms preprocess, 124.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 135.7ms\n",
      "Speed: 5.0ms preprocess, 135.7ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 115.7ms\n",
      "Speed: 3.0ms preprocess, 115.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 4 persons, 128.6ms\n",
      "Speed: 4.0ms preprocess, 128.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 4 persons, 149.4ms\n",
      "Speed: 4.0ms preprocess, 149.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 121.6ms\n",
      "Speed: 3.9ms preprocess, 121.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 113.2ms\n",
      "Speed: 3.5ms preprocess, 113.2ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 124.2ms\n",
      "Speed: 4.2ms preprocess, 124.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 138.7ms\n",
      "Speed: 4.0ms preprocess, 138.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 160.3ms\n",
      "Speed: 3.0ms preprocess, 160.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 117.1ms\n",
      "Speed: 3.0ms preprocess, 117.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 122.9ms\n",
      "Speed: 4.0ms preprocess, 122.9ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 129.3ms\n",
      "Speed: 5.0ms preprocess, 129.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 131.3ms\n",
      "Speed: 4.0ms preprocess, 131.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 137.3ms\n",
      "Speed: 3.0ms preprocess, 137.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 165.6ms\n",
      "Speed: 4.0ms preprocess, 165.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 133.5ms\n",
      "Speed: 4.0ms preprocess, 133.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 215.6ms\n",
      "Speed: 4.5ms preprocess, 215.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 158.7ms\n",
      "Speed: 5.0ms preprocess, 158.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 117.8ms\n",
      "Speed: 3.0ms preprocess, 117.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 136.9ms\n",
      "Speed: 3.1ms preprocess, 136.9ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 128.3ms\n",
      "Speed: 4.0ms preprocess, 128.3ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 125.0ms\n",
      "Speed: 1.4ms preprocess, 125.0ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 141.8ms\n",
      "Speed: 4.0ms preprocess, 141.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 138.3ms\n",
      "Speed: 5.0ms preprocess, 138.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 147.1ms\n",
      "Speed: 3.0ms preprocess, 147.1ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 148.7ms\n",
      "Speed: 3.4ms preprocess, 148.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 113.2ms\n",
      "Speed: 4.0ms preprocess, 113.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 147.5ms\n",
      "Speed: 5.0ms preprocess, 147.5ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 154.8ms\n",
      "Speed: 4.0ms preprocess, 154.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 140.0ms\n",
      "Speed: 5.0ms preprocess, 140.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 223.5ms\n",
      "Speed: 8.8ms preprocess, 223.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 149.5ms\n",
      "Speed: 4.1ms preprocess, 149.5ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 154.7ms\n",
      "Speed: 4.4ms preprocess, 154.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 149.5ms\n",
      "Speed: 4.5ms preprocess, 149.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 156.3ms\n",
      "Speed: 5.0ms preprocess, 156.3ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 148.8ms\n",
      "Speed: 5.0ms preprocess, 148.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 157.5ms\n",
      "Speed: 5.0ms preprocess, 157.5ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 140.7ms\n",
      "Speed: 5.2ms preprocess, 140.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 139.1ms\n",
      "Speed: 4.0ms preprocess, 139.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 124.6ms\n",
      "Speed: 4.0ms preprocess, 124.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 137.2ms\n",
      "Speed: 5.0ms preprocess, 137.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 116.7ms\n",
      "Speed: 4.0ms preprocess, 116.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 117.6ms\n",
      "Speed: 4.3ms preprocess, 117.6ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 114.9ms\n",
      "Speed: 4.3ms preprocess, 114.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 125.1ms\n",
      "Speed: 3.0ms preprocess, 125.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 128.4ms\n",
      "Speed: 4.3ms preprocess, 128.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 133.3ms\n",
      "Speed: 4.0ms preprocess, 133.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 125.7ms\n",
      "Speed: 4.0ms preprocess, 125.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 111.9ms\n",
      "Speed: 5.0ms preprocess, 111.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 135.1ms\n",
      "Speed: 5.4ms preprocess, 135.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 112.5ms\n",
      "Speed: 3.5ms preprocess, 112.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 128.5ms\n",
      "Speed: 3.0ms preprocess, 128.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 132.4ms\n",
      "Speed: 4.0ms preprocess, 132.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 148.1ms\n",
      "Speed: 4.0ms preprocess, 148.1ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 147.7ms\n",
      "Speed: 5.0ms preprocess, 147.7ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 132.5ms\n",
      "Speed: 3.0ms preprocess, 132.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 154.8ms\n",
      "Speed: 5.0ms preprocess, 154.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 148.4ms\n",
      "Speed: 4.0ms preprocess, 148.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 123.7ms\n",
      "Speed: 4.0ms preprocess, 123.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 127.8ms\n",
      "Speed: 4.2ms preprocess, 127.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 137.3ms\n",
      "Speed: 4.0ms preprocess, 137.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 136.3ms\n",
      "Speed: 4.0ms preprocess, 136.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 130.3ms\n",
      "Speed: 5.1ms preprocess, 130.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 111.8ms\n",
      "Speed: 3.1ms preprocess, 111.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 140.2ms\n",
      "Speed: 3.0ms preprocess, 140.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 159.0ms\n",
      "Speed: 6.0ms preprocess, 159.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 121.6ms\n",
      "Speed: 4.0ms preprocess, 121.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 126.4ms\n",
      "Speed: 3.4ms preprocess, 126.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 170.6ms\n",
      "Speed: 4.0ms preprocess, 170.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 123.1ms\n",
      "Speed: 3.5ms preprocess, 123.1ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 134.0ms\n",
      "Speed: 4.0ms preprocess, 134.0ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 149.5ms\n",
      "Speed: 3.0ms preprocess, 149.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 129.0ms\n",
      "Speed: 5.0ms preprocess, 129.0ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 112.8ms\n",
      "Speed: 4.0ms preprocess, 112.8ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 110.3ms\n",
      "Speed: 3.0ms preprocess, 110.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 168.6ms\n",
      "Speed: 3.1ms preprocess, 168.6ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 136.0ms\n",
      "Speed: 4.0ms preprocess, 136.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 151.3ms\n",
      "Speed: 6.0ms preprocess, 151.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 142.5ms\n",
      "Speed: 3.0ms preprocess, 142.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 140.3ms\n",
      "Speed: 5.0ms preprocess, 140.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 130.9ms\n",
      "Speed: 4.4ms preprocess, 130.9ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 152.8ms\n",
      "Speed: 5.0ms preprocess, 152.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 142.5ms\n",
      "Speed: 3.0ms preprocess, 142.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 156.0ms\n",
      "Speed: 3.0ms preprocess, 156.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 159.8ms\n",
      "Speed: 4.0ms preprocess, 159.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 104.1ms\n",
      "Speed: 3.5ms preprocess, 104.1ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 111.4ms\n",
      "Speed: 4.4ms preprocess, 111.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 110.9ms\n",
      "Speed: 3.8ms preprocess, 110.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 126.9ms\n",
      "Speed: 3.0ms preprocess, 126.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 130.6ms\n",
      "Speed: 4.0ms preprocess, 130.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 146.8ms\n",
      "Speed: 3.9ms preprocess, 146.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 130.1ms\n",
      "Speed: 3.0ms preprocess, 130.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 147.0ms\n",
      "Speed: 3.9ms preprocess, 147.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 149.5ms\n",
      "Speed: 7.0ms preprocess, 149.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 129.8ms\n",
      "Speed: 3.8ms preprocess, 129.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 115.2ms\n",
      "Speed: 4.1ms preprocess, 115.2ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 125.2ms\n",
      "Speed: 4.0ms preprocess, 125.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 151.2ms\n",
      "Speed: 4.1ms preprocess, 151.2ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 121.9ms\n",
      "Speed: 4.1ms preprocess, 121.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 130.2ms\n",
      "Speed: 4.7ms preprocess, 130.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 137.6ms\n",
      "Speed: 4.0ms preprocess, 137.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 154.6ms\n",
      "Speed: 4.0ms preprocess, 154.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 107.2ms\n",
      "Speed: 3.3ms preprocess, 107.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 144.3ms\n",
      "Speed: 3.1ms preprocess, 144.3ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 136.3ms\n",
      "Speed: 3.4ms preprocess, 136.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 123.5ms\n",
      "Speed: 4.0ms preprocess, 123.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 173.1ms\n",
      "Speed: 4.9ms preprocess, 173.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 183.9ms\n",
      "Speed: 6.0ms preprocess, 183.9ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 161.2ms\n",
      "Speed: 5.9ms preprocess, 161.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 172.7ms\n",
      "Speed: 5.0ms preprocess, 172.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 164.2ms\n",
      "Speed: 4.0ms preprocess, 164.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 195.3ms\n",
      "Speed: 3.5ms preprocess, 195.3ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 177.2ms\n",
      "Speed: 4.0ms preprocess, 177.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 151.4ms\n",
      "Speed: 5.0ms preprocess, 151.4ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 154.7ms\n",
      "Speed: 3.9ms preprocess, 154.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 175.7ms\n",
      "Speed: 5.0ms preprocess, 175.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 179.6ms\n",
      "Speed: 4.0ms preprocess, 179.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 166.3ms\n",
      "Speed: 5.0ms preprocess, 166.3ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 160.5ms\n",
      "Speed: 5.0ms preprocess, 160.5ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 160.0ms\n",
      "Speed: 4.0ms preprocess, 160.0ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 160.4ms\n",
      "Speed: 4.0ms preprocess, 160.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 161.4ms\n",
      "Speed: 3.0ms preprocess, 161.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 193.9ms\n",
      "Speed: 4.9ms preprocess, 193.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 160.5ms\n",
      "Speed: 4.0ms preprocess, 160.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 130.6ms\n",
      "Speed: 2.4ms preprocess, 130.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 117.3ms\n",
      "Speed: 3.0ms preprocess, 117.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 108.6ms\n",
      "Speed: 4.0ms preprocess, 108.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 109.8ms\n",
      "Speed: 4.0ms preprocess, 109.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 111.6ms\n",
      "Speed: 3.3ms preprocess, 111.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 182.8ms\n",
      "Speed: 4.0ms preprocess, 182.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 105.8ms\n",
      "Speed: 4.6ms preprocess, 105.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 138.7ms\n",
      "Speed: 3.0ms preprocess, 138.7ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 115.2ms\n",
      "Speed: 4.0ms preprocess, 115.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 123.5ms\n",
      "Speed: 4.0ms preprocess, 123.5ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 123.2ms\n",
      "Speed: 3.2ms preprocess, 123.2ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 102.2ms\n",
      "Speed: 3.0ms preprocess, 102.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 130.7ms\n",
      "Speed: 5.0ms preprocess, 130.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 142.8ms\n",
      "Speed: 3.0ms preprocess, 142.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 139.1ms\n",
      "Speed: 5.0ms preprocess, 139.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 132.0ms\n",
      "Speed: 4.0ms preprocess, 132.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 133.8ms\n",
      "Speed: 4.7ms preprocess, 133.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 127.0ms\n",
      "Speed: 4.0ms preprocess, 127.0ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 125.9ms\n",
      "Speed: 3.5ms preprocess, 125.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 105.6ms\n",
      "Speed: 4.6ms preprocess, 105.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 206.6ms\n",
      "Speed: 4.0ms preprocess, 206.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 100.9ms\n",
      "Speed: 3.0ms preprocess, 100.9ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 110.8ms\n",
      "Speed: 3.0ms preprocess, 110.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 107.9ms\n",
      "Speed: 4.3ms preprocess, 107.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 125.4ms\n",
      "Speed: 5.1ms preprocess, 125.4ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 111.0ms\n",
      "Speed: 3.0ms preprocess, 111.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 111.3ms\n",
      "Speed: 3.3ms preprocess, 111.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 176.8ms\n",
      "Speed: 6.0ms preprocess, 176.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 178.2ms\n",
      "Speed: 4.0ms preprocess, 178.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 124.0ms\n",
      "Speed: 6.0ms preprocess, 124.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 125.3ms\n",
      "Speed: 4.6ms preprocess, 125.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 101.2ms\n",
      "Speed: 3.3ms preprocess, 101.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 115.3ms\n",
      "Speed: 4.0ms preprocess, 115.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 174.6ms\n",
      "Speed: 6.3ms preprocess, 174.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 114.8ms\n",
      "Speed: 2.9ms preprocess, 114.8ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 113.4ms\n",
      "Speed: 3.0ms preprocess, 113.4ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 142.3ms\n",
      "Speed: 5.0ms preprocess, 142.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 142.6ms\n",
      "Speed: 4.0ms preprocess, 142.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 123.4ms\n",
      "Speed: 4.1ms preprocess, 123.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 157.4ms\n",
      "Speed: 4.6ms preprocess, 157.4ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 160.9ms\n",
      "Speed: 4.0ms preprocess, 160.9ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 146.4ms\n",
      "Speed: 5.0ms preprocess, 146.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 115.2ms\n",
      "Speed: 4.0ms preprocess, 115.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 143.9ms\n",
      "Speed: 4.9ms preprocess, 143.9ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 158.3ms\n",
      "Speed: 3.1ms preprocess, 158.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 135.0ms\n",
      "Speed: 5.0ms preprocess, 135.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 160.5ms\n",
      "Speed: 5.0ms preprocess, 160.5ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 167.7ms\n",
      "Speed: 4.8ms preprocess, 167.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 167.1ms\n",
      "Speed: 5.0ms preprocess, 167.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 173.1ms\n",
      "Speed: 3.9ms preprocess, 173.1ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 161.0ms\n",
      "Speed: 5.0ms preprocess, 161.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 181.0ms\n",
      "Speed: 4.0ms preprocess, 181.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 186.6ms\n",
      "Speed: 4.9ms preprocess, 186.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 131.1ms\n",
      "Speed: 5.3ms preprocess, 131.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 107.5ms\n",
      "Speed: 3.0ms preprocess, 107.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 103.3ms\n",
      "Speed: 4.0ms preprocess, 103.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 140.1ms\n",
      "Speed: 3.3ms preprocess, 140.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 118.4ms\n",
      "Speed: 3.3ms preprocess, 118.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 99.6ms\n",
      "Speed: 3.7ms preprocess, 99.6ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 108.5ms\n",
      "Speed: 4.1ms preprocess, 108.5ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 103.6ms\n",
      "Speed: 3.0ms preprocess, 103.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 128.3ms\n",
      "Speed: 3.0ms preprocess, 128.3ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 108.9ms\n",
      "Speed: 3.5ms preprocess, 108.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 119.3ms\n",
      "Speed: 4.0ms preprocess, 119.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 116.5ms\n",
      "Speed: 3.0ms preprocess, 116.5ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 124.6ms\n",
      "Speed: 5.0ms preprocess, 124.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 118.8ms\n",
      "Speed: 5.0ms preprocess, 118.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 130.7ms\n",
      "Speed: 5.0ms preprocess, 130.7ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 141.4ms\n",
      "Speed: 4.0ms preprocess, 141.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 109.0ms\n",
      "Speed: 4.0ms preprocess, 109.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 103.3ms\n",
      "Speed: 3.3ms preprocess, 103.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 128.5ms\n",
      "Speed: 5.1ms preprocess, 128.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 116.3ms\n",
      "Speed: 3.4ms preprocess, 116.3ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 102.1ms\n",
      "Speed: 3.9ms preprocess, 102.1ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 107.7ms\n",
      "Speed: 3.0ms preprocess, 107.7ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 129.9ms\n",
      "Speed: 3.0ms preprocess, 129.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 161.4ms\n",
      "Speed: 4.0ms preprocess, 161.4ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 148.3ms\n",
      "Speed: 3.4ms preprocess, 148.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 161.7ms\n",
      "Speed: 4.9ms preprocess, 161.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 153.6ms\n",
      "Speed: 4.9ms preprocess, 153.6ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 138.0ms\n",
      "Speed: 4.0ms preprocess, 138.0ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 125.0ms\n",
      "Speed: 5.1ms preprocess, 125.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 134.5ms\n",
      "Speed: 5.1ms preprocess, 134.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 139.2ms\n",
      "Speed: 3.3ms preprocess, 139.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 214.9ms\n",
      "Speed: 5.9ms preprocess, 214.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 175.4ms\n",
      "Speed: 3.6ms preprocess, 175.4ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 171.0ms\n",
      "Speed: 4.9ms preprocess, 171.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 162.6ms\n",
      "Speed: 5.0ms preprocess, 162.6ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 166.8ms\n",
      "Speed: 4.3ms preprocess, 166.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 185.6ms\n",
      "Speed: 4.9ms preprocess, 185.6ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 153.9ms\n",
      "Speed: 6.0ms preprocess, 153.9ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 147.0ms\n",
      "Speed: 4.0ms preprocess, 147.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 108.3ms\n",
      "Speed: 4.2ms preprocess, 108.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 114.6ms\n",
      "Speed: 3.0ms preprocess, 114.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 186.1ms\n",
      "Speed: 4.2ms preprocess, 186.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 189.7ms\n",
      "Speed: 3.0ms preprocess, 189.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 170.1ms\n",
      "Speed: 5.0ms preprocess, 170.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 208.7ms\n",
      "Speed: 5.0ms preprocess, 208.7ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 178.6ms\n",
      "Speed: 5.4ms preprocess, 178.6ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 192.4ms\n",
      "Speed: 5.0ms preprocess, 192.4ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 179.2ms\n",
      "Speed: 5.0ms preprocess, 179.2ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 167.9ms\n",
      "Speed: 5.0ms preprocess, 167.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 175.5ms\n",
      "Speed: 4.0ms preprocess, 175.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 151.5ms\n",
      "Speed: 6.0ms preprocess, 151.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 198.8ms\n",
      "Speed: 5.0ms preprocess, 198.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 169.9ms\n",
      "Speed: 3.9ms preprocess, 169.9ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 162.2ms\n",
      "Speed: 5.0ms preprocess, 162.2ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 168.8ms\n",
      "Speed: 5.0ms preprocess, 168.8ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 175.7ms\n",
      "Speed: 4.9ms preprocess, 175.7ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 157.1ms\n",
      "Speed: 5.1ms preprocess, 157.1ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 182.9ms\n",
      "Speed: 4.9ms preprocess, 182.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 198.7ms\n",
      "Speed: 4.9ms preprocess, 198.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 172.2ms\n",
      "Speed: 5.0ms preprocess, 172.2ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 178.5ms\n",
      "Speed: 5.0ms preprocess, 178.5ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 167.0ms\n",
      "Speed: 5.0ms preprocess, 167.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 165.0ms\n",
      "Speed: 5.0ms preprocess, 165.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 172.4ms\n",
      "Speed: 5.0ms preprocess, 172.4ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 208.0ms\n",
      "Speed: 4.0ms preprocess, 208.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 181.0ms\n",
      "Speed: 5.0ms preprocess, 181.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 222.6ms\n",
      "Speed: 7.0ms preprocess, 222.6ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 220.5ms\n",
      "Speed: 5.9ms preprocess, 220.5ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 158.9ms\n",
      "Speed: 4.0ms preprocess, 158.9ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 182.8ms\n",
      "Speed: 4.9ms preprocess, 182.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 154.2ms\n",
      "Speed: 5.5ms preprocess, 154.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 218.3ms\n",
      "Speed: 4.9ms preprocess, 218.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 174.7ms\n",
      "Speed: 6.0ms preprocess, 174.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 158.8ms\n",
      "Speed: 5.0ms preprocess, 158.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 181.0ms\n",
      "Speed: 5.0ms preprocess, 181.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 171.3ms\n",
      "Speed: 4.0ms preprocess, 171.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 215.4ms\n",
      "Speed: 5.0ms preprocess, 215.4ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 191.8ms\n",
      "Speed: 4.9ms preprocess, 191.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 201.5ms\n",
      "Speed: 5.0ms preprocess, 201.5ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 171.5ms\n",
      "Speed: 4.0ms preprocess, 171.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 157.3ms\n",
      "Speed: 5.0ms preprocess, 157.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 169.9ms\n",
      "Speed: 4.9ms preprocess, 169.9ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 175.5ms\n",
      "Speed: 4.9ms preprocess, 175.5ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 175.7ms\n",
      "Speed: 5.0ms preprocess, 175.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 169.9ms\n",
      "Speed: 4.0ms preprocess, 169.9ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 187.2ms\n",
      "Speed: 4.0ms preprocess, 187.2ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 180.0ms\n",
      "Speed: 5.0ms preprocess, 180.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 178.1ms\n",
      "Speed: 5.0ms preprocess, 178.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 169.3ms\n",
      "Speed: 5.4ms preprocess, 169.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 169.6ms\n",
      "Speed: 5.0ms preprocess, 169.6ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 168.0ms\n",
      "Speed: 6.0ms preprocess, 168.0ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 169.4ms\n",
      "Speed: 4.9ms preprocess, 169.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 201.8ms\n",
      "Speed: 4.9ms preprocess, 201.8ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 172.9ms\n",
      "Speed: 4.9ms preprocess, 172.9ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 171.6ms\n",
      "Speed: 4.0ms preprocess, 171.6ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 210.4ms\n",
      "Speed: 6.1ms preprocess, 210.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 189.6ms\n",
      "Speed: 4.0ms preprocess, 189.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 167.1ms\n",
      "Speed: 4.0ms preprocess, 167.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 187.3ms\n",
      "Speed: 4.9ms preprocess, 187.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 188.3ms\n",
      "Speed: 5.0ms preprocess, 188.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 182.9ms\n",
      "Speed: 4.6ms preprocess, 182.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 152.9ms\n",
      "Speed: 4.0ms preprocess, 152.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 165.5ms\n",
      "Speed: 4.7ms preprocess, 165.5ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 168.5ms\n",
      "Speed: 5.0ms preprocess, 168.5ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 173.0ms\n",
      "Speed: 4.0ms preprocess, 173.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 137.4ms\n",
      "Speed: 4.5ms preprocess, 137.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 130.1ms\n",
      "Speed: 4.0ms preprocess, 130.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 122.0ms\n",
      "Speed: 5.0ms preprocess, 122.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 136.2ms\n",
      "Speed: 3.5ms preprocess, 136.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 173.2ms\n",
      "Speed: 6.0ms preprocess, 173.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 219.0ms\n",
      "Speed: 3.0ms preprocess, 219.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 172.2ms\n",
      "Speed: 4.0ms preprocess, 172.2ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 202.0ms\n",
      "Speed: 5.2ms preprocess, 202.0ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 166.3ms\n",
      "Speed: 5.0ms preprocess, 166.3ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 242.9ms\n",
      "Speed: 6.0ms preprocess, 242.9ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 182.5ms\n",
      "Speed: 5.3ms preprocess, 182.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 190.8ms\n",
      "Speed: 5.1ms preprocess, 190.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 178.8ms\n",
      "Speed: 3.9ms preprocess, 178.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 131.6ms\n",
      "Speed: 4.0ms preprocess, 131.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 144.2ms\n",
      "Speed: 3.9ms preprocess, 144.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 228.3ms\n",
      "Speed: 4.9ms preprocess, 228.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 158.9ms\n",
      "Speed: 5.0ms preprocess, 158.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 129.6ms\n",
      "Speed: 4.0ms preprocess, 129.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 112.5ms\n",
      "Speed: 4.0ms preprocess, 112.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 201.3ms\n",
      "Speed: 3.0ms preprocess, 201.3ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 246.9ms\n",
      "Speed: 4.9ms preprocess, 246.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 208.9ms\n",
      "Speed: 6.0ms preprocess, 208.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 186.9ms\n",
      "Speed: 5.1ms preprocess, 186.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 211.0ms\n",
      "Speed: 6.0ms preprocess, 211.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 197.5ms\n",
      "Speed: 4.0ms preprocess, 197.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 211.8ms\n",
      "Speed: 4.9ms preprocess, 211.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 190.0ms\n",
      "Speed: 5.0ms preprocess, 190.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 168.2ms\n",
      "Speed: 5.5ms preprocess, 168.2ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 200.7ms\n",
      "Speed: 5.0ms preprocess, 200.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 176.6ms\n",
      "Speed: 6.0ms preprocess, 176.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 194.2ms\n",
      "Speed: 5.0ms preprocess, 194.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 224.8ms\n",
      "Speed: 4.9ms preprocess, 224.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 228.7ms\n",
      "Speed: 4.0ms preprocess, 228.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 254.3ms\n",
      "Speed: 4.9ms preprocess, 254.3ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 191.0ms\n",
      "Speed: 5.0ms preprocess, 191.0ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 236.9ms\n",
      "Speed: 4.0ms preprocess, 236.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 203.1ms\n",
      "Speed: 5.6ms preprocess, 203.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 180.1ms\n",
      "Speed: 4.9ms preprocess, 180.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 193.7ms\n",
      "Speed: 5.0ms preprocess, 193.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 185.3ms\n",
      "Speed: 5.0ms preprocess, 185.3ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 209.3ms\n",
      "Speed: 5.0ms preprocess, 209.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 197.3ms\n",
      "Speed: 5.9ms preprocess, 197.3ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 186.6ms\n",
      "Speed: 6.1ms preprocess, 186.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 181.9ms\n",
      "Speed: 4.1ms preprocess, 181.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 159.8ms\n",
      "Speed: 4.5ms preprocess, 159.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 185.7ms\n",
      "Speed: 4.0ms preprocess, 185.7ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 231.4ms\n",
      "Speed: 5.0ms preprocess, 231.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 175.3ms\n",
      "Speed: 5.0ms preprocess, 175.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 171.5ms\n",
      "Speed: 4.0ms preprocess, 171.5ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 202.9ms\n",
      "Speed: 4.5ms preprocess, 202.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 171.0ms\n",
      "Speed: 5.0ms preprocess, 171.0ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 178.0ms\n",
      "Speed: 4.0ms preprocess, 178.0ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 169.4ms\n",
      "Speed: 4.0ms preprocess, 169.4ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 191.1ms\n",
      "Speed: 5.0ms preprocess, 191.1ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 185.3ms\n",
      "Speed: 5.0ms preprocess, 185.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 189.0ms\n",
      "Speed: 5.0ms preprocess, 189.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 235.8ms\n",
      "Speed: 6.0ms preprocess, 235.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 175.2ms\n",
      "Speed: 3.9ms preprocess, 175.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 187.8ms\n",
      "Speed: 5.0ms preprocess, 187.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 190.6ms\n",
      "Speed: 4.9ms preprocess, 190.6ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 166.7ms\n",
      "Speed: 4.9ms preprocess, 166.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 176.1ms\n",
      "Speed: 5.0ms preprocess, 176.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 183.1ms\n",
      "Speed: 5.1ms preprocess, 183.1ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 210.2ms\n",
      "Speed: 5.0ms preprocess, 210.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 201.2ms\n",
      "Speed: 4.0ms preprocess, 201.2ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 166.7ms\n",
      "Speed: 4.1ms preprocess, 166.7ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 202.4ms\n",
      "Speed: 4.0ms preprocess, 202.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 170.6ms\n",
      "Speed: 4.0ms preprocess, 170.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 238.7ms\n",
      "Speed: 5.0ms preprocess, 238.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 195.0ms\n",
      "Speed: 5.0ms preprocess, 195.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 203.8ms\n",
      "Speed: 5.1ms preprocess, 203.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 183.6ms\n",
      "Speed: 4.9ms preprocess, 183.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 221.8ms\n",
      "Speed: 6.0ms preprocess, 221.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 200.1ms\n",
      "Speed: 4.0ms preprocess, 200.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 219.4ms\n",
      "Speed: 5.0ms preprocess, 219.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 180.3ms\n",
      "Speed: 5.1ms preprocess, 180.3ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 239.6ms\n",
      "Speed: 5.0ms preprocess, 239.6ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 169.7ms\n",
      "Speed: 5.0ms preprocess, 169.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 162.7ms\n",
      "Speed: 6.0ms preprocess, 162.7ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 179.5ms\n",
      "Speed: 6.0ms preprocess, 179.5ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 182.0ms\n",
      "Speed: 5.8ms preprocess, 182.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 190.6ms\n",
      "Speed: 3.8ms preprocess, 190.6ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 190.0ms\n",
      "Speed: 4.9ms preprocess, 190.0ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 213.7ms\n",
      "Speed: 5.0ms preprocess, 213.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 171.1ms\n",
      "Speed: 5.0ms preprocess, 171.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 208.5ms\n",
      "Speed: 5.0ms preprocess, 208.5ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 187.0ms\n",
      "Speed: 4.0ms preprocess, 187.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 171.7ms\n",
      "Speed: 7.0ms preprocess, 171.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 219.3ms\n",
      "Speed: 8.0ms preprocess, 219.3ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 241.7ms\n",
      "Speed: 5.0ms preprocess, 241.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 185.8ms\n",
      "Speed: 4.3ms preprocess, 185.8ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 169.4ms\n",
      "Speed: 4.0ms preprocess, 169.4ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 223.8ms\n",
      "Speed: 4.9ms preprocess, 223.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[31m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 266.4ms\n",
      "Speed: 5.0ms preprocess, 266.4ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 207.5ms\n",
      "Speed: 6.1ms preprocess, 207.5ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 195.8ms\n",
      "Speed: 5.0ms preprocess, 195.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 216.1ms\n",
      "Speed: 5.0ms preprocess, 216.1ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 135.2ms\n",
      "Speed: 3.9ms preprocess, 135.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 128.3ms\n",
      "Speed: 5.0ms preprocess, 128.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 122.0ms\n",
      "Speed: 4.0ms preprocess, 122.0ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 182.2ms\n",
      "Speed: 4.9ms preprocess, 182.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 189.7ms\n",
      "Speed: 4.0ms preprocess, 189.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 189.6ms\n",
      "Speed: 5.0ms preprocess, 189.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 191.4ms\n",
      "Speed: 4.1ms preprocess, 191.4ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 149.8ms\n",
      "Speed: 5.0ms preprocess, 149.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 166.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 5.0ms preprocess, 166.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 202.2ms\n",
      "Speed: 4.0ms preprocess, 202.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 220.1ms\n",
      "Speed: 5.0ms preprocess, 220.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 202.8ms\n",
      "Speed: 4.9ms preprocess, 202.8ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 201.2ms\n",
      "Speed: 5.0ms preprocess, 201.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 180.2ms\n",
      "Speed: 6.0ms preprocess, 180.2ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 158.7ms\n",
      "Speed: 5.0ms preprocess, 158.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 208.7ms\n",
      "Speed: 5.0ms preprocess, 208.7ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 171.4ms\n",
      "Speed: 5.2ms preprocess, 171.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 201.8ms\n",
      "Speed: 9.0ms preprocess, 201.8ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 197.2ms\n",
      "Speed: 5.0ms preprocess, 197.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 177.6ms\n",
      "Speed: 4.0ms preprocess, 177.6ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 157.2ms\n",
      "Speed: 4.0ms preprocess, 157.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 199.0ms\n",
      "Speed: 7.6ms preprocess, 199.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 217.3ms\n",
      "Speed: 7.2ms preprocess, 217.3ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 189.6ms\n",
      "Speed: 4.0ms preprocess, 189.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 210.1ms\n",
      "Speed: 5.0ms preprocess, 210.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 183.1ms\n",
      "Speed: 4.6ms preprocess, 183.1ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 191.9ms\n",
      "Speed: 6.0ms preprocess, 191.9ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 265.4ms\n",
      "Speed: 5.3ms preprocess, 265.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 162.9ms\n",
      "Speed: 5.0ms preprocess, 162.9ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 195.9ms\n",
      "Speed: 5.1ms preprocess, 195.9ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 197.0ms\n",
      "Speed: 4.0ms preprocess, 197.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 180.7ms\n",
      "Speed: 3.6ms preprocess, 180.7ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 162.6ms\n",
      "Speed: 5.0ms preprocess, 162.6ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 199.8ms\n",
      "Speed: 5.9ms preprocess, 199.8ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 207.8ms\n",
      "Speed: 5.0ms preprocess, 207.8ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 197.8ms\n",
      "Speed: 3.0ms preprocess, 197.8ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 192.4ms\n",
      "Speed: 5.0ms preprocess, 192.4ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 162.1ms\n",
      "Speed: 5.0ms preprocess, 162.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 179.3ms\n",
      "Speed: 5.0ms preprocess, 179.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 179.7ms\n",
      "Speed: 5.0ms preprocess, 179.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 232.7ms\n",
      "Speed: 7.0ms preprocess, 232.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 166.3ms\n",
      "Speed: 5.0ms preprocess, 166.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 157.7ms\n",
      "Speed: 4.0ms preprocess, 157.7ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 201.7ms\n",
      "Speed: 5.0ms preprocess, 201.7ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 189.7ms\n",
      "Speed: 6.9ms preprocess, 189.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 189.7ms\n",
      "Speed: 5.0ms preprocess, 189.7ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 176.7ms\n",
      "Speed: 4.0ms preprocess, 176.7ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 189.6ms\n",
      "Speed: 6.0ms preprocess, 189.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 167.7ms\n",
      "Speed: 4.0ms preprocess, 167.7ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 177.0ms\n",
      "Speed: 5.0ms preprocess, 177.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 205.8ms\n",
      "Speed: 4.4ms preprocess, 205.8ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 233.4ms\n",
      "Speed: 4.9ms preprocess, 233.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 219.8ms\n",
      "Speed: 5.0ms preprocess, 219.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 172.8ms\n",
      "Speed: 5.0ms preprocess, 172.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 184.2ms\n",
      "Speed: 3.0ms preprocess, 184.2ms inference, 5.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 170.8ms\n",
      "Speed: 3.9ms preprocess, 170.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 176.4ms\n",
      "Speed: 5.0ms preprocess, 176.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 203.3ms\n",
      "Speed: 5.9ms preprocess, 203.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 185.3ms\n",
      "Speed: 5.5ms preprocess, 185.3ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 166.5ms\n",
      "Speed: 4.0ms preprocess, 166.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 197.6ms\n",
      "Speed: 5.0ms preprocess, 197.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 189.7ms\n",
      "Speed: 4.9ms preprocess, 189.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 177.9ms\n",
      "Speed: 4.9ms preprocess, 177.9ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 140.0ms\n",
      "Speed: 5.9ms preprocess, 140.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 177.4ms\n",
      "Speed: 4.9ms preprocess, 177.4ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 164.6ms\n",
      "Speed: 4.9ms preprocess, 164.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 174.0ms\n",
      "Speed: 5.0ms preprocess, 174.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 169.5ms\n",
      "Speed: 5.0ms preprocess, 169.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 164.0ms\n",
      "Speed: 5.0ms preprocess, 164.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 178.5ms\n",
      "Speed: 5.0ms preprocess, 178.5ms inference, 6.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 182.0ms\n",
      "Speed: 5.0ms preprocess, 182.0ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 145.3ms\n",
      "Speed: 4.0ms preprocess, 145.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 196.6ms\n",
      "Speed: 4.9ms preprocess, 196.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 174.7ms\n",
      "Speed: 5.5ms preprocess, 174.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 193.8ms\n",
      "Speed: 5.3ms preprocess, 193.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 161.8ms\n",
      "Speed: 5.0ms preprocess, 161.8ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 169.0ms\n",
      "Speed: 3.1ms preprocess, 169.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 167.2ms\n",
      "Speed: 4.1ms preprocess, 167.2ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 174.7ms\n",
      "Speed: 5.1ms preprocess, 174.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 261.6ms\n",
      "Speed: 6.0ms preprocess, 261.6ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 230.6ms\n",
      "Speed: 5.0ms preprocess, 230.6ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 217.9ms\n",
      "Speed: 3.6ms preprocess, 217.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 229.1ms\n",
      "Speed: 4.9ms preprocess, 229.1ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 169.4ms\n",
      "Speed: 5.0ms preprocess, 169.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 190.2ms\n",
      "Speed: 5.9ms preprocess, 190.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 226.4ms\n",
      "Speed: 5.0ms preprocess, 226.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 193.3ms\n",
      "Speed: 5.0ms preprocess, 193.3ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 157.2ms\n",
      "Speed: 4.0ms preprocess, 157.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 204.6ms\n",
      "Speed: 3.9ms preprocess, 204.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 172.5ms\n",
      "Speed: 4.1ms preprocess, 172.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 234.6ms\n",
      "Speed: 6.0ms preprocess, 234.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 143.1ms\n",
      "Speed: 4.1ms preprocess, 143.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 201.7ms\n",
      "Speed: 5.1ms preprocess, 201.7ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 181.3ms\n",
      "Speed: 5.3ms preprocess, 181.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 179.2ms\n",
      "Speed: 5.9ms preprocess, 179.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 226.0ms\n",
      "Speed: 5.4ms preprocess, 226.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 162.2ms\n",
      "Speed: 3.8ms preprocess, 162.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 173.1ms\n",
      "Speed: 5.0ms preprocess, 173.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 192.3ms\n",
      "Speed: 4.0ms preprocess, 192.3ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 203.1ms\n",
      "Speed: 5.9ms preprocess, 203.1ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 167.9ms\n",
      "Speed: 4.0ms preprocess, 167.9ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 169.8ms\n",
      "Speed: 3.6ms preprocess, 169.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 213.1ms\n",
      "Speed: 5.0ms preprocess, 213.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 198.0ms\n",
      "Speed: 7.0ms preprocess, 198.0ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 184.8ms\n",
      "Speed: 5.3ms preprocess, 184.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 253.8ms\n",
      "Speed: 4.1ms preprocess, 253.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 158.0ms\n",
      "Speed: 4.0ms preprocess, 158.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 176.0ms\n",
      "Speed: 5.8ms preprocess, 176.0ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 168.0ms\n",
      "Speed: 4.0ms preprocess, 168.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 177.8ms\n",
      "Speed: 5.0ms preprocess, 177.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 183.9ms\n",
      "Speed: 4.9ms preprocess, 183.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 165.3ms\n",
      "Speed: 3.9ms preprocess, 165.3ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 201.2ms\n",
      "Speed: 3.9ms preprocess, 201.2ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 166.2ms\n",
      "Speed: 4.0ms preprocess, 166.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 158.1ms\n",
      "Speed: 4.9ms preprocess, 158.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 136.1ms\n",
      "Speed: 2.0ms preprocess, 136.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 158.7ms\n",
      "Speed: 4.0ms preprocess, 158.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 168.3ms\n",
      "Speed: 5.9ms preprocess, 168.3ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 169.3ms\n",
      "Speed: 5.0ms preprocess, 169.3ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 175.5ms\n",
      "Speed: 4.0ms preprocess, 175.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 297.8ms\n",
      "Speed: 5.0ms preprocess, 297.8ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 212.0ms\n",
      "Speed: 5.0ms preprocess, 212.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 188.0ms\n",
      "Speed: 6.0ms preprocess, 188.0ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 206.1ms\n",
      "Speed: 6.0ms preprocess, 206.1ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 177.4ms\n",
      "Speed: 5.0ms preprocess, 177.4ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 175.4ms\n",
      "Speed: 4.9ms preprocess, 175.4ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 188.1ms\n",
      "Speed: 3.9ms preprocess, 188.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 221.0ms\n",
      "Speed: 8.2ms preprocess, 221.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 161.5ms\n",
      "Speed: 5.0ms preprocess, 161.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 180.7ms\n",
      "Speed: 4.0ms preprocess, 180.7ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 207.1ms\n",
      "Speed: 3.0ms preprocess, 207.1ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 182.0ms\n",
      "Speed: 4.5ms preprocess, 182.0ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 176.6ms\n",
      "Speed: 4.3ms preprocess, 176.6ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 172.1ms\n",
      "Speed: 4.0ms preprocess, 172.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 188.4ms\n",
      "Speed: 6.0ms preprocess, 188.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 167.3ms\n",
      "Speed: 5.1ms preprocess, 167.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 168.5ms\n",
      "Speed: 4.9ms preprocess, 168.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 194.9ms\n",
      "Speed: 6.0ms preprocess, 194.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 164.3ms\n",
      "Speed: 4.9ms preprocess, 164.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 159.0ms\n",
      "Speed: 5.0ms preprocess, 159.0ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 206.1ms\n",
      "Speed: 6.2ms preprocess, 206.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 143.5ms\n",
      "Speed: 4.0ms preprocess, 143.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 240.8ms\n",
      "Speed: 6.0ms preprocess, 240.8ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 215.4ms\n",
      "Speed: 5.3ms preprocess, 215.4ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 181.3ms\n",
      "Speed: 3.9ms preprocess, 181.3ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 197.0ms\n",
      "Speed: 5.0ms preprocess, 197.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 177.4ms\n",
      "Speed: 4.0ms preprocess, 177.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 173.2ms\n",
      "Speed: 4.0ms preprocess, 173.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 168.9ms\n",
      "Speed: 3.0ms preprocess, 168.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 167.4ms\n",
      "Speed: 4.0ms preprocess, 167.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 213.9ms\n",
      "Speed: 5.0ms preprocess, 213.9ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 181.1ms\n",
      "Speed: 4.9ms preprocess, 181.1ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 231.9ms\n",
      "Speed: 7.0ms preprocess, 231.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 170.9ms\n",
      "Speed: 4.9ms preprocess, 170.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 192.5ms\n",
      "Speed: 4.0ms preprocess, 192.5ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 176.2ms\n",
      "Speed: 4.0ms preprocess, 176.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 150.8ms\n",
      "Speed: 3.5ms preprocess, 150.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 174.3ms\n",
      "Speed: 6.0ms preprocess, 174.3ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 161.3ms\n",
      "Speed: 5.0ms preprocess, 161.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 118.8ms\n",
      "Speed: 5.0ms preprocess, 118.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 109.9ms\n",
      "Speed: 3.0ms preprocess, 109.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 108.9ms\n",
      "Speed: 3.0ms preprocess, 108.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 109.6ms\n",
      "Speed: 3.0ms preprocess, 109.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 113.8ms\n",
      "Speed: 4.0ms preprocess, 113.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 167.2ms\n",
      "Speed: 5.0ms preprocess, 167.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 238.7ms\n",
      "Speed: 4.9ms preprocess, 238.7ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 170.8ms\n",
      "Speed: 5.1ms preprocess, 170.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 175.4ms\n",
      "Speed: 5.0ms preprocess, 175.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 170.4ms\n",
      "Speed: 3.9ms preprocess, 170.4ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 182.0ms\n",
      "Speed: 5.5ms preprocess, 182.0ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 153.0ms\n",
      "Speed: 4.0ms preprocess, 153.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 125.5ms\n",
      "Speed: 3.2ms preprocess, 125.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 127.0ms\n",
      "Speed: 4.0ms preprocess, 127.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 137.4ms\n",
      "Speed: 5.0ms preprocess, 137.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 141.6ms\n",
      "Speed: 4.0ms preprocess, 141.6ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 150.4ms\n",
      "Speed: 4.5ms preprocess, 150.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 139.8ms\n",
      "Speed: 4.0ms preprocess, 139.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 160.1ms\n",
      "Speed: 4.0ms preprocess, 160.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 116.7ms\n",
      "Speed: 3.0ms preprocess, 116.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 130.4ms\n",
      "Speed: 3.0ms preprocess, 130.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 168.0ms\n",
      "Speed: 7.0ms preprocess, 168.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 151.7ms\n",
      "Speed: 3.4ms preprocess, 151.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 4 persons, 175.8ms\n",
      "Speed: 6.0ms preprocess, 175.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 128.5ms\n",
      "Speed: 5.5ms preprocess, 128.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 107.4ms\n",
      "Speed: 3.0ms preprocess, 107.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 143.8ms\n",
      "Speed: 3.0ms preprocess, 143.8ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 126.6ms\n",
      "Speed: 4.0ms preprocess, 126.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 130.6ms\n",
      "Speed: 3.5ms preprocess, 130.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 136.3ms\n",
      "Speed: 3.9ms preprocess, 136.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 135.4ms\n",
      "Speed: 3.0ms preprocess, 135.4ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 139.0ms\n",
      "Speed: 3.0ms preprocess, 139.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 153.2ms\n",
      "Speed: 4.0ms preprocess, 153.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 154.1ms\n",
      "Speed: 4.0ms preprocess, 154.1ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 148.0ms\n",
      "Speed: 3.6ms preprocess, 148.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 161.2ms\n",
      "Speed: 5.0ms preprocess, 161.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 182.0ms\n",
      "Speed: 4.9ms preprocess, 182.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 199.4ms\n",
      "Speed: 7.0ms preprocess, 199.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 148.5ms\n",
      "Speed: 4.0ms preprocess, 148.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 142.4ms\n",
      "Speed: 3.4ms preprocess, 142.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 148.9ms\n",
      "Speed: 4.9ms preprocess, 148.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 152.7ms\n",
      "Speed: 5.0ms preprocess, 152.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 143.7ms\n",
      "Speed: 4.9ms preprocess, 143.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 168.3ms\n",
      "Speed: 4.9ms preprocess, 168.3ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 195.2ms\n",
      "Speed: 6.9ms preprocess, 195.2ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 152.5ms\n",
      "Speed: 3.5ms preprocess, 152.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 149.3ms\n",
      "Speed: 4.0ms preprocess, 149.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 166.3ms\n",
      "Speed: 4.0ms preprocess, 166.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 157.7ms\n",
      "Speed: 4.0ms preprocess, 157.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 153.3ms\n",
      "Speed: 5.1ms preprocess, 153.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 151.4ms\n",
      "Speed: 3.9ms preprocess, 151.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 131.0ms\n",
      "Speed: 3.1ms preprocess, 131.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 152.6ms\n",
      "Speed: 9.0ms preprocess, 152.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 167.1ms\n",
      "Speed: 4.5ms preprocess, 167.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 151.7ms\n",
      "Speed: 3.9ms preprocess, 151.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 179.0ms\n",
      "Speed: 4.9ms preprocess, 179.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 175.6ms\n",
      "Speed: 9.0ms preprocess, 175.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 157.2ms\n",
      "Speed: 4.0ms preprocess, 157.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 175.8ms\n",
      "Speed: 5.0ms preprocess, 175.8ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 183.3ms\n",
      "Speed: 6.0ms preprocess, 183.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 222.1ms\n",
      "Speed: 4.8ms preprocess, 222.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 166.5ms\n",
      "Speed: 5.0ms preprocess, 166.5ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 238.2ms\n",
      "Speed: 6.6ms preprocess, 238.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 167.6ms\n",
      "Speed: 4.1ms preprocess, 167.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 248.2ms\n",
      "Speed: 4.9ms preprocess, 248.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 261.7ms\n",
      "Speed: 6.0ms preprocess, 261.7ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 170.7ms\n",
      "Speed: 5.0ms preprocess, 170.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 171.9ms\n",
      "Speed: 4.0ms preprocess, 171.9ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 169.9ms\n",
      "Speed: 4.9ms preprocess, 169.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 167.3ms\n",
      "Speed: 5.0ms preprocess, 167.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 163.6ms\n",
      "Speed: 4.0ms preprocess, 163.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 156.5ms\n",
      "Speed: 4.0ms preprocess, 156.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 182.1ms\n",
      "Speed: 5.0ms preprocess, 182.1ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 200.7ms\n",
      "Speed: 3.9ms preprocess, 200.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 218.3ms\n",
      "Speed: 5.9ms preprocess, 218.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 188.9ms\n",
      "Speed: 5.3ms preprocess, 188.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 162.6ms\n",
      "Speed: 5.6ms preprocess, 162.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 170.8ms\n",
      "Speed: 5.0ms preprocess, 170.8ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 167.1ms\n",
      "Speed: 4.5ms preprocess, 167.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 188.6ms\n",
      "Speed: 9.9ms preprocess, 188.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 242.6ms\n",
      "Speed: 4.9ms preprocess, 242.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 167.4ms\n",
      "Speed: 4.0ms preprocess, 167.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 161.3ms\n",
      "Speed: 3.0ms preprocess, 161.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 156.8ms\n",
      "Speed: 3.5ms preprocess, 156.8ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 212.7ms\n",
      "Speed: 8.6ms preprocess, 212.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 164.3ms\n",
      "Speed: 4.4ms preprocess, 164.3ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 107.5ms\n",
      "Speed: 4.0ms preprocess, 107.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 124.8ms\n",
      "Speed: 3.0ms preprocess, 124.8ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 134.2ms\n",
      "Speed: 4.1ms preprocess, 134.2ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 135.8ms\n",
      "Speed: 4.0ms preprocess, 135.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 144.8ms\n",
      "Speed: 5.2ms preprocess, 144.8ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 196.3ms\n",
      "Speed: 3.9ms preprocess, 196.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 168.0ms\n",
      "Speed: 5.0ms preprocess, 168.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 158.7ms\n",
      "Speed: 4.9ms preprocess, 158.7ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 140.0ms\n",
      "Speed: 3.0ms preprocess, 140.0ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 263.0ms\n",
      "Speed: 9.0ms preprocess, 263.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 156.5ms\n",
      "Speed: 5.0ms preprocess, 156.5ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 202.4ms\n",
      "Speed: 6.0ms preprocess, 202.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 166.0ms\n",
      "Speed: 4.9ms preprocess, 166.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 164.0ms\n",
      "Speed: 4.9ms preprocess, 164.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 230.5ms\n",
      "Speed: 5.9ms preprocess, 230.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 121.8ms\n",
      "Speed: 3.7ms preprocess, 121.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 169.4ms\n",
      "Speed: 7.9ms preprocess, 169.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 121.8ms\n",
      "Speed: 4.3ms preprocess, 121.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 115.4ms\n",
      "Speed: 2.4ms preprocess, 115.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 138.6ms\n",
      "Speed: 4.0ms preprocess, 138.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 146.1ms\n",
      "Speed: 4.9ms preprocess, 146.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 159.6ms\n",
      "Speed: 5.9ms preprocess, 159.6ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 200.3ms\n",
      "Speed: 5.1ms preprocess, 200.3ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 129.1ms\n",
      "Speed: 4.3ms preprocess, 129.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 172.8ms\n",
      "Speed: 2.9ms preprocess, 172.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 220.4ms\n",
      "Speed: 5.0ms preprocess, 220.4ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 155.3ms\n",
      "Speed: 5.0ms preprocess, 155.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 173.1ms\n",
      "Speed: 5.0ms preprocess, 173.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 162.8ms\n",
      "Speed: 3.9ms preprocess, 162.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 194.7ms\n",
      "Speed: 5.1ms preprocess, 194.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 175.2ms\n",
      "Speed: 4.9ms preprocess, 175.2ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 168.0ms\n",
      "Speed: 3.9ms preprocess, 168.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 166.7ms\n",
      "Speed: 4.0ms preprocess, 166.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 142.3ms\n",
      "Speed: 5.1ms preprocess, 142.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 165.9ms\n",
      "Speed: 6.0ms preprocess, 165.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 158.8ms\n",
      "Speed: 4.0ms preprocess, 158.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 176.4ms\n",
      "Speed: 3.9ms preprocess, 176.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 640x384 1 person, 146.7ms\n",
      "Speed: 5.0ms preprocess, 146.7ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 164.5ms\n",
      "Speed: 4.9ms preprocess, 164.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 160.3ms\n",
      "Speed: 4.6ms preprocess, 160.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 166.2ms\n",
      "Speed: 3.9ms preprocess, 166.2ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 158.2ms\n",
      "Speed: 5.0ms preprocess, 158.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 166.7ms\n",
      "Speed: 6.1ms preprocess, 166.7ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 206.3ms\n",
      "Speed: 5.9ms preprocess, 206.3ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 164.4ms\n",
      "Speed: 5.1ms preprocess, 164.4ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 162.2ms\n",
      "Speed: 4.0ms preprocess, 162.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 196.2ms\n",
      "Speed: 5.1ms preprocess, 196.2ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 154.4ms\n",
      "Speed: 5.9ms preprocess, 154.4ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 219.7ms\n",
      "Speed: 4.0ms preprocess, 219.7ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 169.9ms\n",
      "Speed: 4.3ms preprocess, 169.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 219.3ms\n",
      "Speed: 5.0ms preprocess, 219.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 182.1ms\n",
      "Speed: 5.1ms preprocess, 182.1ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 152.2ms\n",
      "Speed: 4.0ms preprocess, 152.2ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 175.3ms\n",
      "Speed: 4.6ms preprocess, 175.3ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 160.4ms\n",
      "Speed: 4.1ms preprocess, 160.4ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 177.8ms\n",
      "Speed: 5.0ms preprocess, 177.8ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 193.2ms\n",
      "Speed: 4.0ms preprocess, 193.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 173.8ms\n",
      "Speed: 5.0ms preprocess, 173.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 166.4ms\n",
      "Speed: 5.1ms preprocess, 166.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 170.9ms\n",
      "Speed: 5.0ms preprocess, 170.9ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 160.3ms\n",
      "Speed: 5.0ms preprocess, 160.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 155.8ms\n",
      "Speed: 5.0ms preprocess, 155.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 154.8ms\n",
      "Speed: 4.4ms preprocess, 154.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 177.0ms\n",
      "Speed: 5.3ms preprocess, 177.0ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 216.4ms\n",
      "Speed: 3.0ms preprocess, 216.4ms inference, 12.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 184.5ms\n",
      "Speed: 5.4ms preprocess, 184.5ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 210.0ms\n",
      "Speed: 9.3ms preprocess, 210.0ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 170.3ms\n",
      "Speed: 5.0ms preprocess, 170.3ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 151.5ms\n",
      "Speed: 3.0ms preprocess, 151.5ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 173.0ms\n",
      "Speed: 4.0ms preprocess, 173.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 160.2ms\n",
      "Speed: 4.0ms preprocess, 160.2ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 186.5ms\n",
      "Speed: 5.0ms preprocess, 186.5ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 147.2ms\n",
      "Speed: 4.0ms preprocess, 147.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 242.3ms\n",
      "Speed: 6.0ms preprocess, 242.3ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 4 persons, 169.8ms\n",
      "Speed: 4.0ms preprocess, 169.8ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 141.7ms\n",
      "Speed: 3.9ms preprocess, 141.7ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 193.1ms\n",
      "Speed: 5.0ms preprocess, 193.1ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 169.5ms\n",
      "Speed: 4.0ms preprocess, 169.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 138.6ms\n",
      "Speed: 4.0ms preprocess, 138.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 152.0ms\n",
      "Speed: 4.0ms preprocess, 152.0ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 163.5ms\n",
      "Speed: 5.0ms preprocess, 163.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 157.3ms\n",
      "Speed: 4.2ms preprocess, 157.3ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 146.5ms\n",
      "Speed: 5.0ms preprocess, 146.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 177.7ms\n",
      "Speed: 5.0ms preprocess, 177.7ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 167.3ms\n",
      "Speed: 4.1ms preprocess, 167.3ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 223.3ms\n",
      "Speed: 8.1ms preprocess, 223.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 175.7ms\n",
      "Speed: 6.1ms preprocess, 175.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 158.8ms\n",
      "Speed: 5.0ms preprocess, 158.8ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 216.6ms\n",
      "Speed: 6.0ms preprocess, 216.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 150.6ms\n",
      "Speed: 3.5ms preprocess, 150.6ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 204.1ms\n",
      "Speed: 5.9ms preprocess, 204.1ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 160.0ms\n",
      "Speed: 3.9ms preprocess, 160.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 152.4ms\n",
      "Speed: 3.0ms preprocess, 152.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 140.6ms\n",
      "Speed: 5.0ms preprocess, 140.6ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 157.1ms\n",
      "Speed: 4.3ms preprocess, 157.1ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 150.1ms\n",
      "Speed: 4.5ms preprocess, 150.1ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 160.2ms\n",
      "Speed: 6.3ms preprocess, 160.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 232.2ms\n",
      "Speed: 4.0ms preprocess, 232.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 160.2ms\n",
      "Speed: 4.0ms preprocess, 160.2ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 165.7ms\n",
      "Speed: 4.2ms preprocess, 165.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 166.7ms\n",
      "Speed: 4.4ms preprocess, 166.7ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 159.1ms\n",
      "Speed: 5.0ms preprocess, 159.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 233.4ms\n",
      "Speed: 4.9ms preprocess, 233.4ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 156.2ms\n",
      "Speed: 4.9ms preprocess, 156.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 157.3ms\n",
      "Speed: 5.6ms preprocess, 157.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 160.9ms\n",
      "Speed: 5.0ms preprocess, 160.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 222.6ms\n",
      "Speed: 6.9ms preprocess, 222.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 157.4ms\n",
      "Speed: 4.9ms preprocess, 157.4ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 168.8ms\n",
      "Speed: 6.0ms preprocess, 168.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 169.4ms\n",
      "Speed: 5.0ms preprocess, 169.4ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 140.0ms\n",
      "Speed: 3.5ms preprocess, 140.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 214.8ms\n",
      "Speed: 5.7ms preprocess, 214.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 177.5ms\n",
      "Speed: 5.7ms preprocess, 177.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 171.5ms\n",
      "Speed: 4.9ms preprocess, 171.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 226.1ms\n",
      "Speed: 6.0ms preprocess, 226.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 162.5ms\n",
      "Speed: 3.9ms preprocess, 162.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 171.3ms\n",
      "Speed: 4.9ms preprocess, 171.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 174.4ms\n",
      "Speed: 4.6ms preprocess, 174.4ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 169.6ms\n",
      "Speed: 4.0ms preprocess, 169.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 154.2ms\n",
      "Speed: 5.0ms preprocess, 154.2ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 162.5ms\n",
      "Speed: 4.1ms preprocess, 162.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 165.9ms\n",
      "Speed: 2.9ms preprocess, 165.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 150.1ms\n",
      "Speed: 4.9ms preprocess, 150.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 153.9ms\n",
      "Speed: 4.0ms preprocess, 153.9ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 158.3ms\n",
      "Speed: 5.0ms preprocess, 158.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 171.0ms\n",
      "Speed: 5.0ms preprocess, 171.0ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 170.6ms\n",
      "Speed: 5.0ms preprocess, 170.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 159.8ms\n",
      "Speed: 6.0ms preprocess, 159.8ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 160.3ms\n",
      "Speed: 5.1ms preprocess, 160.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 168.3ms\n",
      "Speed: 5.0ms preprocess, 168.3ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 163.6ms\n",
      "Speed: 4.0ms preprocess, 163.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 131.5ms\n",
      "Speed: 3.0ms preprocess, 131.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 136.3ms\n",
      "Speed: 5.2ms preprocess, 136.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 158.7ms\n",
      "Speed: 5.0ms preprocess, 158.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 169.8ms\n",
      "Speed: 4.0ms preprocess, 169.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 166.4ms\n",
      "Speed: 6.0ms preprocess, 166.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 174.1ms\n",
      "Speed: 4.0ms preprocess, 174.1ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 187.0ms\n",
      "Speed: 5.0ms preprocess, 187.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 163.3ms\n",
      "Speed: 3.0ms preprocess, 163.3ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 158.3ms\n",
      "Speed: 4.0ms preprocess, 158.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 156.9ms\n",
      "Speed: 4.5ms preprocess, 156.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 214.1ms\n",
      "Speed: 8.0ms preprocess, 214.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 161.8ms\n",
      "Speed: 4.0ms preprocess, 161.8ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 150.1ms\n",
      "Speed: 5.1ms preprocess, 150.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 178.0ms\n",
      "Speed: 5.8ms preprocess, 178.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 156.9ms\n",
      "Speed: 5.0ms preprocess, 156.9ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 168.6ms\n",
      "Speed: 5.0ms preprocess, 168.6ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 169.5ms\n",
      "Speed: 4.0ms preprocess, 169.5ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 155.8ms\n",
      "Speed: 3.5ms preprocess, 155.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 232.4ms\n",
      "Speed: 6.1ms preprocess, 232.4ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 197.6ms\n",
      "Speed: 8.1ms preprocess, 197.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 171.6ms\n",
      "Speed: 7.0ms preprocess, 171.6ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 172.6ms\n",
      "Speed: 4.0ms preprocess, 172.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 192.7ms\n",
      "Speed: 5.0ms preprocess, 192.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 150.6ms\n",
      "Speed: 3.0ms preprocess, 150.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 160.0ms\n",
      "Speed: 5.0ms preprocess, 160.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 160.0ms\n",
      "Speed: 5.0ms preprocess, 160.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 167.0ms\n",
      "Speed: 5.0ms preprocess, 167.0ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 163.0ms\n",
      "Speed: 5.0ms preprocess, 163.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 167.1ms\n",
      "Speed: 5.0ms preprocess, 167.1ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 168.7ms\n",
      "Speed: 5.0ms preprocess, 168.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 163.4ms\n",
      "Speed: 5.1ms preprocess, 163.4ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 140.7ms\n",
      "Speed: 5.6ms preprocess, 140.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 160.7ms\n",
      "Speed: 4.9ms preprocess, 160.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 149.8ms\n",
      "Speed: 4.0ms preprocess, 149.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 167.0ms\n",
      "Speed: 4.9ms preprocess, 167.0ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 164.7ms\n",
      "Speed: 4.9ms preprocess, 164.7ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 174.4ms\n",
      "Speed: 4.9ms preprocess, 174.4ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 149.8ms\n",
      "Speed: 5.0ms preprocess, 149.8ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 208.6ms\n",
      "Speed: 7.0ms preprocess, 208.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 159.5ms\n",
      "Speed: 4.0ms preprocess, 159.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 197.9ms\n",
      "Speed: 7.0ms preprocess, 197.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 157.1ms\n",
      "Speed: 5.4ms preprocess, 157.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 154.6ms\n",
      "Speed: 5.0ms preprocess, 154.6ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 171.7ms\n",
      "Speed: 5.0ms preprocess, 171.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 210.0ms\n",
      "Speed: 5.0ms preprocess, 210.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 166.3ms\n",
      "Speed: 4.0ms preprocess, 166.3ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 156.0ms\n",
      "Speed: 4.0ms preprocess, 156.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 227.5ms\n",
      "Speed: 6.2ms preprocess, 227.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 159.1ms\n",
      "Speed: 5.0ms preprocess, 159.1ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 174.2ms\n",
      "Speed: 6.0ms preprocess, 174.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 164.1ms\n",
      "Speed: 5.0ms preprocess, 164.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 165.4ms\n",
      "Speed: 4.0ms preprocess, 165.4ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 173.4ms\n",
      "Speed: 5.0ms preprocess, 173.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 159.5ms\n",
      "Speed: 4.0ms preprocess, 159.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 162.6ms\n",
      "Speed: 5.1ms preprocess, 162.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 152.0ms\n",
      "Speed: 4.9ms preprocess, 152.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 177.3ms\n",
      "Speed: 4.0ms preprocess, 177.3ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 172.8ms\n",
      "Speed: 5.0ms preprocess, 172.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 217.7ms\n",
      "Speed: 6.4ms preprocess, 217.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 157.1ms\n",
      "Speed: 6.1ms preprocess, 157.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 152.3ms\n",
      "Speed: 4.0ms preprocess, 152.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 166.7ms\n",
      "Speed: 4.2ms preprocess, 166.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 148.7ms\n",
      "Speed: 4.4ms preprocess, 148.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 191.6ms\n",
      "Speed: 6.0ms preprocess, 191.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 210.8ms\n",
      "Speed: 4.5ms preprocess, 210.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 134.9ms\n",
      "Speed: 5.0ms preprocess, 134.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 158.0ms\n",
      "Speed: 4.0ms preprocess, 158.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 138.8ms\n",
      "Speed: 5.0ms preprocess, 138.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 212.7ms\n",
      "Speed: 5.9ms preprocess, 212.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 152.3ms\n",
      "Speed: 3.1ms preprocess, 152.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 162.2ms\n",
      "Speed: 5.0ms preprocess, 162.2ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 144.3ms\n",
      "Speed: 4.9ms preprocess, 144.3ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 167.5ms\n",
      "Speed: 4.5ms preprocess, 167.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 159.2ms\n",
      "Speed: 5.0ms preprocess, 159.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 158.4ms\n",
      "Speed: 5.0ms preprocess, 158.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 166.3ms\n",
      "Speed: 4.0ms preprocess, 166.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 150.3ms\n",
      "Speed: 6.0ms preprocess, 150.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 146.2ms\n",
      "Speed: 3.1ms preprocess, 146.2ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 147.0ms\n",
      "Speed: 4.1ms preprocess, 147.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 142.9ms\n",
      "Speed: 4.0ms preprocess, 142.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 157.0ms\n",
      "Speed: 5.0ms preprocess, 157.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 172.6ms\n",
      "Speed: 4.1ms preprocess, 172.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 166.7ms\n",
      "Speed: 6.0ms preprocess, 166.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 154.2ms\n",
      "Speed: 4.5ms preprocess, 154.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 168.3ms\n",
      "Speed: 5.0ms preprocess, 168.3ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 163.2ms\n",
      "Speed: 4.0ms preprocess, 163.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 153.8ms\n",
      "Speed: 5.0ms preprocess, 153.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 172.3ms\n",
      "Speed: 4.0ms preprocess, 172.3ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 153.2ms\n",
      "Speed: 5.0ms preprocess, 153.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 149.9ms\n",
      "Speed: 5.0ms preprocess, 149.9ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 261.8ms\n",
      "Speed: 9.1ms preprocess, 261.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 155.7ms\n",
      "Speed: 5.1ms preprocess, 155.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 161.5ms\n",
      "Speed: 5.0ms preprocess, 161.5ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 176.3ms\n",
      "Speed: 4.1ms preprocess, 176.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 141.3ms\n",
      "Speed: 6.0ms preprocess, 141.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 151.2ms\n",
      "Speed: 5.0ms preprocess, 151.2ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 161.1ms\n",
      "Speed: 5.0ms preprocess, 161.1ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 164.7ms\n",
      "Speed: 5.0ms preprocess, 164.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 168.2ms\n",
      "Speed: 5.1ms preprocess, 168.2ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 205.3ms\n",
      "Speed: 7.1ms preprocess, 205.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 169.0ms\n",
      "Speed: 6.0ms preprocess, 169.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 164.4ms\n",
      "Speed: 5.0ms preprocess, 164.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 174.1ms\n",
      "Speed: 5.9ms preprocess, 174.1ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 151.8ms\n",
      "Speed: 3.9ms preprocess, 151.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 159.4ms\n",
      "Speed: 5.0ms preprocess, 159.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 158.4ms\n",
      "Speed: 4.1ms preprocess, 158.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 170.9ms\n",
      "Speed: 5.9ms preprocess, 170.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 159.7ms\n",
      "Speed: 5.0ms preprocess, 159.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 160.8ms\n",
      "Speed: 5.1ms preprocess, 160.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 151.1ms\n",
      "Speed: 4.0ms preprocess, 151.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 171.7ms\n",
      "Speed: 3.0ms preprocess, 171.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 154.7ms\n",
      "Speed: 4.0ms preprocess, 154.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 179.6ms\n",
      "Speed: 5.0ms preprocess, 179.6ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 173.9ms\n",
      "Speed: 3.1ms preprocess, 173.9ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 203.5ms\n",
      "Speed: 4.0ms preprocess, 203.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 145.6ms\n",
      "Speed: 5.0ms preprocess, 145.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 161.4ms\n",
      "Speed: 4.9ms preprocess, 161.4ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 196.2ms\n",
      "Speed: 5.0ms preprocess, 196.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 141.4ms\n",
      "Speed: 5.9ms preprocess, 141.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 194.3ms\n",
      "Speed: 5.4ms preprocess, 194.3ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 150.3ms\n",
      "Speed: 6.0ms preprocess, 150.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 239.6ms\n",
      "Speed: 4.1ms preprocess, 239.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 170.2ms\n",
      "Speed: 5.0ms preprocess, 170.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 170.1ms\n",
      "Speed: 6.0ms preprocess, 170.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 167.7ms\n",
      "Speed: 6.0ms preprocess, 167.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 166.8ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 5.0ms preprocess, 166.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 170.4ms\n",
      "Speed: 4.5ms preprocess, 170.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 182.1ms\n",
      "Speed: 5.5ms preprocess, 182.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 157.9ms\n",
      "Speed: 4.0ms preprocess, 157.9ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 207.4ms\n",
      "Speed: 5.0ms preprocess, 207.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 140.4ms\n",
      "Speed: 4.0ms preprocess, 140.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 132.0ms\n",
      "Speed: 3.7ms preprocess, 132.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 136.4ms\n",
      "Speed: 4.0ms preprocess, 136.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 140.3ms\n",
      "Speed: 5.0ms preprocess, 140.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 163.7ms\n",
      "Speed: 5.0ms preprocess, 163.7ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 149.4ms\n",
      "Speed: 5.0ms preprocess, 149.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 138.5ms\n",
      "Speed: 3.0ms preprocess, 138.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 133.4ms\n",
      "Speed: 5.0ms preprocess, 133.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 144.4ms\n",
      "Speed: 4.2ms preprocess, 144.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 143.3ms\n",
      "Speed: 4.0ms preprocess, 143.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 158.5ms\n",
      "Speed: 4.0ms preprocess, 158.5ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 170.9ms\n",
      "Speed: 5.0ms preprocess, 170.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 175.7ms\n",
      "Speed: 5.0ms preprocess, 175.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 167.3ms\n",
      "Speed: 5.0ms preprocess, 167.3ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 161.9ms\n",
      "Speed: 5.0ms preprocess, 161.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 153.2ms\n",
      "Speed: 4.2ms preprocess, 153.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 172.1ms\n",
      "Speed: 3.0ms preprocess, 172.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 157.2ms\n",
      "Speed: 5.0ms preprocess, 157.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 148.2ms\n",
      "Speed: 5.0ms preprocess, 148.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 169.0ms\n",
      "Speed: 4.5ms preprocess, 169.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 162.0ms\n",
      "Speed: 5.0ms preprocess, 162.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 182.1ms\n",
      "Speed: 4.5ms preprocess, 182.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 167.0ms\n",
      "Speed: 4.0ms preprocess, 167.0ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 139.5ms\n",
      "Speed: 4.6ms preprocess, 139.5ms inference, 5.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 152.0ms\n",
      "Speed: 4.4ms preprocess, 152.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 149.3ms\n",
      "Speed: 5.0ms preprocess, 149.3ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 158.4ms\n",
      "Speed: 4.9ms preprocess, 158.4ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 167.1ms\n",
      "Speed: 6.0ms preprocess, 167.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 133.9ms\n",
      "Speed: 4.0ms preprocess, 133.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 158.7ms\n",
      "Speed: 3.9ms preprocess, 158.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 149.2ms\n",
      "Speed: 4.0ms preprocess, 149.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 163.1ms\n",
      "Speed: 4.9ms preprocess, 163.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 144.0ms\n",
      "Speed: 5.9ms preprocess, 144.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 137.4ms\n",
      "Speed: 4.0ms preprocess, 137.4ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 163.3ms\n",
      "Speed: 4.7ms preprocess, 163.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 166.1ms\n",
      "Speed: 3.0ms preprocess, 166.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 162.8ms\n",
      "Speed: 5.9ms preprocess, 162.8ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 141.1ms\n",
      "Speed: 3.9ms preprocess, 141.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 201.7ms\n",
      "Speed: 8.6ms preprocess, 201.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 167.8ms\n",
      "Speed: 3.9ms preprocess, 167.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 140.4ms\n",
      "Speed: 4.9ms preprocess, 140.4ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 136.3ms\n",
      "Speed: 4.0ms preprocess, 136.3ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 150.4ms\n",
      "Speed: 4.0ms preprocess, 150.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 142.6ms\n",
      "Speed: 5.1ms preprocess, 142.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 135.2ms\n",
      "Speed: 6.0ms preprocess, 135.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 141.3ms\n",
      "Speed: 3.9ms preprocess, 141.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 151.2ms\n",
      "Speed: 3.1ms preprocess, 151.2ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 140.7ms\n",
      "Speed: 5.0ms preprocess, 140.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 149.5ms\n",
      "Speed: 4.0ms preprocess, 149.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 640x384 3 persons, 142.7ms\n",
      "Speed: 2.5ms preprocess, 142.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 152.5ms\n",
      "Speed: 4.0ms preprocess, 152.5ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 157.8ms\n",
      "Speed: 4.9ms preprocess, 157.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 162.9ms\n",
      "Speed: 4.5ms preprocess, 162.9ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 209.3ms\n",
      "Speed: 8.8ms preprocess, 209.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 160.4ms\n",
      "Speed: 3.9ms preprocess, 160.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 159.8ms\n",
      "Speed: 3.0ms preprocess, 159.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 213.5ms\n",
      "Speed: 6.1ms preprocess, 213.5ms inference, 6.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 165.1ms\n",
      "Speed: 5.0ms preprocess, 165.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 159.5ms\n",
      "Speed: 5.1ms preprocess, 159.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 163.0ms\n",
      "Speed: 5.0ms preprocess, 163.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 144.8ms\n",
      "Speed: 4.0ms preprocess, 144.8ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 163.5ms\n",
      "Speed: 5.0ms preprocess, 163.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 164.9ms\n",
      "Speed: 4.0ms preprocess, 164.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 171.6ms\n",
      "Speed: 5.1ms preprocess, 171.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 154.5ms\n",
      "Speed: 5.0ms preprocess, 154.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 170.3ms\n",
      "Speed: 4.0ms preprocess, 170.3ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 180.9ms\n",
      "Speed: 7.0ms preprocess, 180.9ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 152.0ms\n",
      "Speed: 4.0ms preprocess, 152.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 155.4ms\n",
      "Speed: 3.0ms preprocess, 155.4ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 159.9ms\n",
      "Speed: 3.9ms preprocess, 159.9ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 226.2ms\n",
      "Speed: 4.7ms preprocess, 226.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 158.5ms\n",
      "Speed: 4.0ms preprocess, 158.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 224.4ms\n",
      "Speed: 5.0ms preprocess, 224.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 188.1ms\n",
      "Speed: 5.0ms preprocess, 188.1ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 165.3ms\n",
      "Speed: 3.8ms preprocess, 165.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 158.3ms\n",
      "Speed: 5.0ms preprocess, 158.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 269.9ms\n",
      "Speed: 5.0ms preprocess, 269.9ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 151.6ms\n",
      "Speed: 4.0ms preprocess, 151.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 166.8ms\n",
      "Speed: 5.0ms preprocess, 166.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 187.9ms\n",
      "Speed: 5.0ms preprocess, 187.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 222.6ms\n",
      "Speed: 8.8ms preprocess, 222.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 189.8ms\n",
      "Speed: 8.6ms preprocess, 189.8ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 147.8ms\n",
      "Speed: 5.0ms preprocess, 147.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 130.1ms\n",
      "Speed: 4.0ms preprocess, 130.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 138.3ms\n",
      "Speed: 4.0ms preprocess, 138.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 129.5ms\n",
      "Speed: 3.0ms preprocess, 129.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 124.5ms\n",
      "Speed: 3.0ms preprocess, 124.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 119.5ms\n",
      "Speed: 4.0ms preprocess, 119.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 112.4ms\n",
      "Speed: 5.0ms preprocess, 112.4ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 115.5ms\n",
      "Speed: 3.0ms preprocess, 115.5ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 115.6ms\n",
      "Speed: 3.0ms preprocess, 115.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 133.1ms\n",
      "Speed: 5.9ms preprocess, 133.1ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 143.4ms\n",
      "Speed: 5.0ms preprocess, 143.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 111.1ms\n",
      "Speed: 4.0ms preprocess, 111.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 115.5ms\n",
      "Speed: 3.3ms preprocess, 115.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 114.9ms\n",
      "Speed: 4.0ms preprocess, 114.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 146.0ms\n",
      "Speed: 4.0ms preprocess, 146.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 169.6ms\n",
      "Speed: 3.0ms preprocess, 169.6ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 139.4ms\n",
      "Speed: 4.0ms preprocess, 139.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 112.0ms\n",
      "Speed: 4.0ms preprocess, 112.0ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 170.0ms\n",
      "Speed: 4.0ms preprocess, 170.0ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 139.8ms\n",
      "Speed: 3.9ms preprocess, 139.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 152.2ms\n",
      "Speed: 3.9ms preprocess, 152.2ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 122.7ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 4.4ms preprocess, 122.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 123.3ms\n",
      "Speed: 4.0ms preprocess, 123.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 121.6ms\n",
      "Speed: 4.0ms preprocess, 121.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 136.0ms\n",
      "Speed: 5.0ms preprocess, 136.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 121.6ms\n",
      "Speed: 3.0ms preprocess, 121.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 154.9ms\n",
      "Speed: 5.0ms preprocess, 154.9ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 115.1ms\n",
      "Speed: 2.1ms preprocess, 115.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 145.1ms\n",
      "Speed: 2.9ms preprocess, 145.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 162.0ms\n",
      "Speed: 4.0ms preprocess, 162.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 169.4ms\n",
      "Speed: 4.0ms preprocess, 169.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 157.1ms\n",
      "Speed: 3.0ms preprocess, 157.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 147.6ms\n",
      "Speed: 3.0ms preprocess, 147.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 140.4ms\n",
      "Speed: 3.9ms preprocess, 140.4ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 164.3ms\n",
      "Speed: 4.0ms preprocess, 164.3ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 144.3ms\n",
      "Speed: 3.0ms preprocess, 144.3ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 193.6ms\n",
      "Speed: 4.6ms preprocess, 193.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 197.2ms\n",
      "Speed: 5.9ms preprocess, 197.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 63.1ms\n",
      "Speed: 3.0ms preprocess, 63.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 70.3ms\n",
      "Speed: 2.0ms preprocess, 70.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 68.3ms\n",
      "Speed: 1.0ms preprocess, 68.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 76.3ms\n",
      "Speed: 3.0ms preprocess, 76.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 68.6ms\n",
      "Speed: 1.6ms preprocess, 68.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 70.5ms\n",
      "Speed: 2.0ms preprocess, 70.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 75.7ms\n",
      "Speed: 2.0ms preprocess, 75.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 68.5ms\n",
      "Speed: 2.0ms preprocess, 68.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 73.4ms\n",
      "Speed: 1.0ms preprocess, 73.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 67.5ms\n",
      "Speed: 1.9ms preprocess, 67.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 65.0ms\n",
      "Speed: 2.0ms preprocess, 65.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 66.4ms\n",
      "Speed: 2.0ms preprocess, 66.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 64.6ms\n",
      "Speed: 2.0ms preprocess, 64.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 149.3ms\n",
      "Speed: 4.0ms preprocess, 149.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 119.6ms\n",
      "Speed: 4.0ms preprocess, 119.6ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 118.4ms\n",
      "Speed: 4.0ms preprocess, 118.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 122.4ms\n",
      "Speed: 3.4ms preprocess, 122.4ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 127.1ms\n",
      "Speed: 4.6ms preprocess, 127.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 127.0ms\n",
      "Speed: 3.0ms preprocess, 127.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 152.1ms\n",
      "Speed: 3.6ms preprocess, 152.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 125.1ms\n",
      "Speed: 3.0ms preprocess, 125.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 138.3ms\n",
      "Speed: 4.3ms preprocess, 138.3ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 126.7ms\n",
      "Speed: 5.0ms preprocess, 126.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 124.1ms\n",
      "Speed: 3.6ms preprocess, 124.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 128.5ms\n",
      "Speed: 4.1ms preprocess, 128.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 229.1ms\n",
      "Speed: 8.4ms preprocess, 229.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 129.3ms\n",
      "Speed: 3.0ms preprocess, 129.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 142.2ms\n",
      "Speed: 3.9ms preprocess, 142.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 126.7ms\n",
      "Speed: 3.0ms preprocess, 126.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 131.7ms\n",
      "Speed: 5.0ms preprocess, 131.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 153.6ms\n",
      "Speed: 5.1ms preprocess, 153.6ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 180.7ms\n",
      "Speed: 4.0ms preprocess, 180.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 213.6ms\n",
      "Speed: 4.6ms preprocess, 213.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 140.4ms\n",
      "Speed: 4.0ms preprocess, 140.4ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 138.2ms\n",
      "Speed: 4.0ms preprocess, 138.2ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 143.3ms\n",
      "Speed: 3.0ms preprocess, 143.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 128.3ms\n",
      "Speed: 4.0ms preprocess, 128.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 133.4ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 2.1ms preprocess, 133.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 146.9ms\n",
      "Speed: 3.5ms preprocess, 146.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 136.7ms\n",
      "Speed: 4.0ms preprocess, 136.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 214.8ms\n",
      "Speed: 3.5ms preprocess, 214.8ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 157.3ms\n",
      "Speed: 3.9ms preprocess, 157.3ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 130.3ms\n",
      "Speed: 4.6ms preprocess, 130.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 144.8ms\n",
      "Speed: 3.6ms preprocess, 144.8ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 148.9ms\n",
      "Speed: 4.0ms preprocess, 148.9ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 134.1ms\n",
      "Speed: 3.0ms preprocess, 134.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 137.0ms\n",
      "Speed: 3.0ms preprocess, 137.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 145.8ms\n",
      "Speed: 5.4ms preprocess, 145.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 142.7ms\n",
      "Speed: 5.0ms preprocess, 142.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 135.6ms\n",
      "Speed: 4.0ms preprocess, 135.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 156.7ms\n",
      "Speed: 6.0ms preprocess, 156.7ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 206.1ms\n",
      "Speed: 8.0ms preprocess, 206.1ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 124.7ms\n",
      "Speed: 4.0ms preprocess, 124.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 138.4ms\n",
      "Speed: 3.9ms preprocess, 138.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 207.6ms\n",
      "Speed: 6.0ms preprocess, 207.6ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 144.8ms\n",
      "Speed: 5.1ms preprocess, 144.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 171.4ms\n",
      "Speed: 4.7ms preprocess, 171.4ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 152.6ms\n",
      "Speed: 3.0ms preprocess, 152.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 174.5ms\n",
      "Speed: 5.0ms preprocess, 174.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 141.5ms\n",
      "Speed: 4.0ms preprocess, 141.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 196.9ms\n",
      "Speed: 3.5ms preprocess, 196.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 153.2ms\n",
      "Speed: 5.0ms preprocess, 153.2ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 136.9ms\n",
      "Speed: 3.9ms preprocess, 136.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 131.6ms\n",
      "Speed: 3.1ms preprocess, 131.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 152.3ms\n",
      "Speed: 5.0ms preprocess, 152.3ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 145.3ms\n",
      "Speed: 3.6ms preprocess, 145.3ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 131.9ms\n",
      "Speed: 3.0ms preprocess, 131.9ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 155.5ms\n",
      "Speed: 4.5ms preprocess, 155.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 167.3ms\n",
      "Speed: 9.1ms preprocess, 167.3ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 117.0ms\n",
      "Speed: 4.0ms preprocess, 117.0ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 131.2ms\n",
      "Speed: 3.5ms preprocess, 131.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 133.4ms\n",
      "Speed: 3.5ms preprocess, 133.4ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 140.3ms\n",
      "Speed: 3.9ms preprocess, 140.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 135.5ms\n",
      "Speed: 4.6ms preprocess, 135.5ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 154.8ms\n",
      "Speed: 4.4ms preprocess, 154.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 161.1ms\n",
      "Speed: 5.0ms preprocess, 161.1ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 162.3ms\n",
      "Speed: 4.5ms preprocess, 162.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 174.3ms\n",
      "Speed: 5.5ms preprocess, 174.3ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 160.8ms\n",
      "Speed: 3.5ms preprocess, 160.8ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 146.4ms\n",
      "Speed: 4.0ms preprocess, 146.4ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 154.1ms\n",
      "Speed: 3.0ms preprocess, 154.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 129.6ms\n",
      "Speed: 3.0ms preprocess, 129.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 152.5ms\n",
      "Speed: 4.0ms preprocess, 152.5ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 132.7ms\n",
      "Speed: 4.0ms preprocess, 132.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 219.2ms\n",
      "Speed: 5.0ms preprocess, 219.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 157.1ms\n",
      "Speed: 5.0ms preprocess, 157.1ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 152.4ms\n",
      "Speed: 4.0ms preprocess, 152.4ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 178.7ms\n",
      "Speed: 5.9ms preprocess, 178.7ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 150.8ms\n",
      "Speed: 5.0ms preprocess, 150.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 175.9ms\n",
      "Speed: 5.0ms preprocess, 175.9ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 157.7ms\n",
      "Speed: 5.0ms preprocess, 157.7ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 190.8ms\n",
      "Speed: 4.0ms preprocess, 190.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 182.6ms\n",
      "Speed: 5.0ms preprocess, 182.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 172.7ms\n",
      "Speed: 4.0ms preprocess, 172.7ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 166.2ms\n",
      "Speed: 4.0ms preprocess, 166.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 146.9ms\n",
      "Speed: 3.0ms preprocess, 146.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 142.6ms\n",
      "Speed: 5.1ms preprocess, 142.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 146.4ms\n",
      "Speed: 4.0ms preprocess, 146.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 175.2ms\n",
      "Speed: 5.0ms preprocess, 175.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 124.7ms\n",
      "Speed: 3.5ms preprocess, 124.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 155.1ms\n",
      "Speed: 4.7ms preprocess, 155.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 187.2ms\n",
      "Speed: 5.2ms preprocess, 187.2ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 160.1ms\n",
      "Speed: 6.0ms preprocess, 160.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 225.4ms\n",
      "Speed: 6.0ms preprocess, 225.4ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 171.3ms\n",
      "Speed: 5.0ms preprocess, 171.3ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 173.6ms\n",
      "Speed: 3.3ms preprocess, 173.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 130.7ms\n",
      "Speed: 3.9ms preprocess, 130.7ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 153.8ms\n",
      "Speed: 4.4ms preprocess, 153.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 149.0ms\n",
      "Speed: 5.0ms preprocess, 149.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 200.3ms\n",
      "Speed: 10.0ms preprocess, 200.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 130.0ms\n",
      "Speed: 4.0ms preprocess, 130.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 141.1ms\n",
      "Speed: 3.0ms preprocess, 141.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 157.6ms\n",
      "Speed: 4.0ms preprocess, 157.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 221.3ms\n",
      "Speed: 5.5ms preprocess, 221.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 192.8ms\n",
      "Speed: 6.1ms preprocess, 192.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 157.0ms\n",
      "Speed: 5.0ms preprocess, 157.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 166.7ms\n",
      "Speed: 4.0ms preprocess, 166.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 129.6ms\n",
      "Speed: 3.2ms preprocess, 129.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 140.1ms\n",
      "Speed: 4.1ms preprocess, 140.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 146.1ms\n",
      "Speed: 5.0ms preprocess, 146.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 188.7ms\n",
      "Speed: 6.0ms preprocess, 188.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 163.2ms\n",
      "Speed: 4.0ms preprocess, 163.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 160.3ms\n",
      "Speed: 3.6ms preprocess, 160.3ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 138.6ms\n",
      "Speed: 4.6ms preprocess, 138.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 151.2ms\n",
      "Speed: 4.0ms preprocess, 151.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 148.3ms\n",
      "Speed: 4.0ms preprocess, 148.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 4 persons, 121.6ms\n",
      "Speed: 4.0ms preprocess, 121.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 143.4ms\n",
      "Speed: 6.0ms preprocess, 143.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 138.6ms\n",
      "Speed: 5.0ms preprocess, 138.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 139.2ms\n",
      "Speed: 5.0ms preprocess, 139.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 128.1ms\n",
      "Speed: 3.0ms preprocess, 128.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 222.0ms\n",
      "Speed: 9.0ms preprocess, 222.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 134.1ms\n",
      "Speed: 5.0ms preprocess, 134.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 129.3ms\n",
      "Speed: 3.0ms preprocess, 129.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 150.7ms\n",
      "Speed: 4.0ms preprocess, 150.7ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 186.6ms\n",
      "Speed: 4.0ms preprocess, 186.6ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 188.6ms\n",
      "Speed: 3.0ms preprocess, 188.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 142.1ms\n",
      "Speed: 3.0ms preprocess, 142.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 222.3ms\n",
      "Speed: 7.0ms preprocess, 222.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 193.0ms\n",
      "Speed: 4.0ms preprocess, 193.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 179.8ms\n",
      "Speed: 5.0ms preprocess, 179.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 172.5ms\n",
      "Speed: 5.3ms preprocess, 172.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 150.4ms\n",
      "Speed: 5.0ms preprocess, 150.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 170.7ms\n",
      "Speed: 4.0ms preprocess, 170.7ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 164.2ms\n",
      "Speed: 5.0ms preprocess, 164.2ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 239.6ms\n",
      "Speed: 9.0ms preprocess, 239.6ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 640x384 2 persons, 182.7ms\n",
      "Speed: 5.0ms preprocess, 182.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 223.5ms\n",
      "Speed: 9.2ms preprocess, 223.5ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 192.7ms\n",
      "Speed: 5.0ms preprocess, 192.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 4 persons, 226.4ms\n",
      "Speed: 9.0ms preprocess, 226.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 176.8ms\n",
      "Speed: 5.0ms preprocess, 176.8ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 184.7ms\n",
      "Speed: 5.0ms preprocess, 184.7ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 178.0ms\n",
      "Speed: 5.0ms preprocess, 178.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 175.2ms\n",
      "Speed: 5.0ms preprocess, 175.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 181.6ms\n",
      "Speed: 3.9ms preprocess, 181.6ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 170.7ms\n",
      "Speed: 3.3ms preprocess, 170.7ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 244.7ms\n",
      "Speed: 5.6ms preprocess, 244.7ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 269.3ms\n",
      "Speed: 7.0ms preprocess, 269.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 184.8ms\n",
      "Speed: 3.1ms preprocess, 184.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 174.3ms\n",
      "Speed: 4.2ms preprocess, 174.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 5 persons, 247.1ms\n",
      "Speed: 9.0ms preprocess, 247.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 5 persons, 170.7ms\n",
      "Speed: 3.0ms preprocess, 170.7ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 5 persons, 156.5ms\n",
      "Speed: 5.0ms preprocess, 156.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 5 persons, 179.5ms\n",
      "Speed: 5.0ms preprocess, 179.5ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 4 persons, 181.5ms\n",
      "Speed: 4.0ms preprocess, 181.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 4 persons, 167.3ms\n",
      "Speed: 5.1ms preprocess, 167.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 4 persons, 228.4ms\n",
      "Speed: 5.0ms preprocess, 228.4ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 180.7ms\n",
      "Speed: 4.9ms preprocess, 180.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 5 persons, 167.3ms\n",
      "Speed: 4.0ms preprocess, 167.3ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 4 persons, 181.6ms\n",
      "Speed: 5.1ms preprocess, 181.6ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 187.8ms\n",
      "Speed: 5.0ms preprocess, 187.8ms inference, 6.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 165.9ms\n",
      "Speed: 4.0ms preprocess, 165.9ms inference, 5.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 165.1ms\n",
      "Speed: 3.9ms preprocess, 165.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 249.6ms\n",
      "Speed: 6.9ms preprocess, 249.6ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 182.6ms\n",
      "Speed: 5.0ms preprocess, 182.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 175.4ms\n",
      "Speed: 4.0ms preprocess, 175.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 222.1ms\n",
      "Speed: 5.0ms preprocess, 222.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 272.3ms\n",
      "Speed: 6.5ms preprocess, 272.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 178.3ms\n",
      "Speed: 4.9ms preprocess, 178.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 146.9ms\n",
      "Speed: 3.3ms preprocess, 146.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 257.2ms\n",
      "Speed: 5.4ms preprocess, 257.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 170.1ms\n",
      "Speed: 5.1ms preprocess, 170.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 176.7ms\n",
      "Speed: 5.0ms preprocess, 176.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 172.9ms\n",
      "Speed: 4.0ms preprocess, 172.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 182.5ms\n",
      "Speed: 8.0ms preprocess, 182.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 161.4ms\n",
      "Speed: 5.0ms preprocess, 161.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 177.3ms\n",
      "Speed: 5.9ms preprocess, 177.3ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 310.3ms\n",
      "Speed: 5.1ms preprocess, 310.3ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 163.1ms\n",
      "Speed: 4.0ms preprocess, 163.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 189.5ms\n",
      "Speed: 5.0ms preprocess, 189.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 168.2ms\n",
      "Speed: 5.1ms preprocess, 168.2ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 165.3ms\n",
      "Speed: 4.0ms preprocess, 165.3ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 275.6ms\n",
      "Speed: 4.0ms preprocess, 275.6ms inference, 7.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 156.6ms\n",
      "Speed: 4.3ms preprocess, 156.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 175.1ms\n",
      "Speed: 9.0ms preprocess, 175.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 140.6ms\n",
      "Speed: 4.0ms preprocess, 140.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 194.4ms\n",
      "Speed: 7.0ms preprocess, 194.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 178.7ms\n",
      "Speed: 4.0ms preprocess, 178.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 128.1ms\n",
      "Speed: 4.0ms preprocess, 128.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 171.5ms\n",
      "Speed: 4.0ms preprocess, 171.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 232.1ms\n",
      "Speed: 9.0ms preprocess, 232.1ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 196.1ms\n",
      "Speed: 4.0ms preprocess, 196.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 172.1ms\n",
      "Speed: 7.0ms preprocess, 172.1ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 157.7ms\n",
      "Speed: 3.0ms preprocess, 157.7ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 156.7ms\n",
      "Speed: 4.1ms preprocess, 156.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 174.1ms\n",
      "Speed: 4.3ms preprocess, 174.1ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 186.4ms\n",
      "Speed: 5.0ms preprocess, 186.4ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 275.9ms\n",
      "Speed: 7.6ms preprocess, 275.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 177.7ms\n",
      "Speed: 3.0ms preprocess, 177.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 171.1ms\n",
      "Speed: 5.0ms preprocess, 171.1ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 170.7ms\n",
      "Speed: 5.2ms preprocess, 170.7ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 167.5ms\n",
      "Speed: 3.0ms preprocess, 167.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 173.4ms\n",
      "Speed: 5.0ms preprocess, 173.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 154.3ms\n",
      "Speed: 4.1ms preprocess, 154.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 186.8ms\n",
      "Speed: 9.4ms preprocess, 186.8ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 165.6ms\n",
      "Speed: 5.1ms preprocess, 165.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 168.7ms\n",
      "Speed: 4.5ms preprocess, 168.7ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 174.8ms\n",
      "Speed: 4.0ms preprocess, 174.8ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 171.0ms\n",
      "Speed: 3.8ms preprocess, 171.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 180.5ms\n",
      "Speed: 5.0ms preprocess, 180.5ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 182.9ms\n",
      "Speed: 4.0ms preprocess, 182.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 174.7ms\n",
      "Speed: 4.0ms preprocess, 174.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 172.1ms\n",
      "Speed: 4.0ms preprocess, 172.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 164.3ms\n",
      "Speed: 5.0ms preprocess, 164.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 175.3ms\n",
      "Speed: 5.0ms preprocess, 175.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 159.9ms\n",
      "Speed: 4.0ms preprocess, 159.9ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 170.0ms\n",
      "Speed: 3.9ms preprocess, 170.0ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 162.9ms\n",
      "Speed: 4.0ms preprocess, 162.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 179.8ms\n",
      "Speed: 5.0ms preprocess, 179.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 207.6ms\n",
      "Speed: 4.0ms preprocess, 207.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 201.4ms\n",
      "Speed: 5.0ms preprocess, 201.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 181.5ms\n",
      "Speed: 6.0ms preprocess, 181.5ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 4 persons, 195.1ms\n",
      "Speed: 8.6ms preprocess, 195.1ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 164.6ms\n",
      "Speed: 4.9ms preprocess, 164.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 225.1ms\n",
      "Speed: 6.0ms preprocess, 225.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 259.5ms\n",
      "Speed: 5.0ms preprocess, 259.5ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 239.5ms\n",
      "Speed: 7.0ms preprocess, 239.5ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 254.8ms\n",
      "Speed: 4.0ms preprocess, 254.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 183.3ms\n",
      "Speed: 5.0ms preprocess, 183.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 177.0ms\n",
      "Speed: 6.0ms preprocess, 177.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 164.1ms\n",
      "Speed: 4.0ms preprocess, 164.1ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 173.5ms\n",
      "Speed: 4.1ms preprocess, 173.5ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 244.2ms\n",
      "Speed: 7.0ms preprocess, 244.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 205.9ms\n",
      "Speed: 5.0ms preprocess, 205.9ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 179.7ms\n",
      "Speed: 5.1ms preprocess, 179.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 182.5ms\n",
      "Speed: 4.1ms preprocess, 182.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 146.3ms\n",
      "Speed: 5.0ms preprocess, 146.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 150.8ms\n",
      "Speed: 5.1ms preprocess, 150.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 147.6ms\n",
      "Speed: 5.0ms preprocess, 147.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 152.2ms\n",
      "Speed: 5.0ms preprocess, 152.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 144.1ms\n",
      "Speed: 3.0ms preprocess, 144.1ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 160.3ms\n",
      "Speed: 4.0ms preprocess, 160.3ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 170.7ms\n",
      "Speed: 4.9ms preprocess, 170.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 225.8ms\n",
      "Speed: 6.0ms preprocess, 225.8ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 172.3ms\n",
      "Speed: 5.0ms preprocess, 172.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 174.4ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 5.9ms preprocess, 174.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 167.7ms\n",
      "Speed: 5.0ms preprocess, 167.7ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 182.6ms\n",
      "Speed: 5.0ms preprocess, 182.6ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 201.6ms\n",
      "Speed: 7.0ms preprocess, 201.6ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 167.4ms\n",
      "Speed: 4.0ms preprocess, 167.4ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 172.9ms\n",
      "Speed: 4.0ms preprocess, 172.9ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 161.7ms\n",
      "Speed: 4.5ms preprocess, 161.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 251.1ms\n",
      "Speed: 8.9ms preprocess, 251.1ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 170.6ms\n",
      "Speed: 5.0ms preprocess, 170.6ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 172.4ms\n",
      "Speed: 5.0ms preprocess, 172.4ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 176.4ms\n",
      "Speed: 2.9ms preprocess, 176.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 205.9ms\n",
      "Speed: 6.5ms preprocess, 205.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 180.3ms\n",
      "Speed: 5.0ms preprocess, 180.3ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 247.1ms\n",
      "Speed: 4.0ms preprocess, 247.1ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 184.8ms\n",
      "Speed: 3.6ms preprocess, 184.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 171.5ms\n",
      "Speed: 6.0ms preprocess, 171.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 192.6ms\n",
      "Speed: 5.6ms preprocess, 192.6ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 141.8ms\n",
      "Speed: 6.0ms preprocess, 141.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 173.0ms\n",
      "Speed: 4.0ms preprocess, 173.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 182.0ms\n",
      "Speed: 5.0ms preprocess, 182.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 127.9ms\n",
      "Speed: 6.0ms preprocess, 127.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 196.7ms\n",
      "Speed: 4.0ms preprocess, 196.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 192.4ms\n",
      "Speed: 5.1ms preprocess, 192.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 288.6ms\n",
      "Speed: 6.0ms preprocess, 288.6ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 226.6ms\n",
      "Speed: 7.0ms preprocess, 226.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 172.5ms\n",
      "Speed: 4.3ms preprocess, 172.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 153.4ms\n",
      "Speed: 3.3ms preprocess, 153.4ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 165.6ms\n",
      "Speed: 3.5ms preprocess, 165.6ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 152.0ms\n",
      "Speed: 4.0ms preprocess, 152.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 164.4ms\n",
      "Speed: 5.0ms preprocess, 164.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 171.6ms\n",
      "Speed: 5.1ms preprocess, 171.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 169.2ms\n",
      "Speed: 5.1ms preprocess, 169.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 185.2ms\n",
      "Speed: 4.0ms preprocess, 185.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 230.8ms\n",
      "Speed: 5.0ms preprocess, 230.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 184.4ms\n",
      "Speed: 4.0ms preprocess, 184.4ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 168.0ms\n",
      "Speed: 4.0ms preprocess, 168.0ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 168.7ms\n",
      "Speed: 4.0ms preprocess, 168.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 171.5ms\n",
      "Speed: 4.0ms preprocess, 171.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 161.1ms\n",
      "Speed: 6.2ms preprocess, 161.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 166.8ms\n",
      "Speed: 4.5ms preprocess, 166.8ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 164.6ms\n",
      "Speed: 4.0ms preprocess, 164.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 192.9ms\n",
      "Speed: 4.7ms preprocess, 192.9ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 184.3ms\n",
      "Speed: 6.0ms preprocess, 184.3ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 235.0ms\n",
      "Speed: 5.9ms preprocess, 235.0ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 198.8ms\n",
      "Speed: 5.0ms preprocess, 198.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 195.5ms\n",
      "Speed: 4.0ms preprocess, 195.5ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 189.2ms\n",
      "Speed: 5.0ms preprocess, 189.2ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 258.2ms\n",
      "Speed: 6.0ms preprocess, 258.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 243.1ms\n",
      "Speed: 7.0ms preprocess, 243.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 170.4ms\n",
      "Speed: 5.0ms preprocess, 170.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 270.2ms\n",
      "Speed: 8.0ms preprocess, 270.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 232.1ms\n",
      "Speed: 8.0ms preprocess, 232.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 179.6ms\n",
      "Speed: 4.5ms preprocess, 179.6ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 216.4ms\n",
      "Speed: 10.1ms preprocess, 216.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 172.3ms\n",
      "Speed: 4.9ms preprocess, 172.3ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 175.2ms\n",
      "Speed: 4.9ms preprocess, 175.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 169.8ms\n",
      "Speed: 4.0ms preprocess, 169.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 163.7ms\n",
      "Speed: 4.9ms preprocess, 163.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 193.9ms\n",
      "Speed: 4.0ms preprocess, 193.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 212.6ms\n",
      "Speed: 4.4ms preprocess, 212.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 190.3ms\n",
      "Speed: 6.0ms preprocess, 190.3ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 159.7ms\n",
      "Speed: 4.0ms preprocess, 159.7ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 161.8ms\n",
      "Speed: 3.0ms preprocess, 161.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 183.9ms\n",
      "Speed: 5.0ms preprocess, 183.9ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 184.2ms\n",
      "Speed: 5.0ms preprocess, 184.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 126.3ms\n",
      "Speed: 5.0ms preprocess, 126.3ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 132.1ms\n",
      "Speed: 3.0ms preprocess, 132.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 142.3ms\n",
      "Speed: 4.0ms preprocess, 142.3ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 150.0ms\n",
      "Speed: 4.0ms preprocess, 150.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 168.7ms\n",
      "Speed: 5.0ms preprocess, 168.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 169.3ms\n",
      "Speed: 4.0ms preprocess, 169.3ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 180.8ms\n",
      "Speed: 6.0ms preprocess, 180.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 148.3ms\n",
      "Speed: 5.0ms preprocess, 148.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 128.6ms\n",
      "Speed: 4.0ms preprocess, 128.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 167.1ms\n",
      "Speed: 3.3ms preprocess, 167.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 143.5ms\n",
      "Speed: 5.0ms preprocess, 143.5ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 138.0ms\n",
      "Speed: 4.0ms preprocess, 138.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 141.8ms\n",
      "Speed: 3.0ms preprocess, 141.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 153.2ms\n",
      "Speed: 4.0ms preprocess, 153.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 115.6ms\n",
      "Speed: 2.6ms preprocess, 115.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 150.6ms\n",
      "Speed: 4.0ms preprocess, 150.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 135.3ms\n",
      "Speed: 4.0ms preprocess, 135.3ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 145.2ms\n",
      "Speed: 4.3ms preprocess, 145.2ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 183.4ms\n",
      "Speed: 3.1ms preprocess, 183.4ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 182.2ms\n",
      "Speed: 5.0ms preprocess, 182.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 142.2ms\n",
      "Speed: 4.8ms preprocess, 142.2ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 127.3ms\n",
      "Speed: 3.0ms preprocess, 127.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 136.5ms\n",
      "Speed: 4.7ms preprocess, 136.5ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 143.7ms\n",
      "Speed: 4.5ms preprocess, 143.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 135.5ms\n",
      "Speed: 5.0ms preprocess, 135.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 142.5ms\n",
      "Speed: 4.5ms preprocess, 142.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 162.1ms\n",
      "Speed: 5.0ms preprocess, 162.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 149.7ms\n",
      "Speed: 3.0ms preprocess, 149.7ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 167.5ms\n",
      "Speed: 4.0ms preprocess, 167.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 116.5ms\n",
      "Speed: 2.5ms preprocess, 116.5ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 153.8ms\n",
      "Speed: 3.0ms preprocess, 153.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 164.9ms\n",
      "Speed: 4.1ms preprocess, 164.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 171.9ms\n",
      "Speed: 5.0ms preprocess, 171.9ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 171.5ms\n",
      "Speed: 3.9ms preprocess, 171.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 170.4ms\n",
      "Speed: 4.0ms preprocess, 170.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 149.7ms\n",
      "Speed: 4.0ms preprocess, 149.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 156.9ms\n",
      "Speed: 5.0ms preprocess, 156.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 176.2ms\n",
      "Speed: 4.0ms preprocess, 176.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 160.5ms\n",
      "Speed: 4.0ms preprocess, 160.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 171.3ms\n",
      "Speed: 5.0ms preprocess, 171.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 163.5ms\n",
      "Speed: 5.0ms preprocess, 163.5ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 182.0ms\n",
      "Speed: 4.0ms preprocess, 182.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 163.9ms\n",
      "Speed: 4.5ms preprocess, 163.9ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 129.9ms\n",
      "Speed: 4.1ms preprocess, 129.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 640x384 (no detections), 134.0ms\n",
      "Speed: 4.0ms preprocess, 134.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 149.7ms\n",
      "Speed: 5.0ms preprocess, 149.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 204.4ms\n",
      "Speed: 6.0ms preprocess, 204.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 169.9ms\n",
      "Speed: 4.0ms preprocess, 169.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 165.2ms\n",
      "Speed: 6.2ms preprocess, 165.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 167.9ms\n",
      "Speed: 5.0ms preprocess, 167.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 177.0ms\n",
      "Speed: 4.0ms preprocess, 177.0ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 153.6ms\n",
      "Speed: 5.1ms preprocess, 153.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 143.5ms\n",
      "Speed: 5.1ms preprocess, 143.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 144.1ms\n",
      "Speed: 4.8ms preprocess, 144.1ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 153.3ms\n",
      "Speed: 5.0ms preprocess, 153.3ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 144.6ms\n",
      "Speed: 4.2ms preprocess, 144.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 138.0ms\n",
      "Speed: 5.0ms preprocess, 138.0ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 204.2ms\n",
      "Speed: 3.0ms preprocess, 204.2ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 135.4ms\n",
      "Speed: 4.0ms preprocess, 135.4ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 128.0ms\n",
      "Speed: 4.0ms preprocess, 128.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 133.2ms\n",
      "Speed: 4.0ms preprocess, 133.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 129.2ms\n",
      "Speed: 3.5ms preprocess, 129.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 145.0ms\n",
      "Speed: 5.8ms preprocess, 145.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 133.4ms\n",
      "Speed: 3.4ms preprocess, 133.4ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 138.9ms\n",
      "Speed: 3.8ms preprocess, 138.9ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 135.8ms\n",
      "Speed: 4.0ms preprocess, 135.8ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 128.4ms\n",
      "Speed: 3.0ms preprocess, 128.4ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 153.0ms\n",
      "Speed: 3.0ms preprocess, 153.0ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 157.2ms\n",
      "Speed: 4.0ms preprocess, 157.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 179.2ms\n",
      "Speed: 6.5ms preprocess, 179.2ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 140.3ms\n",
      "Speed: 6.0ms preprocess, 140.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 140.3ms\n",
      "Speed: 4.4ms preprocess, 140.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 147.5ms\n",
      "Speed: 4.0ms preprocess, 147.5ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 169.0ms\n",
      "Speed: 7.8ms preprocess, 169.0ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 142.9ms\n",
      "Speed: 4.0ms preprocess, 142.9ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 167.6ms\n",
      "Speed: 4.0ms preprocess, 167.6ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 180.7ms\n",
      "Speed: 4.0ms preprocess, 180.7ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 138.0ms\n",
      "Speed: 4.0ms preprocess, 138.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 133.5ms\n",
      "Speed: 2.9ms preprocess, 133.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 133.3ms\n",
      "Speed: 4.3ms preprocess, 133.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 155.8ms\n",
      "Speed: 5.0ms preprocess, 155.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 146.5ms\n",
      "Speed: 3.1ms preprocess, 146.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 163.3ms\n",
      "Speed: 4.1ms preprocess, 163.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 143.9ms\n",
      "Speed: 4.0ms preprocess, 143.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 135.6ms\n",
      "Speed: 4.0ms preprocess, 135.6ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 136.3ms\n",
      "Speed: 4.5ms preprocess, 136.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 193.0ms\n",
      "Speed: 6.0ms preprocess, 193.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 233.1ms\n",
      "Speed: 4.1ms preprocess, 233.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 241.4ms\n",
      "Speed: 12.0ms preprocess, 241.4ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 179.7ms\n",
      "Speed: 4.0ms preprocess, 179.7ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 174.7ms\n",
      "Speed: 12.0ms preprocess, 174.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 165.8ms\n",
      "Speed: 5.6ms preprocess, 165.8ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 169.6ms\n",
      "Speed: 5.0ms preprocess, 169.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 113.5ms\n",
      "Speed: 4.0ms preprocess, 113.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 154.9ms\n",
      "Speed: 5.0ms preprocess, 154.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 182.2ms\n",
      "Speed: 6.0ms preprocess, 182.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 211.7ms\n",
      "Speed: 6.1ms preprocess, 211.7ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 167.8ms\n",
      "Speed: 5.0ms preprocess, 167.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 640x384 1 person, 171.8ms\n",
      "Speed: 3.0ms preprocess, 171.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 181.9ms\n",
      "Speed: 5.0ms preprocess, 181.9ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 158.0ms\n",
      "Speed: 5.0ms preprocess, 158.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 170.2ms\n",
      "Speed: 4.0ms preprocess, 170.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 191.9ms\n",
      "Speed: 5.0ms preprocess, 191.9ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 167.3ms\n",
      "Speed: 4.0ms preprocess, 167.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 162.5ms\n",
      "Speed: 4.5ms preprocess, 162.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 186.1ms\n",
      "Speed: 4.0ms preprocess, 186.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 206.1ms\n",
      "Speed: 4.0ms preprocess, 206.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 158.5ms\n",
      "Speed: 4.0ms preprocess, 158.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 158.5ms\n",
      "Speed: 4.0ms preprocess, 158.5ms inference, 12.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 150.5ms\n",
      "Speed: 4.0ms preprocess, 150.5ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 134.2ms\n",
      "Speed: 4.0ms preprocess, 134.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 135.1ms\n",
      "Speed: 4.9ms preprocess, 135.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 131.1ms\n",
      "Speed: 4.0ms preprocess, 131.1ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 147.5ms\n",
      "Speed: 3.9ms preprocess, 147.5ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 146.7ms\n",
      "Speed: 4.0ms preprocess, 146.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 155.1ms\n",
      "Speed: 4.0ms preprocess, 155.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 186.6ms\n",
      "Speed: 4.9ms preprocess, 186.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 169.6ms\n",
      "Speed: 5.1ms preprocess, 169.6ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 151.8ms\n",
      "Speed: 4.0ms preprocess, 151.8ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 166.3ms\n",
      "Speed: 5.0ms preprocess, 166.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 141.7ms\n",
      "Speed: 5.0ms preprocess, 141.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 151.4ms\n",
      "Speed: 3.0ms preprocess, 151.4ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 216.9ms\n",
      "Speed: 5.0ms preprocess, 216.9ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 196.7ms\n",
      "Speed: 5.0ms preprocess, 196.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 218.4ms\n",
      "Speed: 8.9ms preprocess, 218.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 192.6ms\n",
      "Speed: 4.0ms preprocess, 192.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 161.6ms\n",
      "Speed: 5.0ms preprocess, 161.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 193.7ms\n",
      "Speed: 5.0ms preprocess, 193.7ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 141.1ms\n",
      "Speed: 4.0ms preprocess, 141.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 164.3ms\n",
      "Speed: 5.0ms preprocess, 164.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 173.9ms\n",
      "Speed: 4.9ms preprocess, 173.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 182.1ms\n",
      "Speed: 5.0ms preprocess, 182.1ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 144.5ms\n",
      "Speed: 4.0ms preprocess, 144.5ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 134.5ms\n",
      "Speed: 4.0ms preprocess, 134.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 151.6ms\n",
      "Speed: 4.0ms preprocess, 151.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 168.3ms\n",
      "Speed: 4.0ms preprocess, 168.3ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 213.6ms\n",
      "Speed: 10.0ms preprocess, 213.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 150.0ms\n",
      "Speed: 3.3ms preprocess, 150.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 154.5ms\n",
      "Speed: 4.0ms preprocess, 154.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 163.4ms\n",
      "Speed: 4.0ms preprocess, 163.4ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 142.9ms\n",
      "Speed: 4.0ms preprocess, 142.9ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 170.7ms\n",
      "Speed: 6.0ms preprocess, 170.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 133.8ms\n",
      "Speed: 4.5ms preprocess, 133.8ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 150.7ms\n",
      "Speed: 5.0ms preprocess, 150.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 139.8ms\n",
      "Speed: 4.9ms preprocess, 139.8ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 163.2ms\n",
      "Speed: 5.0ms preprocess, 163.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 151.3ms\n",
      "Speed: 3.0ms preprocess, 151.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 4 persons, 147.8ms\n",
      "Speed: 5.1ms preprocess, 147.8ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 127.1ms\n",
      "Speed: 3.5ms preprocess, 127.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 128.9ms\n",
      "Speed: 3.5ms preprocess, 128.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 127.1ms\n",
      "Speed: 4.0ms preprocess, 127.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 185.8ms\n",
      "Speed: 4.0ms preprocess, 185.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 149.7ms\n",
      "Speed: 5.0ms preprocess, 149.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 174.3ms\n",
      "Speed: 4.0ms preprocess, 174.3ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 152.5ms\n",
      "Speed: 4.2ms preprocess, 152.5ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 156.5ms\n",
      "Speed: 4.3ms preprocess, 156.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 236.2ms\n",
      "Speed: 7.0ms preprocess, 236.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 4 persons, 156.4ms\n",
      "Speed: 5.0ms preprocess, 156.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 4 persons, 137.6ms\n",
      "Speed: 4.0ms preprocess, 137.6ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 158.2ms\n",
      "Speed: 3.0ms preprocess, 158.2ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 4 persons, 165.4ms\n",
      "Speed: 4.1ms preprocess, 165.4ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 213.0ms\n",
      "Speed: 8.0ms preprocess, 213.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 162.2ms\n",
      "Speed: 4.9ms preprocess, 162.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 250.1ms\n",
      "Speed: 6.0ms preprocess, 250.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 168.8ms\n",
      "Speed: 3.0ms preprocess, 168.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 146.6ms\n",
      "Speed: 4.0ms preprocess, 146.6ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 191.2ms\n",
      "Speed: 4.0ms preprocess, 191.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 163.7ms\n",
      "Speed: 5.2ms preprocess, 163.7ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 158.4ms\n",
      "Speed: 4.0ms preprocess, 158.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 134.3ms\n",
      "Speed: 4.5ms preprocess, 134.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 126.0ms\n",
      "Speed: 5.0ms preprocess, 126.0ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 124.0ms\n",
      "Speed: 2.0ms preprocess, 124.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 163.5ms\n",
      "Speed: 4.0ms preprocess, 163.5ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 136.4ms\n",
      "Speed: 4.9ms preprocess, 136.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 138.2ms\n",
      "Speed: 4.4ms preprocess, 138.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 127.4ms\n",
      "Speed: 3.2ms preprocess, 127.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 120.3ms\n",
      "Speed: 3.0ms preprocess, 120.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 135.1ms\n",
      "Speed: 5.0ms preprocess, 135.1ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 132.2ms\n",
      "Speed: 4.3ms preprocess, 132.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 131.5ms\n",
      "Speed: 4.0ms preprocess, 131.5ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 137.5ms\n",
      "Speed: 4.0ms preprocess, 137.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 171.2ms\n",
      "Speed: 4.0ms preprocess, 171.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 183.0ms\n",
      "Speed: 6.0ms preprocess, 183.0ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 152.5ms\n",
      "Speed: 3.9ms preprocess, 152.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 161.0ms\n",
      "Speed: 5.6ms preprocess, 161.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 151.5ms\n",
      "Speed: 5.0ms preprocess, 151.5ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 144.4ms\n",
      "Speed: 3.0ms preprocess, 144.4ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 157.3ms\n",
      "Speed: 4.5ms preprocess, 157.3ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 4 persons, 129.7ms\n",
      "Speed: 3.0ms preprocess, 129.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 188.7ms\n",
      "Speed: 6.9ms preprocess, 188.7ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 189.0ms\n",
      "Speed: 5.9ms preprocess, 189.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 177.2ms\n",
      "Speed: 4.0ms preprocess, 177.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 153.8ms\n",
      "Speed: 4.0ms preprocess, 153.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 161.3ms\n",
      "Speed: 5.0ms preprocess, 161.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 177.3ms\n",
      "Speed: 5.5ms preprocess, 177.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 158.6ms\n",
      "Speed: 3.0ms preprocess, 158.6ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 174.1ms\n",
      "Speed: 4.0ms preprocess, 174.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 164.0ms\n",
      "Speed: 5.0ms preprocess, 164.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 141.2ms\n",
      "Speed: 4.0ms preprocess, 141.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 171.9ms\n",
      "Speed: 4.0ms preprocess, 171.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 161.8ms\n",
      "Speed: 5.2ms preprocess, 161.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 168.0ms\n",
      "Speed: 3.0ms preprocess, 168.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 159.7ms\n",
      "Speed: 4.0ms preprocess, 159.7ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 180.8ms\n",
      "Speed: 4.5ms preprocess, 180.8ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 161.4ms\n",
      "Speed: 5.0ms preprocess, 161.4ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 181.1ms\n",
      "Speed: 5.0ms preprocess, 181.1ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 140.3ms\n",
      "Speed: 3.0ms preprocess, 140.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 160.6ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 5.0ms preprocess, 160.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 187.6ms\n",
      "Speed: 4.9ms preprocess, 187.6ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 172.9ms\n",
      "Speed: 5.0ms preprocess, 172.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 205.6ms\n",
      "Speed: 4.0ms preprocess, 205.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 168.7ms\n",
      "Speed: 5.0ms preprocess, 168.7ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 169.5ms\n",
      "Speed: 5.0ms preprocess, 169.5ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 171.7ms\n",
      "Speed: 5.0ms preprocess, 171.7ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 160.9ms\n",
      "Speed: 5.5ms preprocess, 160.9ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 185.1ms\n",
      "Speed: 5.1ms preprocess, 185.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 171.9ms\n",
      "Speed: 4.0ms preprocess, 171.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 226.3ms\n",
      "Speed: 4.0ms preprocess, 226.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 174.6ms\n",
      "Speed: 5.0ms preprocess, 174.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 210.5ms\n",
      "Speed: 6.0ms preprocess, 210.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 221.5ms\n",
      "Speed: 3.9ms preprocess, 221.5ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 159.8ms\n",
      "Speed: 4.0ms preprocess, 159.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 189.2ms\n",
      "Speed: 4.8ms preprocess, 189.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 172.3ms\n",
      "Speed: 4.0ms preprocess, 172.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 171.5ms\n",
      "Speed: 4.0ms preprocess, 171.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 234.2ms\n",
      "Speed: 7.9ms preprocess, 234.2ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 176.3ms\n",
      "Speed: 3.1ms preprocess, 176.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 175.6ms\n",
      "Speed: 5.0ms preprocess, 175.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 164.2ms\n",
      "Speed: 5.2ms preprocess, 164.2ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 161.1ms\n",
      "Speed: 5.0ms preprocess, 161.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 200.7ms\n",
      "Speed: 5.4ms preprocess, 200.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 154.9ms\n",
      "Speed: 3.0ms preprocess, 154.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 137.5ms\n",
      "Speed: 3.0ms preprocess, 137.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 166.4ms\n",
      "Speed: 4.4ms preprocess, 166.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 170.7ms\n",
      "Speed: 5.5ms preprocess, 170.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 204.5ms\n",
      "Speed: 4.0ms preprocess, 204.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 4 persons, 164.1ms\n",
      "Speed: 4.9ms preprocess, 164.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 4 persons, 206.4ms\n",
      "Speed: 6.0ms preprocess, 206.4ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 4 persons, 181.6ms\n",
      "Speed: 5.0ms preprocess, 181.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 4 persons, 157.5ms\n",
      "Speed: 4.0ms preprocess, 157.5ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 154.3ms\n",
      "Speed: 4.7ms preprocess, 154.3ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 161.9ms\n",
      "Speed: 5.0ms preprocess, 161.9ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 152.3ms\n",
      "Speed: 4.0ms preprocess, 152.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 163.2ms\n",
      "Speed: 4.0ms preprocess, 163.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 201.3ms\n",
      "Speed: 5.0ms preprocess, 201.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 178.9ms\n",
      "Speed: 5.0ms preprocess, 178.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 161.5ms\n",
      "Speed: 5.0ms preprocess, 161.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 182.3ms\n",
      "Speed: 5.1ms preprocess, 182.3ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 159.0ms\n",
      "Speed: 4.2ms preprocess, 159.0ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 168.4ms\n",
      "Speed: 5.0ms preprocess, 168.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 147.1ms\n",
      "Speed: 4.0ms preprocess, 147.1ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 158.5ms\n",
      "Speed: 4.0ms preprocess, 158.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 154.7ms\n",
      "Speed: 4.3ms preprocess, 154.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 182.8ms\n",
      "Speed: 4.0ms preprocess, 182.8ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 220.8ms\n",
      "Speed: 5.9ms preprocess, 220.8ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 165.8ms\n",
      "Speed: 4.6ms preprocess, 165.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 164.7ms\n",
      "Speed: 5.0ms preprocess, 164.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 151.2ms\n",
      "Speed: 4.0ms preprocess, 151.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 176.8ms\n",
      "Speed: 3.9ms preprocess, 176.8ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 238.6ms\n",
      "Speed: 5.5ms preprocess, 238.6ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 171.8ms\n",
      "Speed: 5.4ms preprocess, 171.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 258.4ms\n",
      "Speed: 5.0ms preprocess, 258.4ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 176.8ms\n",
      "Speed: 5.0ms preprocess, 176.8ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 203.7ms\n",
      "Speed: 6.0ms preprocess, 203.7ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 249.1ms\n",
      "Speed: 8.1ms preprocess, 249.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 184.9ms\n",
      "Speed: 5.0ms preprocess, 184.9ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 221.2ms\n",
      "Speed: 5.9ms preprocess, 221.2ms inference, 6.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 160.0ms\n",
      "Speed: 3.0ms preprocess, 160.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 152.9ms\n",
      "Speed: 3.0ms preprocess, 152.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 136.8ms\n",
      "Speed: 5.3ms preprocess, 136.8ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 175.3ms\n",
      "Speed: 4.6ms preprocess, 175.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 159.2ms\n",
      "Speed: 4.0ms preprocess, 159.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 154.5ms\n",
      "Speed: 3.0ms preprocess, 154.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 153.3ms\n",
      "Speed: 3.0ms preprocess, 153.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 128.8ms\n",
      "Speed: 3.0ms preprocess, 128.8ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 159.5ms\n",
      "Speed: 4.0ms preprocess, 159.5ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 146.7ms\n",
      "Speed: 3.2ms preprocess, 146.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 161.7ms\n",
      "Speed: 5.0ms preprocess, 161.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 176.9ms\n",
      "Speed: 5.0ms preprocess, 176.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 171.5ms\n",
      "Speed: 5.0ms preprocess, 171.5ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 237.7ms\n",
      "Speed: 6.0ms preprocess, 237.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 165.2ms\n",
      "Speed: 3.5ms preprocess, 165.2ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 172.9ms\n",
      "Speed: 4.0ms preprocess, 172.9ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 192.9ms\n",
      "Speed: 5.0ms preprocess, 192.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 155.5ms\n",
      "Speed: 5.2ms preprocess, 155.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 178.8ms\n",
      "Speed: 4.0ms preprocess, 178.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 152.7ms\n",
      "Speed: 3.0ms preprocess, 152.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 168.6ms\n",
      "Speed: 3.0ms preprocess, 168.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 157.9ms\n",
      "Speed: 5.0ms preprocess, 157.9ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 190.5ms\n",
      "Speed: 5.2ms preprocess, 190.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 157.0ms\n",
      "Speed: 4.6ms preprocess, 157.0ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 166.4ms\n",
      "Speed: 5.0ms preprocess, 166.4ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 177.4ms\n",
      "Speed: 6.0ms preprocess, 177.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 164.1ms\n",
      "Speed: 3.2ms preprocess, 164.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 170.5ms\n",
      "Speed: 4.0ms preprocess, 170.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 172.2ms\n",
      "Speed: 5.0ms preprocess, 172.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 167.3ms\n",
      "Speed: 5.0ms preprocess, 167.3ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 157.1ms\n",
      "Speed: 4.9ms preprocess, 157.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 186.2ms\n",
      "Speed: 7.0ms preprocess, 186.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 267.1ms\n",
      "Speed: 4.0ms preprocess, 267.1ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 186.9ms\n",
      "Speed: 5.0ms preprocess, 186.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 172.7ms\n",
      "Speed: 5.0ms preprocess, 172.7ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 184.6ms\n",
      "Speed: 4.0ms preprocess, 184.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 164.3ms\n",
      "Speed: 5.2ms preprocess, 164.3ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 213.9ms\n",
      "Speed: 6.9ms preprocess, 213.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 183.6ms\n",
      "Speed: 4.0ms preprocess, 183.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 192.6ms\n",
      "Speed: 5.0ms preprocess, 192.6ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 239.9ms\n",
      "Speed: 5.9ms preprocess, 239.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 260.5ms\n",
      "Speed: 6.9ms preprocess, 260.5ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 186.6ms\n",
      "Speed: 6.0ms preprocess, 186.6ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 158.5ms\n",
      "Speed: 5.0ms preprocess, 158.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 167.1ms\n",
      "Speed: 5.0ms preprocess, 167.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 162.0ms\n",
      "Speed: 5.0ms preprocess, 162.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 163.5ms\n",
      "Speed: 4.1ms preprocess, 163.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 161.0ms\n",
      "Speed: 4.9ms preprocess, 161.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "classes = [0]\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture('treadmill_1.mp4')  # replace with your video file path\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Get the default resolutions\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "\n",
    "# Define the codec and create a VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # or use 'XVID'\n",
    "out = cv2.VideoWriter('treadmill_output_1.mp4', fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "\n",
    "treadmill_time_1=[]\n",
    "counter = 0  # Initialize counter\n",
    "continuous_detection = False\n",
    "\n",
    "while True:\n",
    "    # Read the frame from the video file\n",
    "    _, img = cap.read()\n",
    "    \n",
    "    if not _:\n",
    "        break\n",
    "    \n",
    "    frame_no = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "    timestamp = frame_no / fps\n",
    "    \n",
    "    # Run inference on the frame\n",
    "    results = model.predict(img,classes=classes)\n",
    "    \n",
    "    detected_classes = [box.cls for box in results[0].boxes]\n",
    "    if 0 in detected_classes:\n",
    "        counter += 1  # Increment counter if class 0 is detected\n",
    "        if counter >= 10 * fps:  # Check if class 0 has been detected for at least 10 seconds\n",
    "            continuous_detection = True\n",
    "    else:\n",
    "        counter = 0  # Reset counter if class 0 is not detected\n",
    "        continuous_detection = False\n",
    "\n",
    "    if continuous_detection:\n",
    "        print('Treadmill: '+'\\033[31m' + '•' + '\\033[0m')\n",
    "        treadmill_time_1.append(timestamp)\n",
    "    else:\n",
    "        print('Treadmill: '+'\\033[32m' + '•' + '\\033[0m')\n",
    "    \n",
    "    for r in results:\n",
    "        # Create an annotator for the image\n",
    "        annotator = Annotator(img)\n",
    "\n",
    "        # Get the bounding boxes\n",
    "        boxes = r.boxes\n",
    "\n",
    "        # Draw each bounding box on the image\n",
    "        for box in boxes:\n",
    "            b = box.xyxy[0]  # get box coordinates in (left, top, right, bottom) format\n",
    "            c = box.cls\n",
    "            annotator.box_label(b, model.names[int(c)])  # draw the box and label on the image\n",
    "\n",
    "        \n",
    "        # Get the annotated image\n",
    "        img = annotator.result()\n",
    "        \n",
    "        out.write(img)\n",
    "        \n",
    "    # Display the image with bounding boxes\n",
    "    cv2.imshow('YOLO V8 Detection', img)\n",
    "\n",
    "    # Break the loop if the 'space' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord(' '):\n",
    "        break\n",
    "\n",
    "# Release the video file and close all windows\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c41dfa4-d949-4a12-b3aa-d9b971b7bb38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76494b05",
   "metadata": {},
   "source": [
    "# Gym Equipment - Treadmill-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0c24aba-7a06-41ab-b81f-70ea6028efe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x384 (no detections), 416.1ms\n",
      "Speed: 23.5ms preprocess, 416.1ms inference, 6407.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 210.9ms\n",
      "Speed: 8.0ms preprocess, 210.9ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 188.8ms\n",
      "Speed: 5.0ms preprocess, 188.8ms inference, 24.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 233.7ms\n",
      "Speed: 4.7ms preprocess, 233.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 388.7ms\n",
      "Speed: 6.7ms preprocess, 388.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 315.3ms\n",
      "Speed: 6.0ms preprocess, 315.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 96.9ms\n",
      "Speed: 3.9ms preprocess, 96.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 84.5ms\n",
      "Speed: 4.0ms preprocess, 84.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 92.0ms\n",
      "Speed: 3.0ms preprocess, 92.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 82.5ms\n",
      "Speed: 2.0ms preprocess, 82.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 82.5ms\n",
      "Speed: 2.0ms preprocess, 82.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 85.8ms\n",
      "Speed: 2.1ms preprocess, 85.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 85.2ms\n",
      "Speed: 3.0ms preprocess, 85.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 81.0ms\n",
      "Speed: 2.0ms preprocess, 81.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 79.5ms\n",
      "Speed: 2.0ms preprocess, 79.5ms inference, 10.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 82.0ms\n",
      "Speed: 2.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 88.5ms\n",
      "Speed: 2.0ms preprocess, 88.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 80.2ms\n",
      "Speed: 2.0ms preprocess, 80.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 116.4ms\n",
      "Speed: 3.0ms preprocess, 116.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 74.0ms\n",
      "Speed: 2.0ms preprocess, 74.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 81.5ms\n",
      "Speed: 4.0ms preprocess, 81.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 77.0ms\n",
      "Speed: 2.0ms preprocess, 77.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 78.0ms\n",
      "Speed: 2.0ms preprocess, 78.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 78.0ms\n",
      "Speed: 2.0ms preprocess, 78.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 79.9ms\n",
      "Speed: 3.7ms preprocess, 79.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 85.1ms\n",
      "Speed: 2.3ms preprocess, 85.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 74.0ms\n",
      "Speed: 2.0ms preprocess, 74.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 84.5ms\n",
      "Speed: 2.0ms preprocess, 84.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 85.1ms\n",
      "Speed: 2.1ms preprocess, 85.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 76.8ms\n",
      "Speed: 2.0ms preprocess, 76.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 83.6ms\n",
      "Speed: 2.0ms preprocess, 83.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 72.6ms\n",
      "Speed: 2.0ms preprocess, 72.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 84.4ms\n",
      "Speed: 2.0ms preprocess, 84.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 84.0ms\n",
      "Speed: 2.0ms preprocess, 84.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 96.7ms\n",
      "Speed: 2.0ms preprocess, 96.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 84.4ms\n",
      "Speed: 2.0ms preprocess, 84.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 86.6ms\n",
      "Speed: 2.0ms preprocess, 86.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 89.5ms\n",
      "Speed: 3.0ms preprocess, 89.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 87.3ms\n",
      "Speed: 2.0ms preprocess, 87.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 87.0ms\n",
      "Speed: 2.0ms preprocess, 87.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 92.6ms\n",
      "Speed: 2.0ms preprocess, 92.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 85.6ms\n",
      "Speed: 3.0ms preprocess, 85.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 87.3ms\n",
      "Speed: 1.0ms preprocess, 87.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 86.5ms\n",
      "Speed: 2.5ms preprocess, 86.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 96.8ms\n",
      "Speed: 2.0ms preprocess, 96.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 93.3ms\n",
      "Speed: 2.5ms preprocess, 93.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 88.9ms\n",
      "Speed: 3.0ms preprocess, 88.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 85.6ms\n",
      "Speed: 2.0ms preprocess, 85.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 90.2ms\n",
      "Speed: 3.9ms preprocess, 90.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 83.3ms\n",
      "Speed: 2.4ms preprocess, 83.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 93.4ms\n",
      "Speed: 2.4ms preprocess, 93.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 90.0ms\n",
      "Speed: 3.0ms preprocess, 90.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 94.8ms\n",
      "Speed: 3.1ms preprocess, 94.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 89.1ms\n",
      "Speed: 3.0ms preprocess, 89.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 83.0ms\n",
      "Speed: 2.0ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 84.9ms\n",
      "Speed: 2.2ms preprocess, 84.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 88.3ms\n",
      "Speed: 8.6ms preprocess, 88.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 87.8ms\n",
      "Speed: 3.0ms preprocess, 87.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 94.8ms\n",
      "Speed: 3.1ms preprocess, 94.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 88.8ms\n",
      "Speed: 3.0ms preprocess, 88.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 91.6ms\n",
      "Speed: 2.0ms preprocess, 91.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 289.4ms\n",
      "Speed: 2.0ms preprocess, 289.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 179.6ms\n",
      "Speed: 4.5ms preprocess, 179.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 300.6ms\n",
      "Speed: 6.3ms preprocess, 300.6ms inference, 13.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 204.3ms\n",
      "Speed: 5.0ms preprocess, 204.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 271.4ms\n",
      "Speed: 6.4ms preprocess, 271.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 280.4ms\n",
      "Speed: 5.0ms preprocess, 280.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 195.1ms\n",
      "Speed: 5.5ms preprocess, 195.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 176.5ms\n",
      "Speed: 5.0ms preprocess, 176.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 348.5ms\n",
      "Speed: 4.2ms preprocess, 348.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 336.6ms\n",
      "Speed: 4.0ms preprocess, 336.6ms inference, 12.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 251.1ms\n",
      "Speed: 5.0ms preprocess, 251.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 354.0ms\n",
      "Speed: 5.0ms preprocess, 354.0ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 242.2ms\n",
      "Speed: 4.0ms preprocess, 242.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 355.3ms\n",
      "Speed: 7.0ms preprocess, 355.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 261.7ms\n",
      "Speed: 5.0ms preprocess, 261.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 391.6ms\n",
      "Speed: 4.9ms preprocess, 391.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 255.0ms\n",
      "Speed: 5.4ms preprocess, 255.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 196.0ms\n",
      "Speed: 2.0ms preprocess, 196.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 495.9ms\n",
      "Speed: 4.0ms preprocess, 495.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 229.7ms\n",
      "Speed: 5.0ms preprocess, 229.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 214.8ms\n",
      "Speed: 4.5ms preprocess, 214.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 244.7ms\n",
      "Speed: 2.0ms preprocess, 244.7ms inference, 12.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 154.2ms\n",
      "Speed: 4.8ms preprocess, 154.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 300.5ms\n",
      "Speed: 5.9ms preprocess, 300.5ms inference, 12.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 324.0ms\n",
      "Speed: 6.0ms preprocess, 324.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 155.3ms\n",
      "Speed: 5.6ms preprocess, 155.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 252.6ms\n",
      "Speed: 4.8ms preprocess, 252.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 348.1ms\n",
      "Speed: 5.5ms preprocess, 348.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 197.1ms\n",
      "Speed: 3.0ms preprocess, 197.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 315.3ms\n",
      "Speed: 7.0ms preprocess, 315.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 244.9ms\n",
      "Speed: 2.5ms preprocess, 244.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 310.5ms\n",
      "Speed: 4.5ms preprocess, 310.5ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 464.4ms\n",
      "Speed: 8.6ms preprocess, 464.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 481.8ms\n",
      "Speed: 6.9ms preprocess, 481.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 379.9ms\n",
      "Speed: 9.0ms preprocess, 379.9ms inference, 13.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 351.3ms\n",
      "Speed: 5.0ms preprocess, 351.3ms inference, 39.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 253.3ms\n",
      "Speed: 4.0ms preprocess, 253.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 204.4ms\n",
      "Speed: 5.0ms preprocess, 204.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 277.4ms\n",
      "Speed: 5.0ms preprocess, 277.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 254.2ms\n",
      "Speed: 4.5ms preprocess, 254.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 281.6ms\n",
      "Speed: 7.5ms preprocess, 281.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 253.7ms\n",
      "Speed: 4.0ms preprocess, 253.7ms inference, 11.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 332.7ms\n",
      "Speed: 4.0ms preprocess, 332.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 388.3ms\n",
      "Speed: 5.0ms preprocess, 388.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 272.9ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 3.1ms preprocess, 272.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 303.0ms\n",
      "Speed: 13.0ms preprocess, 303.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 169.7ms\n",
      "Speed: 4.1ms preprocess, 169.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 267.8ms\n",
      "Speed: 4.0ms preprocess, 267.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 358.3ms\n",
      "Speed: 8.0ms preprocess, 358.3ms inference, 12.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 339.4ms\n",
      "Speed: 7.0ms preprocess, 339.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 228.2ms\n",
      "Speed: 34.9ms preprocess, 228.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 226.6ms\n",
      "Speed: 6.0ms preprocess, 226.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 338.7ms\n",
      "Speed: 10.5ms preprocess, 338.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 294.3ms\n",
      "Speed: 7.0ms preprocess, 294.3ms inference, 12.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 452.9ms\n",
      "Speed: 3.0ms preprocess, 452.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 390.5ms\n",
      "Speed: 8.0ms preprocess, 390.5ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 383.5ms\n",
      "Speed: 46.2ms preprocess, 383.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 307.0ms\n",
      "Speed: 6.0ms preprocess, 307.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 94.2ms\n",
      "Speed: 3.0ms preprocess, 94.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 90.5ms\n",
      "Speed: 10.0ms preprocess, 90.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 76.8ms\n",
      "Speed: 2.0ms preprocess, 76.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 85.5ms\n",
      "Speed: 3.0ms preprocess, 85.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 81.5ms\n",
      "Speed: 3.0ms preprocess, 81.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 79.3ms\n",
      "Speed: 3.0ms preprocess, 79.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 80.0ms\n",
      "Speed: 2.0ms preprocess, 80.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 87.4ms\n",
      "Speed: 5.0ms preprocess, 87.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 85.0ms\n",
      "Speed: 3.0ms preprocess, 85.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 86.5ms\n",
      "Speed: 2.0ms preprocess, 86.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 85.8ms\n",
      "Speed: 4.0ms preprocess, 85.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 83.9ms\n",
      "Speed: 2.0ms preprocess, 83.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 84.5ms\n",
      "Speed: 1.0ms preprocess, 84.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 88.2ms\n",
      "Speed: 3.0ms preprocess, 88.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 82.0ms\n",
      "Speed: 2.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 85.5ms\n",
      "Speed: 2.0ms preprocess, 85.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 87.0ms\n",
      "Speed: 2.0ms preprocess, 87.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 88.3ms\n",
      "Speed: 3.0ms preprocess, 88.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 84.3ms\n",
      "Speed: 4.0ms preprocess, 84.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 91.0ms\n",
      "Speed: 4.0ms preprocess, 91.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 82.2ms\n",
      "Speed: 2.0ms preprocess, 82.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 202.8ms\n",
      "Speed: 4.0ms preprocess, 202.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 404.2ms\n",
      "Speed: 6.0ms preprocess, 404.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 325.8ms\n",
      "Speed: 6.0ms preprocess, 325.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 341.3ms\n",
      "Speed: 4.0ms preprocess, 341.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 414.4ms\n",
      "Speed: 6.9ms preprocess, 414.4ms inference, 11.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 333.9ms\n",
      "Speed: 4.0ms preprocess, 333.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 422.2ms\n",
      "Speed: 7.4ms preprocess, 422.2ms inference, 12.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 333.7ms\n",
      "Speed: 3.0ms preprocess, 333.7ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 337.7ms\n",
      "Speed: 5.5ms preprocess, 337.7ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 367.9ms\n",
      "Speed: 5.0ms preprocess, 367.9ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 389.3ms\n",
      "Speed: 16.0ms preprocess, 389.3ms inference, 9.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 422.6ms\n",
      "Speed: 5.0ms preprocess, 422.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 519.2ms\n",
      "Speed: 8.0ms preprocess, 519.2ms inference, 11.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 388.1ms\n",
      "Speed: 7.0ms preprocess, 388.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 563.2ms\n",
      "Speed: 7.0ms preprocess, 563.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 547.4ms\n",
      "Speed: 7.0ms preprocess, 547.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 272.5ms\n",
      "Speed: 8.0ms preprocess, 272.5ms inference, 12.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 342.0ms\n",
      "Speed: 31.1ms preprocess, 342.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 308.1ms\n",
      "Speed: 7.0ms preprocess, 308.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 528.3ms\n",
      "Speed: 4.0ms preprocess, 528.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 388.6ms\n",
      "Speed: 4.5ms preprocess, 388.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 493.9ms\n",
      "Speed: 7.0ms preprocess, 493.9ms inference, 12.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 491.2ms\n",
      "Speed: 10.0ms preprocess, 491.2ms inference, 14.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 313.7ms\n",
      "Speed: 6.0ms preprocess, 313.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 409.7ms\n",
      "Speed: 3.0ms preprocess, 409.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 322.5ms\n",
      "Speed: 5.2ms preprocess, 322.5ms inference, 71.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 374.2ms\n",
      "Speed: 3.5ms preprocess, 374.2ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 415.9ms\n",
      "Speed: 4.0ms preprocess, 415.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 305.8ms\n",
      "Speed: 4.5ms preprocess, 305.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 345.2ms\n",
      "Speed: 3.8ms preprocess, 345.2ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 403.5ms\n",
      "Speed: 4.5ms preprocess, 403.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 357.1ms\n",
      "Speed: 2.5ms preprocess, 357.1ms inference, 42.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 311.8ms\n",
      "Speed: 4.0ms preprocess, 311.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 474.8ms\n",
      "Speed: 7.0ms preprocess, 474.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 320.7ms\n",
      "Speed: 3.7ms preprocess, 320.7ms inference, 6.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 362.2ms\n",
      "Speed: 6.0ms preprocess, 362.2ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 437.8ms\n",
      "Speed: 3.0ms preprocess, 437.8ms inference, 16.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 215.7ms\n",
      "Speed: 7.0ms preprocess, 215.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 196.7ms\n",
      "Speed: 5.0ms preprocess, 196.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 293.3ms\n",
      "Speed: 5.0ms preprocess, 293.3ms inference, 7.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 295.7ms\n",
      "Speed: 4.0ms preprocess, 295.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 341.4ms\n",
      "Speed: 10.0ms preprocess, 341.4ms inference, 13.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 377.8ms\n",
      "Speed: 18.7ms preprocess, 377.8ms inference, 27.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 446.6ms\n",
      "Speed: 3.5ms preprocess, 446.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 374.7ms\n",
      "Speed: 2.5ms preprocess, 374.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 537.3ms\n",
      "Speed: 7.6ms preprocess, 537.3ms inference, 22.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 411.0ms\n",
      "Speed: 3.3ms preprocess, 411.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 422.5ms\n",
      "Speed: 94.1ms preprocess, 422.5ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 325.9ms\n",
      "Speed: 9.5ms preprocess, 325.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 406.9ms\n",
      "Speed: 50.3ms preprocess, 406.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 471.1ms\n",
      "Speed: 88.5ms preprocess, 471.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 441.6ms\n",
      "Speed: 3.0ms preprocess, 441.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 422.9ms\n",
      "Speed: 5.2ms preprocess, 422.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 410.7ms\n",
      "Speed: 7.0ms preprocess, 410.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 342.5ms\n",
      "Speed: 3.4ms preprocess, 342.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 512.0ms\n",
      "Speed: 7.4ms preprocess, 512.0ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 435.1ms\n",
      "Speed: 7.0ms preprocess, 435.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 403.7ms\n",
      "Speed: 3.1ms preprocess, 403.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 371.9ms\n",
      "Speed: 4.5ms preprocess, 371.9ms inference, 12.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 446.1ms\n",
      "Speed: 2.5ms preprocess, 446.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 475.9ms\n",
      "Speed: 6.0ms preprocess, 475.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 393.4ms\n",
      "Speed: 5.2ms preprocess, 393.4ms inference, 13.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 400.9ms\n",
      "Speed: 1.8ms preprocess, 400.9ms inference, 14.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 300.2ms\n",
      "Speed: 7.0ms preprocess, 300.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 425.1ms\n",
      "Speed: 5.0ms preprocess, 425.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 688.8ms\n",
      "Speed: 3.0ms preprocess, 688.8ms inference, 13.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 386.7ms\n",
      "Speed: 9.5ms preprocess, 386.7ms inference, 14.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 545.7ms\n",
      "Speed: 7.0ms preprocess, 545.7ms inference, 9.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 328.3ms\n",
      "Speed: 54.0ms preprocess, 328.3ms inference, 14.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 468.7ms\n",
      "Speed: 8.0ms preprocess, 468.7ms inference, 11.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 445.0ms\n",
      "Speed: 7.0ms preprocess, 445.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 342.4ms\n",
      "Speed: 3.8ms preprocess, 342.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 640x384 1 person, 359.2ms\n",
      "Speed: 3.5ms preprocess, 359.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 314.0ms\n",
      "Speed: 4.2ms preprocess, 314.0ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 365.3ms\n",
      "Speed: 3.9ms preprocess, 365.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 346.5ms\n",
      "Speed: 3.0ms preprocess, 346.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 314.8ms\n",
      "Speed: 8.4ms preprocess, 314.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 269.8ms\n",
      "Speed: 5.0ms preprocess, 269.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 267.6ms\n",
      "Speed: 3.5ms preprocess, 267.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 234.3ms\n",
      "Speed: 40.2ms preprocess, 234.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 199.4ms\n",
      "Speed: 4.1ms preprocess, 199.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 265.4ms\n",
      "Speed: 3.0ms preprocess, 265.4ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 197.5ms\n",
      "Speed: 4.0ms preprocess, 197.5ms inference, 13.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 187.6ms\n",
      "Speed: 4.0ms preprocess, 187.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 380.7ms\n",
      "Speed: 3.7ms preprocess, 380.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 248.1ms\n",
      "Speed: 4.0ms preprocess, 248.1ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 363.1ms\n",
      "Speed: 4.0ms preprocess, 363.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 395.9ms\n",
      "Speed: 5.9ms preprocess, 395.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 384.9ms\n",
      "Speed: 3.0ms preprocess, 384.9ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 314.2ms\n",
      "Speed: 7.0ms preprocess, 314.2ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 308.2ms\n",
      "Speed: 4.0ms preprocess, 308.2ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 270.2ms\n",
      "Speed: 5.0ms preprocess, 270.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 364.3ms\n",
      "Speed: 5.0ms preprocess, 364.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 348.5ms\n",
      "Speed: 4.7ms preprocess, 348.5ms inference, 17.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 256.9ms\n",
      "Speed: 7.0ms preprocess, 256.9ms inference, 13.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 403.6ms\n",
      "Speed: 5.0ms preprocess, 403.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 257.0ms\n",
      "Speed: 5.0ms preprocess, 257.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 364.8ms\n",
      "Speed: 4.0ms preprocess, 364.8ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 242.5ms\n",
      "Speed: 4.1ms preprocess, 242.5ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 267.8ms\n",
      "Speed: 4.2ms preprocess, 267.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 276.9ms\n",
      "Speed: 4.3ms preprocess, 276.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 204.2ms\n",
      "Speed: 5.5ms preprocess, 204.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 279.4ms\n",
      "Speed: 4.0ms preprocess, 279.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 326.7ms\n",
      "Speed: 5.2ms preprocess, 326.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 176.3ms\n",
      "Speed: 3.5ms preprocess, 176.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 206.2ms\n",
      "Speed: 3.3ms preprocess, 206.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 329.2ms\n",
      "Speed: 2.7ms preprocess, 329.2ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 283.0ms\n",
      "Speed: 4.0ms preprocess, 283.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 260.2ms\n",
      "Speed: 5.7ms preprocess, 260.2ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 190.8ms\n",
      "Speed: 4.5ms preprocess, 190.8ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 286.2ms\n",
      "Speed: 6.0ms preprocess, 286.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 376.8ms\n",
      "Speed: 4.0ms preprocess, 376.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 277.3ms\n",
      "Speed: 3.0ms preprocess, 277.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 211.0ms\n",
      "Speed: 4.0ms preprocess, 211.0ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 299.1ms\n",
      "Speed: 3.2ms preprocess, 299.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 275.2ms\n",
      "Speed: 2.5ms preprocess, 275.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 281.5ms\n",
      "Speed: 5.3ms preprocess, 281.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 382.0ms\n",
      "Speed: 5.0ms preprocess, 382.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 325.6ms\n",
      "Speed: 2.5ms preprocess, 325.6ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 311.2ms\n",
      "Speed: 5.5ms preprocess, 311.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 332.1ms\n",
      "Speed: 3.3ms preprocess, 332.1ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 341.7ms\n",
      "Speed: 3.5ms preprocess, 341.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 206.7ms\n",
      "Speed: 4.0ms preprocess, 206.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 201.8ms\n",
      "Speed: 9.1ms preprocess, 201.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 242.5ms\n",
      "Speed: 4.5ms preprocess, 242.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 379.3ms\n",
      "Speed: 2.0ms preprocess, 379.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 266.2ms\n",
      "Speed: 4.4ms preprocess, 266.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 369.2ms\n",
      "Speed: 7.0ms preprocess, 369.2ms inference, 12.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 321.5ms\n",
      "Speed: 8.0ms preprocess, 321.5ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 343.3ms\n",
      "Speed: 6.0ms preprocess, 343.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 3 persons, 279.1ms\n",
      "Speed: 9.0ms preprocess, 279.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 297.4ms\n",
      "Speed: 4.4ms preprocess, 297.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 398.8ms\n",
      "Speed: 5.0ms preprocess, 398.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 334.6ms\n",
      "Speed: 2.5ms preprocess, 334.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 430.7ms\n",
      "Speed: 3.1ms preprocess, 430.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 354.4ms\n",
      "Speed: 5.0ms preprocess, 354.4ms inference, 13.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 321.8ms\n",
      "Speed: 4.0ms preprocess, 321.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 341.8ms\n",
      "Speed: 6.9ms preprocess, 341.8ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 442.0ms\n",
      "Speed: 2.0ms preprocess, 442.0ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 246.9ms\n",
      "Speed: 7.0ms preprocess, 246.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 251.9ms\n",
      "Speed: 6.0ms preprocess, 251.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 199.5ms\n",
      "Speed: 4.0ms preprocess, 199.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 292.2ms\n",
      "Speed: 5.0ms preprocess, 292.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 276.6ms\n",
      "Speed: 3.6ms preprocess, 276.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 243.7ms\n",
      "Speed: 2.6ms preprocess, 243.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 270.4ms\n",
      "Speed: 5.0ms preprocess, 270.4ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 2 persons, 373.6ms\n",
      "Speed: 4.0ms preprocess, 373.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 234.6ms\n",
      "Speed: 5.0ms preprocess, 234.6ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 168.6ms\n",
      "Speed: 4.0ms preprocess, 168.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 300.5ms\n",
      "Speed: 33.0ms preprocess, 300.5ms inference, 12.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 201.4ms\n",
      "Speed: 5.0ms preprocess, 201.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 196.3ms\n",
      "Speed: 5.0ms preprocess, 196.3ms inference, 12.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 178.5ms\n",
      "Speed: 32.2ms preprocess, 178.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 167.8ms\n",
      "Speed: 3.0ms preprocess, 167.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 295.6ms\n",
      "Speed: 4.0ms preprocess, 295.6ms inference, 15.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 278.8ms\n",
      "Speed: 5.4ms preprocess, 278.8ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 266.1ms\n",
      "Speed: 6.3ms preprocess, 266.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 380.5ms\n",
      "Speed: 4.4ms preprocess, 380.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 265.1ms\n",
      "Speed: 5.1ms preprocess, 265.1ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 204.2ms\n",
      "Speed: 4.0ms preprocess, 204.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 200.0ms\n",
      "Speed: 5.0ms preprocess, 200.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 257.7ms\n",
      "Speed: 8.0ms preprocess, 257.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 1 person, 322.7ms\n",
      "Speed: 4.0ms preprocess, 322.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 188.2ms\n",
      "Speed: 4.0ms preprocess, 188.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 193.1ms\n",
      "Speed: 4.0ms preprocess, 193.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 397.7ms\n",
      "Speed: 7.0ms preprocess, 397.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 262.5ms\n",
      "Speed: 3.4ms preprocess, 262.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 269.6ms\n",
      "Speed: 4.1ms preprocess, 269.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 304.1ms\n",
      "Speed: 5.0ms preprocess, 304.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 248.0ms\n",
      "Speed: 4.0ms preprocess, 248.0ms inference, 8.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 173.0ms\n",
      "Speed: 5.0ms preprocess, 173.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 282.7ms\n",
      "Speed: 7.1ms preprocess, 282.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 174.8ms\n",
      "Speed: 5.4ms preprocess, 174.8ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 195.9ms\n",
      "Speed: 4.0ms preprocess, 195.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 274.1ms\n",
      "Speed: 5.4ms preprocess, 274.1ms inference, 12.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 253.2ms\n",
      "Speed: 72.0ms preprocess, 253.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 283.5ms\n",
      "Speed: 2.9ms preprocess, 283.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 245.3ms\n",
      "Speed: 2.5ms preprocess, 245.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 397.8ms\n",
      "Speed: 4.0ms preprocess, 397.8ms inference, 12.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 270.7ms\n",
      "Speed: 4.1ms preprocess, 270.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 194.6ms\n",
      "Speed: 4.5ms preprocess, 194.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 177.3ms\n",
      "Speed: 3.0ms preprocess, 177.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 283.7ms\n",
      "Speed: 4.0ms preprocess, 283.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 224.5ms\n",
      "Speed: 5.0ms preprocess, 224.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 237.9ms\n",
      "Speed: 77.1ms preprocess, 237.9ms inference, 11.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 203.3ms\n",
      "Speed: 5.0ms preprocess, 203.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 198.6ms\n",
      "Speed: 3.0ms preprocess, 198.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 267.1ms\n",
      "Speed: 5.0ms preprocess, 267.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 136.5ms\n",
      "Speed: 5.0ms preprocess, 136.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 216.3ms\n",
      "Speed: 4.0ms preprocess, 216.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 200.7ms\n",
      "Speed: 4.0ms preprocess, 200.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 199.2ms\n",
      "Speed: 4.0ms preprocess, 199.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 220.8ms\n",
      "Speed: 4.4ms preprocess, 220.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 171.5ms\n",
      "Speed: 4.3ms preprocess, 171.5ms inference, 14.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 325.2ms\n",
      "Speed: 4.0ms preprocess, 325.2ms inference, 11.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 341.1ms\n",
      "Speed: 4.0ms preprocess, 341.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 264.7ms\n",
      "Speed: 4.0ms preprocess, 264.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 211.9ms\n",
      "Speed: 2.9ms preprocess, 211.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 193.8ms\n",
      "Speed: 4.4ms preprocess, 193.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 276.5ms\n",
      "Speed: 3.6ms preprocess, 276.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 255.1ms\n",
      "Speed: 3.0ms preprocess, 255.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 284.5ms\n",
      "Speed: 5.0ms preprocess, 284.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 245.2ms\n",
      "Speed: 5.0ms preprocess, 245.2ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 266.7ms\n",
      "Speed: 5.3ms preprocess, 266.7ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 199.0ms\n",
      "Speed: 4.1ms preprocess, 199.0ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 153.2ms\n",
      "Speed: 4.3ms preprocess, 153.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 263.9ms\n",
      "Speed: 5.5ms preprocess, 263.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 194.7ms\n",
      "Speed: 5.0ms preprocess, 194.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 291.1ms\n",
      "Speed: 9.0ms preprocess, 291.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 402.9ms\n",
      "Speed: 10.0ms preprocess, 402.9ms inference, 12.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 349.6ms\n",
      "Speed: 7.0ms preprocess, 349.6ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n",
      "\n",
      "0: 640x384 (no detections), 381.4ms\n",
      "Speed: 7.1ms preprocess, 381.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Treadmill: \u001b[32m•\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "classes = [0]\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture('treadmill_2.mp4')  # replace with your video file path\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Get the default resolutions\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "\n",
    "# Define the codec and create a VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # or use 'XVID'\n",
    "out = cv2.VideoWriter('treadmill_output_2.mp4', fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "\n",
    "treadmill_time_2=[]\n",
    "counter = 0  # Initialize counter\n",
    "continuous_detection = False\n",
    "\n",
    "while True:\n",
    "    # Read the frame from the video file\n",
    "    _, img = cap.read()\n",
    "    \n",
    "    if not _:\n",
    "        break\n",
    "    \n",
    "    frame_no = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "    timestamp = frame_no / fps\n",
    "    \n",
    "    # Run inference on the frame\n",
    "    results = model.predict(img,classes=classes)\n",
    "    \n",
    "    detected_classes = [box.cls for box in results[0].boxes]\n",
    "    if 0 in detected_classes:\n",
    "        counter += 1  # Increment counter if class 0 is detected\n",
    "        if counter >= 10 * fps:  # Check if class 0 has been detected for at least 10 seconds\n",
    "            continuous_detection = True\n",
    "    else:\n",
    "        counter = 0  # Reset counter if class 0 is not detected\n",
    "        continuous_detection = False\n",
    "\n",
    "    if continuous_detection:\n",
    "        print('Treadmill: '+'\\033[31m' + '•' + '\\033[0m')\n",
    "        treadmill_time_2.append(timestamp)\n",
    "    else:\n",
    "        print('Treadmill: '+'\\033[32m' + '•' + '\\033[0m')\n",
    "    \n",
    "    for r in results:\n",
    "        # Create an annotator for the image\n",
    "        annotator = Annotator(img)\n",
    "\n",
    "        # Get the bounding boxes\n",
    "        boxes = r.boxes\n",
    "\n",
    "        # Draw each bounding box on the image\n",
    "        for box in boxes:\n",
    "            b = box.xyxy[0]  # get box coordinates in (left, top, right, bottom) format\n",
    "            c = box.cls\n",
    "            annotator.box_label(b, model.names[int(c)])  # draw the box and label on the image\n",
    "\n",
    "        \n",
    "        # Get the annotated image\n",
    "        img = annotator.result()\n",
    "        \n",
    "        out.write(img)\n",
    "        \n",
    "    # Display the image with bounding boxes\n",
    "    cv2.imshow('YOLO V8 Detection', img)\n",
    "\n",
    "    # Break the loop if the 'space' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord(' '):\n",
    "        break\n",
    "\n",
    "# Release the video file and close all windows\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf90d92-5123-4344-b553-181dea54adf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edbb3257",
   "metadata": {},
   "source": [
    "# Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eda6f90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "basketball_time_1 = [int(t) for t in basketball_time_1]\n",
    "basketball_time_2 = [int(t) for t in basketball_time_2]\n",
    "table_tennis_time_1 = [int(t) for t in table_tennis_time_1]\n",
    "table_tennis_time_2= [int(t) for t in table_tennis_time_2]\n",
    "treadmill_time_1 =[int(t) for t in treadmill_time_1]\n",
    "treadmill_time_2 =[int(t) for t in treadmill_time_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9123de2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "basketball_time_1 = [j for i in basketball_time_1 for j in range(i, i+11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d33263b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "basketball_time_2 = [j for i in basketball_time_2 for j in range(i, i+11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a40e1bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_tennis_time_1 = [j for i in table_tennis_time_1 for j in range(i, i+11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "45d31c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_tennis_time_2 = [j for i in table_tennis_time_2 for j in range(i, i+11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3bafcb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "treadmill_time_1 = [j for i in treadmill_time_1 for j in range(i, i+11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "612359ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "treadmill_time_2 = [j for i in treadmill_time_2 for j in range(i, i+11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e6c64f95-a209-45de-bfda-9b2253435375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "size": 30
         },
         "mode": "markers+text",
         "text": [
          "Basketball Court 1"
         ],
         "textfont": {
          "size": 20
         },
         "textposition": "top center",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          2
         ]
        },
        {
         "marker": {
          "size": 30
         },
         "mode": "markers+text",
         "text": [
          "Basketball Court 2"
         ],
         "textfont": {
          "size": 20
         },
         "textposition": "top center",
         "type": "scatter",
         "x": [
          1.5
         ],
         "y": [
          2
         ]
        },
        {
         "marker": {
          "size": 30
         },
         "mode": "markers+text",
         "text": [
          "Table Tennis"
         ],
         "textfont": {
          "size": 20
         },
         "textposition": "top center",
         "type": "scatter",
         "x": [
          2
         ],
         "y": [
          2
         ]
        },
        {
         "marker": {
          "size": 30
         },
         "mode": "markers+text",
         "text": [
          "Yoga Room"
         ],
         "textfont": {
          "size": 20
         },
         "textposition": "top center",
         "type": "scatter",
         "x": [
          2.5
         ],
         "y": [
          2
         ]
        },
        {
         "marker": {
          "size": 30
         },
         "mode": "markers+text",
         "text": [
          "Treadmill"
         ],
         "textfont": {
          "size": 20
         },
         "textposition": "top center",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          0.5
         ]
        },
        {
         "marker": {
          "size": 30
         },
         "mode": "markers+text",
         "text": [
          "Exercise Bike"
         ],
         "textfont": {
          "size": 20
         },
         "textposition": "top center",
         "type": "scatter",
         "x": [
          1.5
         ],
         "y": [
          0.5
         ]
        },
        {
         "marker": {
          "size": 30
         },
         "mode": "markers+text",
         "text": [
          "Weight Bench"
         ],
         "textfont": {
          "size": 20
         },
         "textposition": "top center",
         "type": "scatter",
         "x": [
          2
         ],
         "y": [
          0.5
         ]
        },
        {
         "line": {
          "color": "#FFA15A"
         },
         "mode": "lines+text",
         "name": "Gym",
         "text": [
          "Gym"
         ],
         "textfont": {
          "size": 30
         },
         "textposition": "top right",
         "type": "scatter",
         "x": [
          0.5,
          10
         ],
         "y": [
          1,
          1
         ]
        }
       ],
       "frames": [
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "red",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "red",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "red",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "red",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "red",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "red",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "red",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "red",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "red",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "red",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "red",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "red",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "red",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "red",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "red",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "red",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "red",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "red",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "red",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "red",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "red",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "red",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "red",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "red",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "red",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "red",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "red",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "red",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "red",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "red",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "red",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "red",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "red",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "red",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "red",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "red",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "red",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "red",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "red",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "red",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "red",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        },
        {
         "data": [
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2.5
           ],
           "y": [
            2
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            1.5
           ],
           "y": [
            0.5
           ]
          },
          {
           "marker": {
            "color": "green",
            "size": 30
           },
           "mode": "markers+text",
           "type": "scatter",
           "x": [
            2
           ],
           "y": [
            0.5
           ]
          },
          {
           "line": {
            "color": "#FFA15A"
           },
           "mode": "lines+text",
           "name": "Gym",
           "text": [
            "Gym"
           ],
           "textfont": {
            "size": 30
           },
           "textposition": "top right",
           "type": "scatter",
           "x": [
            0.5,
            10
           ],
           "y": [
            1,
            1
           ]
          }
         ]
        }
       ],
       "layout": {
        "height": 1000,
        "plot_bgcolor": "rgba(0,0,0,0)",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "size": 30
         },
         "text": "Dashboard"
        },
        "updatemenus": [
         {
          "buttons": [
           {
            "args": [
             null,
             {
              "frame": {
               "duration": 1000,
               "redraw": false
              }
             }
            ],
            "label": "Play",
            "method": "animate"
           }
          ],
          "type": "buttons"
         }
        ],
        "width": 1500,
        "xaxis": {
         "autorange": false,
         "range": [
          0,
          3
         ],
         "showgrid": false,
         "showticklabels": false,
         "zeroline": false
        },
        "yaxis": {
         "autorange": false,
         "range": [
          0,
          3
         ],
         "showgrid": false,
         "showticklabels": false,
         "zeroline": false
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"45a21cff-4d00-44cb-923c-89b0d8c5d549\" class=\"plotly-graph-div\" style=\"height:1000px; width:1500px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"45a21cff-4d00-44cb-923c-89b0d8c5d549\")) {                    Plotly.newPlot(                        \"45a21cff-4d00-44cb-923c-89b0d8c5d549\",                        [{\"marker\":{\"size\":30},\"mode\":\"markers+text\",\"text\":[\"Basketball Court 1\"],\"textfont\":{\"size\":20},\"textposition\":\"top center\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"size\":30},\"mode\":\"markers+text\",\"text\":[\"Basketball Court 2\"],\"textfont\":{\"size\":20},\"textposition\":\"top center\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"size\":30},\"mode\":\"markers+text\",\"text\":[\"Table Tennis\"],\"textfont\":{\"size\":20},\"textposition\":\"top center\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"size\":30},\"mode\":\"markers+text\",\"text\":[\"Yoga Room\"],\"textfont\":{\"size\":20},\"textposition\":\"top center\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"size\":30},\"mode\":\"markers+text\",\"text\":[\"Treadmill\"],\"textfont\":{\"size\":20},\"textposition\":\"top center\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"size\":30},\"mode\":\"markers+text\",\"text\":[\"Exercise Bike\"],\"textfont\":{\"size\":20},\"textposition\":\"top center\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"size\":30},\"mode\":\"markers+text\",\"text\":[\"Weight Bench\"],\"textfont\":{\"size\":20},\"textposition\":\"top center\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}],                        {\"updatemenus\":[{\"buttons\":[{\"args\":[null,{\"frame\":{\"duration\":1000,\"redraw\":false}}],\"label\":\"Play\",\"method\":\"animate\"}],\"type\":\"buttons\"}],\"xaxis\":{\"autorange\":false,\"range\":[0,3],\"showgrid\":false,\"zeroline\":false,\"showticklabels\":false},\"yaxis\":{\"autorange\":false,\"range\":[0,3],\"showgrid\":false,\"zeroline\":false,\"showticklabels\":false},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Dashboard\",\"font\":{\"size\":30}},\"width\":1500,\"height\":1000,\"plot_bgcolor\":\"rgba(0,0,0,0)\"},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            Plotly.addFrames('45a21cff-4d00-44cb-923c-89b0d8c5d549', [{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]},{\"data\":[{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2.5],\"y\":[2],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[1.5],\"y\":[0.5],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":30},\"mode\":\"markers+text\",\"x\":[2],\"y\":[0.5],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FFA15A\"},\"mode\":\"lines+text\",\"name\":\"Gym\",\"text\":[\"Gym\"],\"textfont\":{\"size\":30},\"textposition\":\"top right\",\"x\":[0.5,10],\"y\":[1,1],\"type\":\"scatter\"}]}]);\n",
       "                        }).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('45a21cff-4d00-44cb-923c-89b0d8c5d549');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Scatter(x=[1], y=[2], mode='markers+text', text=['Basketball Court 1'], textfont=dict(size=20), textposition='top center', marker=dict(size=30)),\n",
    "        go.Scatter(x=[1.5], y=[2], mode='markers+text', text=['Basketball Court 2'], textfont=dict(size=20), textposition='top center', marker=dict(size=30)),\n",
    "        go.Scatter(x=[2], y=[2], mode='markers+text', text=['Table Tennis'], textfont=dict(size=20), textposition='top center', marker=dict(size=30)),\n",
    "        go.Scatter(x=[2.5], y=[2], mode='markers+text', text=['Yoga Room'], textfont=dict(size=20), textposition='top center', marker=dict(size=30)),\n",
    "        go.Scatter(x=[1], y=[0.5], mode='markers+text', text=['Treadmill'], textfont=dict(size=20), textposition='top center', marker=dict(size=30)),\n",
    "        go.Scatter(x=[1.5], y=[0.5], mode='markers+text', text=['Exercise Bike'], textfont=dict(size=20), textposition='top center', marker=dict(size=30)),\n",
    "        go.Scatter(x=[0.5,10], y=[1,1], name='Gym', mode='lines+text', text=['Gym'],textfont=dict(size=30), textposition='top right',line=dict(color='#FFA15A'))\n",
    "    ],\n",
    "    layout=go.Layout(\n",
    "        xaxis=dict(range=[0, 3], autorange=False),\n",
    "        yaxis=dict(range=[0, 3], autorange=False),\n",
    "        updatemenus=[dict(type=\"buttons\", buttons=[dict(label=\"Play\", method=\"animate\", args=[None])])]),\n",
    "    frames=[\n",
    "        go.Frame(\n",
    "            data=[\n",
    "                go.Scatter(x=[1], y=[2], mode='markers+text', marker=dict(color='red' if i in basketball_time_1 else 'green', size=30)),\n",
    "                go.Scatter(x=[1.5], y=[2], mode='markers+text', marker=dict(color='red' if i in basketball_time_2 else 'green', size=30)),\n",
    "                go.Scatter(x=[2], y=[2], mode='markers+text', marker=dict(color='red' if i in table_tennis_time_1 else 'green', size=30)),\n",
    "                go.Scatter(x=[2.5], y=[2], mode='markers+text', marker=dict(color='red' if i in table_tennis_time_2 else 'green', size=30)),\n",
    "                go.Scatter(x=[1], y=[0.5], mode='markers+text', marker=dict(color='red' if i in treadmill_time_1 else 'green', size=30)),\n",
    "                go.Scatter(x=[1.5], y=[0.5], mode='markers+text', marker=dict(color='red' if i in treadmill_time_2 else 'green', size=30)),\n",
    "                go.Scatter(x=[0.5,10], y=[1,1], name='Gym', mode='lines+text', text=['Gym'],textfont=dict(size=30), textposition='top right',line=dict(color='#FFA15A'))\n",
    "            ])\n",
    "        for i in range(0, 60)]\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Dashboard\",\n",
    "    titlefont=dict(size=30),\n",
    "    width=1500,  # Adjust the size of the plot\n",
    "    height=1000,  # Adjust the size of the plot\n",
    "    xaxis=dict(showgrid=False,zeroline=False, showticklabels=False),  # Remove the x-axis grid lines\n",
    "    yaxis=dict(showgrid=False,zeroline=False, showticklabels=False),  # Remove the y-axis grid lines\n",
    "    updatemenus=[dict(type=\"buttons\", buttons=[dict(label=\"Play\", method=\"animate\", args=[None, {\"frame\": {\"duration\": 1000, \"redraw\": False}}])])],\n",
    "    plot_bgcolor='rgba(0,0,0,0)'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e15479-58d9-41ba-8c05-14cd114f8ddc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80d9ec2-8ce2-4f50-91cd-92c6204c0689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf572a1d-6507-4259-b1b6-daa93aa61564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd60c4ea-7bbb-4d03-9af3-13f1a3386c44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f10c645-16cf-44ba-8a07-5ad13c32a61d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74be17e-9ba5-440f-bb80-a37a58802755",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf68538-1e89-4c60-91fc-708ba182853c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cca9ce9-78f7-4e9a-930b-0fb5aa8a1e1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ee86cf-3e01-439d-a376-3da2f13b02ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79faee41-4584-4bc2-84f3-6239f8aac63b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ec87dc-98ec-4085-86ea-7773d28102df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52956544-9c1a-462c-a7f2-e4393ae80111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3573e2dd-6e1f-46a4-9c6e-d76194e56f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05d2b71-4172-4bcc-91b5-b1b44a6c66a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ff7cb1-2225-49a5-a192-980397f68875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c749ff-5b39-4edc-b4c5-dddc7f8d95ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5e667d-806e-4074-b8a5-daa1a6e27c02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43ddcc2-ac4f-4d80-b34c-190e562676a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
